{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b07a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc3e8d",
   "metadata": {},
   "source": [
    "## Get measurements from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5161bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_readings = pd.read_csv(\"D:\\Master\\Thesis\\Code\\LBNL_FDD_Dataset_FCU\\measurements_LBNL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3646f3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>measurement</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-01 00:00:00</td>\n",
       "      <td>FCU_CTRL</td>\n",
       "      <td>2.000</td>\n",
       "      <td>FCU_CTRL_2018-02-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-01 00:10:00</td>\n",
       "      <td>FCU_CTRL</td>\n",
       "      <td>2.000</td>\n",
       "      <td>FCU_CTRL_2018-02-01 00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:20:00</td>\n",
       "      <td>FCU_CTRL</td>\n",
       "      <td>2.000</td>\n",
       "      <td>FCU_CTRL_2018-02-01 00:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-02-01 00:30:00</td>\n",
       "      <td>FCU_CTRL</td>\n",
       "      <td>2.000</td>\n",
       "      <td>FCU_CTRL_2018-02-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-02-01 00:40:00</td>\n",
       "      <td>FCU_CTRL</td>\n",
       "      <td>2.000</td>\n",
       "      <td>FCU_CTRL_2018-02-01 00:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793723</th>\n",
       "      <td>793723</td>\n",
       "      <td>2018-08-31 23:10:00</td>\n",
       "      <td>FCU_RA_HUMD</td>\n",
       "      <td>80.966</td>\n",
       "      <td>FCU_RA_HUMD_2018-08-31 23:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793724</th>\n",
       "      <td>793724</td>\n",
       "      <td>2018-08-31 23:20:00</td>\n",
       "      <td>FCU_RA_HUMD</td>\n",
       "      <td>81.204</td>\n",
       "      <td>FCU_RA_HUMD_2018-08-31 23:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793725</th>\n",
       "      <td>793725</td>\n",
       "      <td>2018-08-31 23:30:00</td>\n",
       "      <td>FCU_RA_HUMD</td>\n",
       "      <td>81.387</td>\n",
       "      <td>FCU_RA_HUMD_2018-08-31 23:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793726</th>\n",
       "      <td>793726</td>\n",
       "      <td>2018-08-31 23:40:00</td>\n",
       "      <td>FCU_RA_HUMD</td>\n",
       "      <td>81.536</td>\n",
       "      <td>FCU_RA_HUMD_2018-08-31 23:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793727</th>\n",
       "      <td>793727</td>\n",
       "      <td>2018-08-31 23:50:00</td>\n",
       "      <td>FCU_RA_HUMD</td>\n",
       "      <td>81.664</td>\n",
       "      <td>FCU_RA_HUMD_2018-08-31 23:50:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>793728 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0             Datetime    sensor_id  measurement  \\\n",
       "0                0  2018-02-01 00:00:00     FCU_CTRL        2.000   \n",
       "1                1  2018-02-01 00:10:00     FCU_CTRL        2.000   \n",
       "2                2  2018-02-01 00:20:00     FCU_CTRL        2.000   \n",
       "3                3  2018-02-01 00:30:00     FCU_CTRL        2.000   \n",
       "4                4  2018-02-01 00:40:00     FCU_CTRL        2.000   \n",
       "...            ...                  ...          ...          ...   \n",
       "793723      793723  2018-08-31 23:10:00  FCU_RA_HUMD       80.966   \n",
       "793724      793724  2018-08-31 23:20:00  FCU_RA_HUMD       81.204   \n",
       "793725      793725  2018-08-31 23:30:00  FCU_RA_HUMD       81.387   \n",
       "793726      793726  2018-08-31 23:40:00  FCU_RA_HUMD       81.536   \n",
       "793727      793727  2018-08-31 23:50:00  FCU_RA_HUMD       81.664   \n",
       "\n",
       "                              unique_id  \n",
       "0          FCU_CTRL_2018-02-01 00:00:00  \n",
       "1          FCU_CTRL_2018-02-01 00:10:00  \n",
       "2          FCU_CTRL_2018-02-01 00:20:00  \n",
       "3          FCU_CTRL_2018-02-01 00:30:00  \n",
       "4          FCU_CTRL_2018-02-01 00:40:00  \n",
       "...                                 ...  \n",
       "793723  FCU_RA_HUMD_2018-08-31 23:10:00  \n",
       "793724  FCU_RA_HUMD_2018-08-31 23:20:00  \n",
       "793725  FCU_RA_HUMD_2018-08-31 23:30:00  \n",
       "793726  FCU_RA_HUMD_2018-08-31 23:40:00  \n",
       "793727  FCU_RA_HUMD_2018-08-31 23:50:00  \n",
       "\n",
       "[793728 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74ad359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df = sensor_readings.pivot(index='Datetime', columns='sensor_id', values='measurement')\n",
    "pivoted_df.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b167858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FCU_CLG_GPM</th>\n",
       "      <th>FCU_CLG_RWT</th>\n",
       "      <th>FCU_CTRL</th>\n",
       "      <th>FCU_CVLV</th>\n",
       "      <th>FCU_CVLV_DM</th>\n",
       "      <th>FCU_DAT</th>\n",
       "      <th>FCU_DA_CFM</th>\n",
       "      <th>FCU_DA_HUMD</th>\n",
       "      <th>FCU_DMPR</th>\n",
       "      <th>FCU_DMPR_DM</th>\n",
       "      <th>...</th>\n",
       "      <th>FCU_OAT</th>\n",
       "      <th>FCU_OA_CFM</th>\n",
       "      <th>FCU_OA_HUMD</th>\n",
       "      <th>FCU_RAT</th>\n",
       "      <th>FCU_RA_HUMD</th>\n",
       "      <th>FCU_SPD</th>\n",
       "      <th>FCU_WAT</th>\n",
       "      <th>RMCLGSPT</th>\n",
       "      <th>RMHTGSPT</th>\n",
       "      <th>RM_TEMP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>54.652</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.186</td>\n",
       "      <td>0.007</td>\n",
       "      <td>71.668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.144</td>\n",
       "      <td>0.88</td>\n",
       "      <td>82.015</td>\n",
       "      <td>64.898</td>\n",
       "      <td>87.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:10:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>54.284</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.874</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>72.390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.214</td>\n",
       "      <td>0.88</td>\n",
       "      <td>76.755</td>\n",
       "      <td>64.754</td>\n",
       "      <td>88.086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:20:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53.912</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.558</td>\n",
       "      <td>0.001</td>\n",
       "      <td>73.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.284</td>\n",
       "      <td>0.88</td>\n",
       "      <td>71.091</td>\n",
       "      <td>64.608</td>\n",
       "      <td>88.264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53.535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.235</td>\n",
       "      <td>0.011</td>\n",
       "      <td>73.912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.354</td>\n",
       "      <td>0.88</td>\n",
       "      <td>65.328</td>\n",
       "      <td>64.463</td>\n",
       "      <td>88.411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:40:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53.155</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.909</td>\n",
       "      <td>0.014</td>\n",
       "      <td>74.713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.424</td>\n",
       "      <td>0.88</td>\n",
       "      <td>59.767</td>\n",
       "      <td>64.318</td>\n",
       "      <td>88.525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:10:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>67.976</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.763</td>\n",
       "      <td>0.010</td>\n",
       "      <td>49.449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.190</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84.538</td>\n",
       "      <td>75.970</td>\n",
       "      <td>80.966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:20:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.875</td>\n",
       "      <td>0.003</td>\n",
       "      <td>49.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.985</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84.690</td>\n",
       "      <td>75.908</td>\n",
       "      <td>81.204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.524</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.962</td>\n",
       "      <td>0.009</td>\n",
       "      <td>49.075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.777</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84.672</td>\n",
       "      <td>75.868</td>\n",
       "      <td>81.387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:40:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.774</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.020</td>\n",
       "      <td>0.008</td>\n",
       "      <td>48.967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.565</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84.508</td>\n",
       "      <td>75.841</td>\n",
       "      <td>81.536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:50:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>69.001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.055</td>\n",
       "      <td>0.002</td>\n",
       "      <td>48.903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.350</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84.220</td>\n",
       "      <td>75.822</td>\n",
       "      <td>81.664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30528 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FCU_CLG_GPM  FCU_CLG_RWT  FCU_CTRL  FCU_CVLV  \\\n",
       "Datetime                                                            \n",
       "2018-02-01 00:00:00          0.0       54.652       2.0       0.0   \n",
       "2018-02-01 00:10:00          0.0       54.284       2.0       0.0   \n",
       "2018-02-01 00:20:00          0.0       53.912       2.0       0.0   \n",
       "2018-02-01 00:30:00          0.0       53.535       2.0       0.0   \n",
       "2018-02-01 00:40:00          0.0       53.155       2.0       0.0   \n",
       "...                          ...          ...       ...       ...   \n",
       "2018-08-31 23:10:00          0.0       67.976       2.0       0.0   \n",
       "2018-08-31 23:20:00          0.0       68.258       2.0       0.0   \n",
       "2018-08-31 23:30:00          0.0       68.524       2.0       0.0   \n",
       "2018-08-31 23:40:00          0.0       68.774       2.0       0.0   \n",
       "2018-08-31 23:50:00          0.0       69.001       2.0       0.0   \n",
       "\n",
       "                     FCU_CVLV_DM  FCU_DAT  FCU_DA_CFM  FCU_DA_HUMD  FCU_DMPR  \\\n",
       "Datetime                                                                       \n",
       "2018-02-01 00:00:00          0.0   58.186       0.007       71.668       0.0   \n",
       "2018-02-01 00:10:00          0.0   57.874      -0.004       72.390       0.0   \n",
       "2018-02-01 00:20:00          0.0   57.558       0.001       73.137       0.0   \n",
       "2018-02-01 00:30:00          0.0   57.235       0.011       73.912       0.0   \n",
       "2018-02-01 00:40:00          0.0   56.909       0.014       74.713       0.0   \n",
       "...                          ...      ...         ...          ...       ...   \n",
       "2018-08-31 23:10:00          0.0   68.763       0.010       49.449       0.0   \n",
       "2018-08-31 23:20:00          0.0   68.875       0.003       49.234       0.0   \n",
       "2018-08-31 23:30:00          0.0   68.962       0.009       49.075       0.0   \n",
       "2018-08-31 23:40:00          0.0   69.020       0.008       48.967       0.0   \n",
       "2018-08-31 23:50:00          0.0   69.055       0.002       48.903       0.0   \n",
       "\n",
       "                     FCU_DMPR_DM  ...  FCU_OAT  FCU_OA_CFM  FCU_OA_HUMD  \\\n",
       "Datetime                          ...                                     \n",
       "2018-02-01 00:00:00          0.0  ...   16.144        0.88       82.015   \n",
       "2018-02-01 00:10:00          0.0  ...   15.214        0.88       76.755   \n",
       "2018-02-01 00:20:00          0.0  ...   14.284        0.88       71.091   \n",
       "2018-02-01 00:30:00          0.0  ...   13.354        0.88       65.328   \n",
       "2018-02-01 00:40:00          0.0  ...   12.424        0.88       59.767   \n",
       "...                          ...  ...      ...         ...          ...   \n",
       "2018-08-31 23:10:00          0.0  ...   74.190        0.88       84.538   \n",
       "2018-08-31 23:20:00          0.0  ...   73.985        0.88       84.690   \n",
       "2018-08-31 23:30:00          0.0  ...   73.777        0.88       84.672   \n",
       "2018-08-31 23:40:00          0.0  ...   73.565        0.88       84.508   \n",
       "2018-08-31 23:50:00          0.0  ...   73.350        0.88       84.220   \n",
       "\n",
       "                     FCU_RAT  FCU_RA_HUMD  FCU_SPD  FCU_WAT  RMCLGSPT  \\\n",
       "Datetime                                                                \n",
       "2018-02-01 00:00:00   64.898       87.883      0.0      0.0      85.0   \n",
       "2018-02-01 00:10:00   64.754       88.086      0.0      0.0      85.0   \n",
       "2018-02-01 00:20:00   64.608       88.264      0.0      0.0      85.0   \n",
       "2018-02-01 00:30:00   64.463       88.411      0.0      0.0      85.0   \n",
       "2018-02-01 00:40:00   64.318       88.525      0.0      0.0      85.0   \n",
       "...                      ...          ...      ...      ...       ...   \n",
       "2018-08-31 23:10:00   75.970       80.966      0.0      0.0      85.0   \n",
       "2018-08-31 23:20:00   75.908       81.204      0.0      0.0      85.0   \n",
       "2018-08-31 23:30:00   75.868       81.387      0.0      0.0      85.0   \n",
       "2018-08-31 23:40:00   75.841       81.536      0.0      0.0      85.0   \n",
       "2018-08-31 23:50:00   75.822       81.664      0.0      0.0      85.0   \n",
       "\n",
       "                     RMHTGSPT  RM_TEMP  \n",
       "Datetime                                \n",
       "2018-02-01 00:00:00      55.0   64.898  \n",
       "2018-02-01 00:10:00      55.0   64.754  \n",
       "2018-02-01 00:20:00      55.0   64.608  \n",
       "2018-02-01 00:30:00      55.0   64.463  \n",
       "2018-02-01 00:40:00      55.0   64.318  \n",
       "...                       ...      ...  \n",
       "2018-08-31 23:10:00      55.0   75.970  \n",
       "2018-08-31 23:20:00      55.0   75.908  \n",
       "2018-08-31 23:30:00      55.0   75.868  \n",
       "2018-08-31 23:40:00      55.0   75.841  \n",
       "2018-08-31 23:50:00      55.0   75.822  \n",
       "\n",
       "[30528 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be116b2",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a5060",
   "metadata": {},
   "source": [
    "### Split train/val, and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c7ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "temp_cols, humidity_cols, air_flow_cols, water_flow_cols, power_cols, binary_cols, speed_cols = [], [], [], [], [], [], []\n",
    "\n",
    "for column in pivoted_df.columns:\n",
    "    if \"HUMD\" in column:\n",
    "        humidity_cols.append(column)\n",
    "    elif \"GPM\" in column:\n",
    "        water_flow_cols.append(column)\n",
    "    elif \"CFM\" in column:\n",
    "        air_flow_cols.append(column)\n",
    "    elif \"WAT\" in column:\n",
    "        power_cols.append(column)\n",
    "    elif any(sub in column for sub in [\"CTRL\", \"CVLV\", \"HVLV\", \"DMPR\"]):\n",
    "        binary_cols.append(column)\n",
    "    elif \"SPD\" in column:\n",
    "        speed_cols.append(column)\n",
    "    else:\n",
    "        temp_cols.append(column)\n",
    "\n",
    "# Create scalers for each feature type\n",
    "scalers = {\n",
    "    'temp': StandardScaler(),\n",
    "    'humidity': MinMaxScaler(),\n",
    "    'water_flow': StandardScaler(),\n",
    "    'air_flow': StandardScaler(),\n",
    "    'power': StandardScaler(),\n",
    "    'binary': None,\n",
    "    'speed': StandardScaler()\n",
    "}\n",
    "\n",
    "column_groups = {\n",
    "    'temp': temp_cols,\n",
    "    'humidity': humidity_cols,\n",
    "    'water_flow': water_flow_cols,\n",
    "    'air_flow': air_flow_cols,\n",
    "    'power': power_cols,\n",
    "    'binary': binary_cols,\n",
    "    'speed': speed_cols\n",
    "}\n",
    "\n",
    "\n",
    "def split_scale(measurements, cluster):\n",
    "    # Train/validation split\n",
    "    X_train_full, X_val_full = train_test_split(measurements, test_size=0.2, shuffle = False, random_state=42)\n",
    "\n",
    "    # Deep copies\n",
    "    X_train_full_scaled = X_train_full.copy()\n",
    "    X_val_full_scaled = X_val_full.copy()\n",
    "\n",
    "    fitted_scalers = {}\n",
    "\n",
    "    for group, cols in column_groups.items():\n",
    "        # Only use columns present in the current data\n",
    "        present_cols = [col for col in cols if col in X_train_full.columns]\n",
    "\n",
    "        if not present_cols:\n",
    "            continue  # Skip if no columns from this group are in the dataset\n",
    "\n",
    "        scaler = scalers[group]\n",
    "        if scaler is not None:\n",
    "            scaler_instance = scaler.fit(X_train_full[present_cols])\n",
    "            X_train_full_scaled[present_cols] = scaler_instance.transform(X_train_full[present_cols])\n",
    "            X_val_full_scaled[present_cols] = scaler_instance.transform(X_val_full[present_cols])\n",
    "            joblib.dump(scaler_instance, f\"{group}_scaler_{cluster}.pkl\")\n",
    "            fitted_scalers[group] = scaler_instance\n",
    "\n",
    "    return X_train_full_scaled, X_val_full_scaled, X_train_full, X_val_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090c844",
   "metadata": {},
   "source": [
    "### Select semantically relevant pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cooling_coil = pivoted_df[['FCU_CVLV_DM', 'FCU_CLG_GPM', 'FCU_CVLV', 'FCU_CLG_RWT']]\n",
    "c_FCU = pivoted_df[['FCU_RA_HUMD', 'FCU_DA_HUMD', 'FCU_RAT', 'FCU_MAT', 'FCU_OAT', 'FCU_OA_CFM', 'FCU_CTRL', 'FCU_DAT', 'FCU_DA_CFM', 'FCU_MA_HUMD', 'FCU_OA_HUMD']]\n",
    "c_heating_coil = pivoted_df[['FCU_HVLV_DM', 'FCU_HVLV', 'FCU_HTG_GPM', 'FCU_HTG_RWT']]\n",
    "c_supply_air = pivoted_df[['FCU_WAT', 'FCU_SPD']]\n",
    "c_zone = pivoted_df[['RMCLGSPT', 'RM_TEMP', 'RMHTGSPT']]\n",
    "c_all = pivoted_df.copy()\n",
    "\n",
    "# Initialize the containers\n",
    "X_train_full_scaled = {}\n",
    "X_val_full_scaled = {}\n",
    "X_train_full_unscaled = {}\n",
    "X_val_full_unscaled = {}\n",
    "clusters = [c_cooling_coil, c_FCU, c_heating_coil, c_supply_air, c_zone, c_all]\n",
    "\n",
    "# Iterate over the clusters\n",
    "for i, cluster in enumerate(clusters):\n",
    "    X_train_full_scaled[i], X_val_full_scaled[i], X_train_full_unscaled[i], X_val_full_unscaled[i] = split_scale(cluster, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f7840a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FCU_CVLV_DM</th>\n",
       "      <th>FCU_CLG_GPM</th>\n",
       "      <th>FCU_CVLV</th>\n",
       "      <th>FCU_CLG_RWT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>54.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:10:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>54.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:20:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>53.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:30:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>53.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:40:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>53.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 13:30:00</th>\n",
       "      <td>0.230</td>\n",
       "      <td>1.079</td>\n",
       "      <td>0.230</td>\n",
       "      <td>63.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 13:40:00</th>\n",
       "      <td>0.230</td>\n",
       "      <td>1.095</td>\n",
       "      <td>0.230</td>\n",
       "      <td>63.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 13:50:00</th>\n",
       "      <td>0.235</td>\n",
       "      <td>1.118</td>\n",
       "      <td>0.235</td>\n",
       "      <td>63.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:00:00</th>\n",
       "      <td>0.240</td>\n",
       "      <td>1.141</td>\n",
       "      <td>0.240</td>\n",
       "      <td>63.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:10:00</th>\n",
       "      <td>0.240</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.240</td>\n",
       "      <td>63.514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24422 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FCU_CVLV_DM  FCU_CLG_GPM  FCU_CVLV  FCU_CLG_RWT\n",
       "Datetime                                                            \n",
       "2018-02-01 00:00:00        0.000        0.000     0.000       54.652\n",
       "2018-02-01 00:10:00        0.000        0.000     0.000       54.284\n",
       "2018-02-01 00:20:00        0.000        0.000     0.000       53.912\n",
       "2018-02-01 00:30:00        0.000        0.000     0.000       53.535\n",
       "2018-02-01 00:40:00        0.000        0.000     0.000       53.155\n",
       "...                          ...          ...       ...          ...\n",
       "2018-07-20 13:30:00        0.230        1.079     0.230       63.779\n",
       "2018-07-20 13:40:00        0.230        1.095     0.230       63.745\n",
       "2018-07-20 13:50:00        0.235        1.118     0.235       63.675\n",
       "2018-07-20 14:00:00        0.240        1.141     0.240       63.592\n",
       "2018-07-20 14:10:00        0.240        1.163     0.240       63.514\n",
       "\n",
       "[24422 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full_unscaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b85c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_3d(data, window_size, stride):\n",
    "    \"\"\"\n",
    "    Converts a long time series [1, T, F] into [N, window_size, F]\n",
    "    \"\"\"\n",
    "    data = data.squeeze(0)  # [T, F]\n",
    "    total_steps, n_features = data.shape\n",
    "    windows = []\n",
    "\n",
    "    for i in range(0, total_steps - window_size + 1, stride):\n",
    "        window = data[i:i+window_size]\n",
    "        windows.append(window)\n",
    "\n",
    "    return np.stack(windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cef39d",
   "metadata": {},
   "source": [
    "### Introduce MCAR Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10cc076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FCU_HVLV_DM</th>\n",
       "      <th>FCU_HVLV</th>\n",
       "      <th>FCU_HTG_GPM</th>\n",
       "      <th>FCU_HTG_RWT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:20:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158043</td>\n",
       "      <td>-0.096195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158043</td>\n",
       "      <td>-0.098679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:40:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158043</td>\n",
       "      <td>-0.101535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:50:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158043</td>\n",
       "      <td>-0.104889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 15:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158043</td>\n",
       "      <td>-0.109360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:10:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158043</td>\n",
       "      <td>0.763521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:20:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158043</td>\n",
       "      <td>0.777432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158043</td>\n",
       "      <td>0.788237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:40:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158043</td>\n",
       "      <td>0.795441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:50:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.158043</td>\n",
       "      <td>0.799415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6106 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FCU_HVLV_DM  FCU_HVLV  FCU_HTG_GPM  FCU_HTG_RWT\n",
       "Datetime                                                            \n",
       "2018-07-20 14:20:00          0.0       0.0    -0.158043    -0.096195\n",
       "2018-07-20 14:30:00          0.0       0.0    -0.158043    -0.098679\n",
       "2018-07-20 14:40:00          0.0       0.0    -0.158043    -0.101535\n",
       "2018-07-20 14:50:00          0.0       0.0    -0.158043    -0.104889\n",
       "2018-07-20 15:00:00          0.0       0.0    -0.158043    -0.109360\n",
       "...                          ...       ...          ...          ...\n",
       "2018-08-31 23:10:00          0.0       0.0    -0.158043     0.763521\n",
       "2018-08-31 23:20:00          0.0       0.0    -0.158043     0.777432\n",
       "2018-08-31 23:30:00          0.0       0.0    -0.158043     0.788237\n",
       "2018-08-31 23:40:00          0.0       0.0    -0.158043     0.795441\n",
       "2018-08-31 23:50:00          0.0       0.0    -0.158043     0.799415\n",
       "\n",
       "[6106 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_full_scaled[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d71795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing 5.0% missingness for cluster 0 with key 5\n",
      "Introducing 20.0% missingness for cluster 0 with key 20\n",
      "Introducing 60.0% missingness for cluster 0 with key 60\n",
      "Introducing 90.0% missingness for cluster 0 with key 90\n",
      "Introducing 5.0% missingness for cluster 1 with key 5\n",
      "Introducing 20.0% missingness for cluster 1 with key 20\n",
      "Introducing 60.0% missingness for cluster 1 with key 60\n",
      "Introducing 90.0% missingness for cluster 1 with key 90\n",
      "Introducing 5.0% missingness for cluster 2 with key 5\n",
      "Introducing 20.0% missingness for cluster 2 with key 20\n",
      "Introducing 60.0% missingness for cluster 2 with key 60\n",
      "Introducing 90.0% missingness for cluster 2 with key 90\n",
      "Introducing 5.0% missingness for cluster 3 with key 5\n",
      "Introducing 20.0% missingness for cluster 3 with key 20\n",
      "Introducing 60.0% missingness for cluster 3 with key 60\n",
      "Introducing 90.0% missingness for cluster 3 with key 90\n",
      "Introducing 5.0% missingness for cluster 4 with key 5\n",
      "Introducing 20.0% missingness for cluster 4 with key 20\n",
      "Introducing 60.0% missingness for cluster 4 with key 60\n",
      "Introducing 90.0% missingness for cluster 4 with key 90\n",
      "Introducing 5.0% missingness for cluster 5 with key 5\n",
      "Introducing 20.0% missingness for cluster 5 with key 20\n",
      "Introducing 60.0% missingness for cluster 5 with key 60\n",
      "Introducing 90.0% missingness for cluster 5 with key 90\n"
     ]
    }
   ],
   "source": [
    "from pygrinder import mcar\n",
    "\n",
    "missing_rates = [0.05, 0.2, 0.6, 0.90]\n",
    "\n",
    "# Training and validation sets for each cluster\n",
    "X_train_incomplete = {}\n",
    "X_val_incomplete = {}\n",
    "train_masks = {}\n",
    "val_masks = {}\n",
    "X_train_seq = {}\n",
    "X_val_seq = {}\n",
    "train_masks_seq = {}\n",
    "val_masks_seq = {}\n",
    "\n",
    "# Full tensors for each cluster\n",
    "X_train_full_tensor = {}\n",
    "X_val_full_tensor = {}\n",
    "X_val_full_seq = {}\n",
    "X_train_full_seq = {}\n",
    "X_train_full_unscaled_seq_tensor = {}\n",
    "X_val_full_unscaled_seq_tensor = {}\n",
    "\n",
    "n_steps = 504  # 3.5 days each window\n",
    "stride = 144  # 1 day stride\n",
    "\n",
    "for cluster_id, flow_cluster in enumerate(clusters):\n",
    "    X_train_incomplete[cluster_id] = {}\n",
    "    X_val_incomplete[cluster_id] = {}\n",
    "    train_masks[cluster_id] = {}\n",
    "    val_masks[cluster_id] = {}\n",
    "    X_train_seq[cluster_id] = {}\n",
    "    X_val_seq[cluster_id] = {}\n",
    "    train_masks_seq[cluster_id] = {}\n",
    "    val_masks_seq[cluster_id] = {}\n",
    "\n",
    "\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        # Introduce missingness per cluster & rate\n",
    "        print(f\"Introducing {rate*100}% missingness for cluster {cluster_id} with key {key}\")\n",
    "        X_train_incomplete[cluster_id][key] = mcar(X_train_full_scaled[cluster_id].values, p=rate)\n",
    "        X_val_incomplete[cluster_id][key] = mcar(X_val_full_scaled[cluster_id].values, p=rate)\n",
    "\n",
    "        # Masks for missingness\n",
    "        train_masks[cluster_id][key] = np.isnan(X_train_incomplete[cluster_id][key])\n",
    "        val_masks[cluster_id][key] = np.isnan(X_val_incomplete[cluster_id][key])\n",
    "\n",
    "        # Expand dims for batch axis (needed for sliding window)\n",
    "        X_train_tensor = np.expand_dims(X_train_incomplete[cluster_id][key], axis=0)\n",
    "        X_val_tensor = np.expand_dims(X_val_incomplete[cluster_id][key], axis=0)\n",
    "        train_mask_tensor = np.expand_dims(train_masks[cluster_id][key], axis=0)\n",
    "        val_mask_tensor = np.expand_dims(val_masks[cluster_id][key], axis=0)\n",
    "\n",
    "        # Sliding window on data\n",
    "        X_train_seq[cluster_id][key] = sliding_window_3d(X_train_tensor, window_size=n_steps, stride=stride)\n",
    "        X_val_seq[cluster_id][key] = sliding_window_3d(X_val_tensor, window_size=n_steps, stride=stride)\n",
    "\n",
    "        # Sliding window on masks\n",
    "        train_masks_seq[cluster_id][key] = sliding_window_3d(train_mask_tensor, window_size=n_steps, stride=stride)\n",
    "        val_masks_seq[cluster_id][key] = sliding_window_3d(val_mask_tensor, window_size=n_steps, stride=stride)\n",
    "\n",
    "\n",
    "    # Expand full training tensors\n",
    "    X_train_full_tensor[cluster_id] = np.expand_dims(X_train_full_scaled[cluster_id].values, axis = 0)\n",
    "\n",
    "    # Expand full validation tensors\n",
    "    X_val_full_tensor[cluster_id] = np.expand_dims(X_val_full_scaled[cluster_id].values, axis = 0)\n",
    "\n",
    "    # Convert scaled data to tensor\n",
    "    X_val_full_seq[cluster_id] = sliding_window_3d(X_val_full_tensor[cluster_id], window_size=n_steps, stride=stride)\n",
    "    X_train_full_seq[cluster_id] = sliding_window_3d(X_train_full_tensor[cluster_id], window_size=n_steps, stride=stride)\n",
    "\n",
    "    # Convert unscaled data to tensor\n",
    "    X_train_full_unscaled_values = np.expand_dims(X_train_full_unscaled[cluster_id].values, axis=0)\n",
    "    X_train_full_unscaled_seq_tensor[cluster_id] = sliding_window_3d(X_train_full_unscaled_values, window_size=n_steps, stride=stride)\n",
    "\n",
    "    X_val_full_unscaled_values = np.expand_dims(X_val_full_unscaled[cluster_id].values, axis=0)\n",
    "    X_val_full_unscaled_seq_tensor[cluster_id] = sliding_window_3d(X_val_full_unscaled_values, window_size=n_steps, stride=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "363a2503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([5, 20, 60, 90])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_incomplete[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 percent missing\n",
    "train_data, val_data = {}, {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    train_data[cluster_id] = {}\n",
    "    val_data[cluster_id] = {}\n",
    "    \n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        \n",
    "        # Prepare the train and validation data dictionaries for each missing rate\n",
    "        train_data[cluster_id][key] = {\"X\": X_train_seq[cluster_id][key]}\n",
    "        val_data[cluster_id][key] = {\"X\": X_val_seq[cluster_id][key], \"X_ori\": X_val_full_seq[cluster_id]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222cb3dd",
   "metadata": {},
   "source": [
    "### BRITS Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f544ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pypots.imputation import BRITS\n",
    "from pypots.nn.modules.loss import MAE, MSE\n",
    "from pypots.optim.adam import Adam\n",
    "import torch\n",
    "\n",
    "def intialize_BRITS(n_steps, num_features, rnn_hidden_size):\n",
    "\n",
    "    # Basic configuration\n",
    "    model = BRITS(\n",
    "        n_steps=n_steps,\n",
    "        n_features=num_features,\n",
    "        rnn_hidden_size=rnn_hidden_size,               # Reasonable hidden size\n",
    "        batch_size=32,                    # Standard for most datasets\n",
    "        epochs=25,                       # Higher epochs for better convergence\n",
    "        patience=5,                      # Early stopping if no improvement\n",
    "        training_loss=MAE,                # MAE often performs well for imputation\n",
    "        validation_metric=MSE,           # Use MSE for validation comparison\n",
    "        optimizer=Adam,                   # Adam optimizer (default)\n",
    "        num_workers=0,                    # Adjust if using DataLoader with multiprocessing\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # Use GPU if available\n",
    "        saving_path=\"./brits_model\",     # Directory to save model checkpoints\n",
    "        model_saving_strategy=\"best\",    # Save best model only\n",
    "        verbose=True                      # Print training progress\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ab868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 20:42:01 [INFO]: Using the given device: cpu\n",
      "2025-06-23 20:42:01 [INFO]: Model files will be saved to ./brits_model\\20250623_T204201\n",
      "2025-06-23 20:42:01 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T204201\\tensorboard\n",
      "2025-06-23 20:42:01 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 20:42:01 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 20:42:01 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 0...\n",
      "Training model for missing rate 0.05 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 20:42:14 [INFO]: Epoch 001 - training loss (MAE): 0.9914, validation MSE: 1.3307\n",
      "2025-06-23 20:42:22 [INFO]: Epoch 002 - training loss (MAE): 0.9702, validation MSE: 1.3166\n",
      "2025-06-23 20:42:30 [INFO]: Epoch 003 - training loss (MAE): 0.9157, validation MSE: 1.3025\n",
      "2025-06-23 20:42:39 [INFO]: Epoch 004 - training loss (MAE): 0.8973, validation MSE: 1.2894\n",
      "2025-06-23 20:42:47 [INFO]: Epoch 005 - training loss (MAE): 0.8623, validation MSE: 1.2734\n",
      "2025-06-23 20:42:56 [INFO]: Epoch 006 - training loss (MAE): 0.8256, validation MSE: 1.2548\n",
      "2025-06-23 20:43:04 [INFO]: Epoch 007 - training loss (MAE): 0.8366, validation MSE: 1.2356\n",
      "2025-06-23 20:43:13 [INFO]: Epoch 008 - training loss (MAE): 0.8363, validation MSE: 1.2101\n",
      "2025-06-23 20:43:21 [INFO]: Epoch 009 - training loss (MAE): 0.7946, validation MSE: 1.1785\n",
      "2025-06-23 20:43:29 [INFO]: Epoch 010 - training loss (MAE): 0.7607, validation MSE: 1.1450\n",
      "2025-06-23 20:43:38 [INFO]: Epoch 011 - training loss (MAE): 0.7353, validation MSE: 1.1092\n",
      "2025-06-23 20:43:46 [INFO]: Epoch 012 - training loss (MAE): 0.7260, validation MSE: 1.0677\n",
      "2025-06-23 20:43:55 [INFO]: Epoch 013 - training loss (MAE): 0.7345, validation MSE: 1.0223\n",
      "2025-06-23 20:44:03 [INFO]: Epoch 014 - training loss (MAE): 0.6887, validation MSE: 0.9722\n",
      "2025-06-23 20:44:12 [INFO]: Epoch 015 - training loss (MAE): 0.6889, validation MSE: 0.9186\n",
      "2025-06-23 20:44:20 [INFO]: Epoch 016 - training loss (MAE): 0.6446, validation MSE: 0.8637\n",
      "2025-06-23 20:44:29 [INFO]: Epoch 017 - training loss (MAE): 0.6243, validation MSE: 0.8149\n",
      "2025-06-23 20:44:37 [INFO]: Epoch 018 - training loss (MAE): 0.6260, validation MSE: 0.7734\n",
      "2025-06-23 20:44:46 [INFO]: Epoch 019 - training loss (MAE): 0.6305, validation MSE: 0.7334\n",
      "2025-06-23 20:44:55 [INFO]: Epoch 020 - training loss (MAE): 0.5747, validation MSE: 0.6914\n",
      "2025-06-23 20:45:03 [INFO]: Epoch 021 - training loss (MAE): 0.5382, validation MSE: 0.6539\n",
      "2025-06-23 20:45:11 [INFO]: Epoch 022 - training loss (MAE): 0.5324, validation MSE: 0.6188\n",
      "2025-06-23 20:45:20 [INFO]: Epoch 023 - training loss (MAE): 0.5205, validation MSE: 0.5833\n",
      "2025-06-23 20:45:28 [INFO]: Epoch 024 - training loss (MAE): 0.5012, validation MSE: 0.5467\n",
      "2025-06-23 20:45:37 [INFO]: Epoch 025 - training loss (MAE): 0.5057, validation MSE: 0.5143\n",
      "2025-06-23 20:45:37 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 20:45:37 [INFO]: Saved the model to ./brits_model\\20250623_T204201\\BRITS.pypots\n",
      "2025-06-23 20:45:37 [INFO]: Using the given device: cpu\n",
      "2025-06-23 20:45:37 [INFO]: Model files will be saved to ./brits_model\\20250623_T204537\n",
      "2025-06-23 20:45:37 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T204537\\tensorboard\n",
      "2025-06-23 20:45:37 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 20:45:37 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 20:45:37 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 20:45:49 [INFO]: Epoch 001 - training loss (MAE): 0.9502, validation MSE: 1.4709\n",
      "2025-06-23 20:45:58 [INFO]: Epoch 002 - training loss (MAE): 0.9038, validation MSE: 1.4606\n",
      "2025-06-23 20:46:06 [INFO]: Epoch 003 - training loss (MAE): 0.8969, validation MSE: 1.4502\n",
      "2025-06-23 20:46:14 [INFO]: Epoch 004 - training loss (MAE): 0.8807, validation MSE: 1.4391\n",
      "2025-06-23 20:46:23 [INFO]: Epoch 005 - training loss (MAE): 0.8632, validation MSE: 1.4278\n",
      "2025-06-23 20:46:31 [INFO]: Epoch 006 - training loss (MAE): 0.8436, validation MSE: 1.4158\n",
      "2025-06-23 20:46:41 [INFO]: Epoch 007 - training loss (MAE): 0.8137, validation MSE: 1.4037\n",
      "2025-06-23 20:46:51 [INFO]: Epoch 008 - training loss (MAE): 0.7826, validation MSE: 1.3908\n",
      "2025-06-23 20:47:00 [INFO]: Epoch 009 - training loss (MAE): 0.7600, validation MSE: 1.3728\n",
      "2025-06-23 20:47:10 [INFO]: Epoch 010 - training loss (MAE): 0.7318, validation MSE: 1.3465\n",
      "2025-06-23 20:47:20 [INFO]: Epoch 011 - training loss (MAE): 0.7371, validation MSE: 1.3125\n",
      "2025-06-23 20:47:30 [INFO]: Epoch 012 - training loss (MAE): 0.6912, validation MSE: 1.2710\n",
      "2025-06-23 20:47:40 [INFO]: Epoch 013 - training loss (MAE): 0.7120, validation MSE: 1.2278\n",
      "2025-06-23 20:47:50 [INFO]: Epoch 014 - training loss (MAE): 0.6636, validation MSE: 1.1861\n",
      "2025-06-23 20:47:59 [INFO]: Epoch 015 - training loss (MAE): 0.6319, validation MSE: 1.1460\n",
      "2025-06-23 20:48:17 [INFO]: Epoch 016 - training loss (MAE): 0.6228, validation MSE: 1.1071\n",
      "2025-06-23 20:48:37 [INFO]: Epoch 017 - training loss (MAE): 0.6018, validation MSE: 1.0700\n",
      "2025-06-23 20:48:56 [INFO]: Epoch 018 - training loss (MAE): 0.5867, validation MSE: 1.0395\n",
      "2025-06-23 20:49:16 [INFO]: Epoch 019 - training loss (MAE): 0.5609, validation MSE: 1.0088\n",
      "2025-06-23 20:49:35 [INFO]: Epoch 020 - training loss (MAE): 0.5477, validation MSE: 0.9762\n",
      "2025-06-23 20:49:54 [INFO]: Epoch 021 - training loss (MAE): 0.5465, validation MSE: 0.9402\n",
      "2025-06-23 20:50:13 [INFO]: Epoch 022 - training loss (MAE): 0.5247, validation MSE: 0.9028\n",
      "2025-06-23 20:50:31 [INFO]: Epoch 023 - training loss (MAE): 0.5024, validation MSE: 0.8694\n",
      "2025-06-23 20:50:49 [INFO]: Epoch 024 - training loss (MAE): 0.4855, validation MSE: 0.8407\n",
      "2025-06-23 20:51:08 [INFO]: Epoch 025 - training loss (MAE): 0.4740, validation MSE: 0.8157\n",
      "2025-06-23 20:51:08 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 20:51:08 [INFO]: Saved the model to ./brits_model\\20250623_T204537\\BRITS.pypots\n",
      "2025-06-23 20:51:08 [INFO]: Using the given device: cpu\n",
      "2025-06-23 20:51:08 [INFO]: Model files will be saved to ./brits_model\\20250623_T205108\n",
      "2025-06-23 20:51:08 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T205108\\tensorboard\n",
      "2025-06-23 20:51:08 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 20:51:08 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 20:51:08 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 20:51:37 [INFO]: Epoch 001 - training loss (MAE): 0.9592, validation MSE: 1.3651\n",
      "2025-06-23 20:51:56 [INFO]: Epoch 002 - training loss (MAE): 0.8960, validation MSE: 1.3664\n",
      "2025-06-23 20:52:14 [INFO]: Epoch 003 - training loss (MAE): 0.9011, validation MSE: 1.3677\n",
      "2025-06-23 20:52:33 [INFO]: Epoch 004 - training loss (MAE): 0.8872, validation MSE: 1.3696\n",
      "2025-06-23 20:52:52 [INFO]: Epoch 005 - training loss (MAE): 0.8378, validation MSE: 1.3716\n",
      "2025-06-23 20:53:11 [INFO]: Epoch 006 - training loss (MAE): 0.8096, validation MSE: 1.3744\n",
      "2025-06-23 20:53:11 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-06-23 20:53:11 [INFO]: Finished training. The best model is from epoch#1.\n",
      "2025-06-23 20:53:11 [INFO]: Saved the model to ./brits_model\\20250623_T205108\\BRITS.pypots\n",
      "2025-06-23 20:53:11 [INFO]: Using the given device: cpu\n",
      "2025-06-23 20:53:11 [INFO]: Model files will be saved to ./brits_model\\20250623_T205311\n",
      "2025-06-23 20:53:11 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T205311\\tensorboard\n",
      "2025-06-23 20:53:11 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 20:53:11 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 20:53:11 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.9 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 20:53:40 [INFO]: Epoch 001 - training loss (MAE): 0.9999, validation MSE: 1.4280\n",
      "2025-06-23 20:53:59 [INFO]: Epoch 002 - training loss (MAE): 0.9705, validation MSE: 1.4261\n",
      "2025-06-23 20:54:18 [INFO]: Epoch 003 - training loss (MAE): 0.9569, validation MSE: 1.4250\n",
      "2025-06-23 20:54:38 [INFO]: Epoch 004 - training loss (MAE): 0.9458, validation MSE: 1.4243\n",
      "2025-06-23 20:54:57 [INFO]: Epoch 005 - training loss (MAE): 0.9461, validation MSE: 1.4246\n",
      "2025-06-23 20:55:16 [INFO]: Epoch 006 - training loss (MAE): 0.9135, validation MSE: 1.4263\n",
      "2025-06-23 20:55:35 [INFO]: Epoch 007 - training loss (MAE): 0.8971, validation MSE: 1.4292\n",
      "2025-06-23 20:55:55 [INFO]: Epoch 008 - training loss (MAE): 0.8831, validation MSE: 1.4340\n",
      "2025-06-23 20:56:14 [INFO]: Epoch 009 - training loss (MAE): 0.8624, validation MSE: 1.4408\n",
      "2025-06-23 20:56:14 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-06-23 20:56:14 [INFO]: Finished training. The best model is from epoch#4.\n",
      "2025-06-23 20:56:14 [INFO]: Saved the model to ./brits_model\\20250623_T205311\\BRITS.pypots\n",
      "2025-06-23 20:56:14 [INFO]: Using the given device: cpu\n",
      "2025-06-23 20:56:14 [INFO]: Model files will be saved to ./brits_model\\20250623_T205614\n",
      "2025-06-23 20:56:14 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T205614\\tensorboard\n",
      "2025-06-23 20:56:14 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 20:56:14 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 20:56:14 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 1...\n",
      "Training model for missing rate 0.05 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 20:56:44 [INFO]: Epoch 001 - training loss (MAE): 1.6393, validation MSE: 1.2129\n",
      "2025-06-23 20:57:04 [INFO]: Epoch 002 - training loss (MAE): 1.6262, validation MSE: 1.1507\n",
      "2025-06-23 20:57:24 [INFO]: Epoch 003 - training loss (MAE): 1.5506, validation MSE: 1.0877\n",
      "2025-06-23 20:57:43 [INFO]: Epoch 004 - training loss (MAE): 1.4659, validation MSE: 1.0134\n",
      "2025-06-23 20:58:02 [INFO]: Epoch 005 - training loss (MAE): 1.4174, validation MSE: 0.9358\n",
      "2025-06-23 20:58:10 [INFO]: Epoch 006 - training loss (MAE): 1.3579, validation MSE: 0.8591\n",
      "2025-06-23 20:58:19 [INFO]: Epoch 007 - training loss (MAE): 1.3132, validation MSE: 0.7888\n",
      "2025-06-23 20:58:28 [INFO]: Epoch 008 - training loss (MAE): 1.2405, validation MSE: 0.7226\n",
      "2025-06-23 20:58:37 [INFO]: Epoch 009 - training loss (MAE): 1.1827, validation MSE: 0.6583\n",
      "2025-06-23 20:58:46 [INFO]: Epoch 010 - training loss (MAE): 1.1416, validation MSE: 0.5984\n",
      "2025-06-23 20:58:54 [INFO]: Epoch 011 - training loss (MAE): 1.1077, validation MSE: 0.5377\n",
      "2025-06-23 20:59:03 [INFO]: Epoch 012 - training loss (MAE): 1.0485, validation MSE: 0.4903\n",
      "2025-06-23 20:59:12 [INFO]: Epoch 013 - training loss (MAE): 1.0346, validation MSE: 0.4430\n",
      "2025-06-23 20:59:21 [INFO]: Epoch 014 - training loss (MAE): 0.9727, validation MSE: 0.4023\n",
      "2025-06-23 20:59:30 [INFO]: Epoch 015 - training loss (MAE): 0.9338, validation MSE: 0.3683\n",
      "2025-06-23 20:59:39 [INFO]: Epoch 016 - training loss (MAE): 0.9027, validation MSE: 0.3354\n",
      "2025-06-23 20:59:47 [INFO]: Epoch 017 - training loss (MAE): 0.8650, validation MSE: 0.3050\n",
      "2025-06-23 20:59:56 [INFO]: Epoch 018 - training loss (MAE): 0.8522, validation MSE: 0.2757\n",
      "2025-06-23 21:00:05 [INFO]: Epoch 019 - training loss (MAE): 0.8247, validation MSE: 0.2487\n",
      "2025-06-23 21:00:14 [INFO]: Epoch 020 - training loss (MAE): 0.7893, validation MSE: 0.2270\n",
      "2025-06-23 21:00:23 [INFO]: Epoch 021 - training loss (MAE): 0.7522, validation MSE: 0.2081\n",
      "2025-06-23 21:00:31 [INFO]: Epoch 022 - training loss (MAE): 0.7253, validation MSE: 0.1896\n",
      "2025-06-23 21:00:40 [INFO]: Epoch 023 - training loss (MAE): 0.7200, validation MSE: 0.1737\n",
      "2025-06-23 21:00:49 [INFO]: Epoch 024 - training loss (MAE): 0.6930, validation MSE: 0.1604\n",
      "2025-06-23 21:00:58 [INFO]: Epoch 025 - training loss (MAE): 0.6662, validation MSE: 0.1489\n",
      "2025-06-23 21:00:58 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:00:58 [INFO]: Saved the model to ./brits_model\\20250623_T205614\\BRITS.pypots\n",
      "2025-06-23 21:00:58 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:00:58 [INFO]: Model files will be saved to ./brits_model\\20250623_T210058\n",
      "2025-06-23 21:00:58 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T210058\\tensorboard\n",
      "2025-06-23 21:00:58 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:00:58 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:00:58 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:01:11 [INFO]: Epoch 001 - training loss (MAE): 1.6892, validation MSE: 1.2255\n",
      "2025-06-23 21:01:20 [INFO]: Epoch 002 - training loss (MAE): 1.6503, validation MSE: 1.1707\n",
      "2025-06-23 21:01:29 [INFO]: Epoch 003 - training loss (MAE): 1.5870, validation MSE: 1.1155\n",
      "2025-06-23 21:01:37 [INFO]: Epoch 004 - training loss (MAE): 1.5477, validation MSE: 1.0591\n",
      "2025-06-23 21:01:46 [INFO]: Epoch 005 - training loss (MAE): 1.4990, validation MSE: 1.0017\n",
      "2025-06-23 21:01:55 [INFO]: Epoch 006 - training loss (MAE): 1.4527, validation MSE: 0.9432\n",
      "2025-06-23 21:02:04 [INFO]: Epoch 007 - training loss (MAE): 1.3873, validation MSE: 0.8771\n",
      "2025-06-23 21:02:13 [INFO]: Epoch 008 - training loss (MAE): 1.3257, validation MSE: 0.8048\n",
      "2025-06-23 21:02:22 [INFO]: Epoch 009 - training loss (MAE): 1.2897, validation MSE: 0.7282\n",
      "2025-06-23 21:02:30 [INFO]: Epoch 010 - training loss (MAE): 1.2085, validation MSE: 0.6569\n",
      "2025-06-23 21:02:39 [INFO]: Epoch 011 - training loss (MAE): 1.1353, validation MSE: 0.5929\n",
      "2025-06-23 21:02:48 [INFO]: Epoch 012 - training loss (MAE): 1.0973, validation MSE: 0.5279\n",
      "2025-06-23 21:02:57 [INFO]: Epoch 013 - training loss (MAE): 1.0591, validation MSE: 0.4634\n",
      "2025-06-23 21:03:06 [INFO]: Epoch 014 - training loss (MAE): 1.0030, validation MSE: 0.4024\n",
      "2025-06-23 21:03:15 [INFO]: Epoch 015 - training loss (MAE): 0.9487, validation MSE: 0.3469\n",
      "2025-06-23 21:03:24 [INFO]: Epoch 016 - training loss (MAE): 0.9025, validation MSE: 0.3003\n",
      "2025-06-23 21:03:33 [INFO]: Epoch 017 - training loss (MAE): 0.8613, validation MSE: 0.2622\n",
      "2025-06-23 21:03:41 [INFO]: Epoch 018 - training loss (MAE): 0.8313, validation MSE: 0.2296\n",
      "2025-06-23 21:03:50 [INFO]: Epoch 019 - training loss (MAE): 0.7870, validation MSE: 0.2024\n",
      "2025-06-23 21:03:59 [INFO]: Epoch 020 - training loss (MAE): 0.7622, validation MSE: 0.1773\n",
      "2025-06-23 21:04:08 [INFO]: Epoch 021 - training loss (MAE): 0.7263, validation MSE: 0.1597\n",
      "2025-06-23 21:04:17 [INFO]: Epoch 022 - training loss (MAE): 0.7168, validation MSE: 0.1462\n",
      "2025-06-23 21:04:26 [INFO]: Epoch 023 - training loss (MAE): 0.6755, validation MSE: 0.1338\n",
      "2025-06-23 21:04:35 [INFO]: Epoch 024 - training loss (MAE): 0.6703, validation MSE: 0.1250\n",
      "2025-06-23 21:04:44 [INFO]: Epoch 025 - training loss (MAE): 0.6486, validation MSE: 0.1182\n",
      "2025-06-23 21:04:44 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:04:44 [INFO]: Saved the model to ./brits_model\\20250623_T210058\\BRITS.pypots\n",
      "2025-06-23 21:04:44 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:04:44 [INFO]: Model files will be saved to ./brits_model\\20250623_T210444\n",
      "2025-06-23 21:04:44 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T210444\\tensorboard\n",
      "2025-06-23 21:04:44 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:04:44 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:04:44 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:04:56 [INFO]: Epoch 001 - training loss (MAE): 1.6000, validation MSE: 1.1332\n",
      "2025-06-23 21:05:05 [INFO]: Epoch 002 - training loss (MAE): 1.5574, validation MSE: 1.0929\n",
      "2025-06-23 21:05:14 [INFO]: Epoch 003 - training loss (MAE): 1.5220, validation MSE: 1.0499\n",
      "2025-06-23 21:05:23 [INFO]: Epoch 004 - training loss (MAE): 1.5068, validation MSE: 1.0016\n",
      "2025-06-23 21:05:34 [INFO]: Epoch 005 - training loss (MAE): 1.4516, validation MSE: 0.9452\n",
      "2025-06-23 21:05:44 [INFO]: Epoch 006 - training loss (MAE): 1.4107, validation MSE: 0.8910\n",
      "2025-06-23 21:05:54 [INFO]: Epoch 007 - training loss (MAE): 1.3761, validation MSE: 0.8433\n",
      "2025-06-23 21:06:05 [INFO]: Epoch 008 - training loss (MAE): 1.3200, validation MSE: 0.7989\n",
      "2025-06-23 21:06:15 [INFO]: Epoch 009 - training loss (MAE): 1.2918, validation MSE: 0.7574\n",
      "2025-06-23 21:06:25 [INFO]: Epoch 010 - training loss (MAE): 1.2269, validation MSE: 0.7194\n",
      "2025-06-23 21:06:35 [INFO]: Epoch 011 - training loss (MAE): 1.1874, validation MSE: 0.6888\n",
      "2025-06-23 21:06:46 [INFO]: Epoch 012 - training loss (MAE): 1.1502, validation MSE: 0.6621\n",
      "2025-06-23 21:06:56 [INFO]: Epoch 013 - training loss (MAE): 1.1700, validation MSE: 0.6261\n",
      "2025-06-23 21:07:06 [INFO]: Epoch 014 - training loss (MAE): 1.1016, validation MSE: 0.5922\n",
      "2025-06-23 21:07:16 [INFO]: Epoch 015 - training loss (MAE): 1.0842, validation MSE: 0.5589\n",
      "2025-06-23 21:07:27 [INFO]: Epoch 016 - training loss (MAE): 1.0260, validation MSE: 0.5228\n",
      "2025-06-23 21:07:37 [INFO]: Epoch 017 - training loss (MAE): 1.0012, validation MSE: 0.4897\n",
      "2025-06-23 21:07:47 [INFO]: Epoch 018 - training loss (MAE): 0.9555, validation MSE: 0.4555\n",
      "2025-06-23 21:07:57 [INFO]: Epoch 019 - training loss (MAE): 0.9383, validation MSE: 0.4176\n",
      "2025-06-23 21:08:07 [INFO]: Epoch 020 - training loss (MAE): 0.9005, validation MSE: 0.3745\n",
      "2025-06-23 21:08:18 [INFO]: Epoch 021 - training loss (MAE): 0.8766, validation MSE: 0.3354\n",
      "2025-06-23 21:08:28 [INFO]: Epoch 022 - training loss (MAE): 0.8265, validation MSE: 0.3008\n",
      "2025-06-23 21:08:38 [INFO]: Epoch 023 - training loss (MAE): 0.7983, validation MSE: 0.2708\n",
      "2025-06-23 21:08:48 [INFO]: Epoch 024 - training loss (MAE): 0.8048, validation MSE: 0.2449\n",
      "2025-06-23 21:08:59 [INFO]: Epoch 025 - training loss (MAE): 0.7587, validation MSE: 0.2244\n",
      "2025-06-23 21:08:59 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:08:59 [INFO]: Saved the model to ./brits_model\\20250623_T210444\\BRITS.pypots\n",
      "2025-06-23 21:08:59 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:08:59 [INFO]: Model files will be saved to ./brits_model\\20250623_T210859\n",
      "2025-06-23 21:08:59 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T210859\\tensorboard\n",
      "2025-06-23 21:08:59 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:08:59 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:08:59 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.9 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:09:14 [INFO]: Epoch 001 - training loss (MAE): 1.6073, validation MSE: 1.1187\n",
      "2025-06-23 21:09:24 [INFO]: Epoch 002 - training loss (MAE): 1.5613, validation MSE: 1.0983\n",
      "2025-06-23 21:09:34 [INFO]: Epoch 003 - training loss (MAE): 1.5705, validation MSE: 1.0776\n",
      "2025-06-23 21:09:44 [INFO]: Epoch 004 - training loss (MAE): 1.5430, validation MSE: 1.0557\n",
      "2025-06-23 21:09:54 [INFO]: Epoch 005 - training loss (MAE): 1.5392, validation MSE: 1.0311\n",
      "2025-06-23 21:10:04 [INFO]: Epoch 006 - training loss (MAE): 1.5004, validation MSE: 1.0000\n",
      "2025-06-23 21:10:15 [INFO]: Epoch 007 - training loss (MAE): 1.4803, validation MSE: 0.9610\n",
      "2025-06-23 21:10:25 [INFO]: Epoch 008 - training loss (MAE): 1.4497, validation MSE: 0.9151\n",
      "2025-06-23 21:10:35 [INFO]: Epoch 009 - training loss (MAE): 1.3898, validation MSE: 0.8682\n",
      "2025-06-23 21:10:45 [INFO]: Epoch 010 - training loss (MAE): 1.3525, validation MSE: 0.8197\n",
      "2025-06-23 21:10:55 [INFO]: Epoch 011 - training loss (MAE): 1.3200, validation MSE: 0.7750\n",
      "2025-06-23 21:11:05 [INFO]: Epoch 012 - training loss (MAE): 1.2930, validation MSE: 0.7417\n",
      "2025-06-23 21:11:15 [INFO]: Epoch 013 - training loss (MAE): 1.2906, validation MSE: 0.7065\n",
      "2025-06-23 21:11:26 [INFO]: Epoch 014 - training loss (MAE): 1.2617, validation MSE: 0.6758\n",
      "2025-06-23 21:11:36 [INFO]: Epoch 015 - training loss (MAE): 1.2473, validation MSE: 0.6526\n",
      "2025-06-23 21:11:46 [INFO]: Epoch 016 - training loss (MAE): 1.1882, validation MSE: 0.6421\n",
      "2025-06-23 21:11:56 [INFO]: Epoch 017 - training loss (MAE): 1.1888, validation MSE: 0.6270\n",
      "2025-06-23 21:12:06 [INFO]: Epoch 018 - training loss (MAE): 1.1764, validation MSE: 0.6228\n",
      "2025-06-23 21:12:16 [INFO]: Epoch 019 - training loss (MAE): 1.1467, validation MSE: 0.6013\n",
      "2025-06-23 21:12:26 [INFO]: Epoch 020 - training loss (MAE): 1.1316, validation MSE: 0.5680\n",
      "2025-06-23 21:12:36 [INFO]: Epoch 021 - training loss (MAE): 1.1220, validation MSE: 0.5520\n",
      "2025-06-23 21:12:46 [INFO]: Epoch 022 - training loss (MAE): 1.1122, validation MSE: 0.5409\n",
      "2025-06-23 21:12:57 [INFO]: Epoch 023 - training loss (MAE): 1.0669, validation MSE: 0.5317\n",
      "2025-06-23 21:13:07 [INFO]: Epoch 024 - training loss (MAE): 1.0427, validation MSE: 0.5151\n",
      "2025-06-23 21:13:18 [INFO]: Epoch 025 - training loss (MAE): 1.0648, validation MSE: 0.5143\n",
      "2025-06-23 21:13:18 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:13:18 [INFO]: Saved the model to ./brits_model\\20250623_T210859\\BRITS.pypots\n",
      "2025-06-23 21:13:18 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:13:18 [INFO]: Model files will be saved to ./brits_model\\20250623_T211318\n",
      "2025-06-23 21:13:18 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T211318\\tensorboard\n",
      "2025-06-23 21:13:18 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:13:18 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:13:18 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 2...\n",
      "Training model for missing rate 0.05 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:13:34 [INFO]: Epoch 001 - training loss (MAE): 0.7473, validation MSE: 0.3675\n",
      "2025-06-23 21:13:44 [INFO]: Epoch 002 - training loss (MAE): 0.7249, validation MSE: 0.3576\n",
      "2025-06-23 21:13:53 [INFO]: Epoch 003 - training loss (MAE): 0.6897, validation MSE: 0.3484\n",
      "2025-06-23 21:14:03 [INFO]: Epoch 004 - training loss (MAE): 0.6849, validation MSE: 0.3378\n",
      "2025-06-23 21:14:13 [INFO]: Epoch 005 - training loss (MAE): 0.6602, validation MSE: 0.3244\n",
      "2025-06-23 21:14:23 [INFO]: Epoch 006 - training loss (MAE): 0.6221, validation MSE: 0.3091\n",
      "2025-06-23 21:14:33 [INFO]: Epoch 007 - training loss (MAE): 0.6402, validation MSE: 0.2945\n",
      "2025-06-23 21:14:43 [INFO]: Epoch 008 - training loss (MAE): 0.6006, validation MSE: 0.2794\n",
      "2025-06-23 21:14:53 [INFO]: Epoch 009 - training loss (MAE): 0.5887, validation MSE: 0.2640\n",
      "2025-06-23 21:15:03 [INFO]: Epoch 010 - training loss (MAE): 0.5611, validation MSE: 0.2431\n",
      "2025-06-23 21:15:13 [INFO]: Epoch 011 - training loss (MAE): 0.5739, validation MSE: 0.2144\n",
      "2025-06-23 21:15:22 [INFO]: Epoch 012 - training loss (MAE): 0.5346, validation MSE: 0.1823\n",
      "2025-06-23 21:15:32 [INFO]: Epoch 013 - training loss (MAE): 0.5156, validation MSE: 0.1534\n",
      "2025-06-23 21:15:42 [INFO]: Epoch 014 - training loss (MAE): 0.5314, validation MSE: 0.1348\n",
      "2025-06-23 21:15:52 [INFO]: Epoch 015 - training loss (MAE): 0.4622, validation MSE: 0.1219\n",
      "2025-06-23 21:16:02 [INFO]: Epoch 016 - training loss (MAE): 0.4647, validation MSE: 0.1136\n",
      "2025-06-23 21:16:11 [INFO]: Epoch 017 - training loss (MAE): 0.4544, validation MSE: 0.1062\n",
      "2025-06-23 21:16:21 [INFO]: Epoch 018 - training loss (MAE): 0.4404, validation MSE: 0.0944\n",
      "2025-06-23 21:16:31 [INFO]: Epoch 019 - training loss (MAE): 0.4391, validation MSE: 0.0829\n",
      "2025-06-23 21:16:41 [INFO]: Epoch 020 - training loss (MAE): 0.4318, validation MSE: 0.0714\n",
      "2025-06-23 21:16:51 [INFO]: Epoch 021 - training loss (MAE): 0.3862, validation MSE: 0.0616\n",
      "2025-06-23 21:17:00 [INFO]: Epoch 022 - training loss (MAE): 0.3915, validation MSE: 0.0532\n",
      "2025-06-23 21:17:10 [INFO]: Epoch 023 - training loss (MAE): 0.3842, validation MSE: 0.0445\n",
      "2025-06-23 21:17:20 [INFO]: Epoch 024 - training loss (MAE): 0.3904, validation MSE: 0.0376\n",
      "2025-06-23 21:17:30 [INFO]: Epoch 025 - training loss (MAE): 0.3589, validation MSE: 0.0303\n",
      "2025-06-23 21:17:30 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:17:30 [INFO]: Saved the model to ./brits_model\\20250623_T211318\\BRITS.pypots\n",
      "2025-06-23 21:17:30 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:17:30 [INFO]: Model files will be saved to ./brits_model\\20250623_T211730\n",
      "2025-06-23 21:17:30 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T211730\\tensorboard\n",
      "2025-06-23 21:17:30 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:17:30 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:17:30 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:17:45 [INFO]: Epoch 001 - training loss (MAE): 0.8289, validation MSE: 0.3469\n",
      "2025-06-23 21:17:54 [INFO]: Epoch 002 - training loss (MAE): 0.7889, validation MSE: 0.3366\n",
      "2025-06-23 21:18:04 [INFO]: Epoch 003 - training loss (MAE): 0.7815, validation MSE: 0.3264\n",
      "2025-06-23 21:18:14 [INFO]: Epoch 004 - training loss (MAE): 0.7201, validation MSE: 0.3169\n",
      "2025-06-23 21:18:24 [INFO]: Epoch 005 - training loss (MAE): 0.7878, validation MSE: 0.3082\n",
      "2025-06-23 21:18:34 [INFO]: Epoch 006 - training loss (MAE): 0.6958, validation MSE: 0.2999\n",
      "2025-06-23 21:18:44 [INFO]: Epoch 007 - training loss (MAE): 0.6750, validation MSE: 0.2932\n",
      "2025-06-23 21:18:54 [INFO]: Epoch 008 - training loss (MAE): 0.6643, validation MSE: 0.2882\n",
      "2025-06-23 21:19:03 [INFO]: Epoch 009 - training loss (MAE): 0.6369, validation MSE: 0.2801\n",
      "2025-06-23 21:19:13 [INFO]: Epoch 010 - training loss (MAE): 0.6121, validation MSE: 0.2695\n",
      "2025-06-23 21:19:23 [INFO]: Epoch 011 - training loss (MAE): 0.6399, validation MSE: 0.2566\n",
      "2025-06-23 21:19:33 [INFO]: Epoch 012 - training loss (MAE): 0.5995, validation MSE: 0.2393\n",
      "2025-06-23 21:19:43 [INFO]: Epoch 013 - training loss (MAE): 0.5836, validation MSE: 0.2154\n",
      "2025-06-23 21:19:52 [INFO]: Epoch 014 - training loss (MAE): 0.5441, validation MSE: 0.1871\n",
      "2025-06-23 21:20:02 [INFO]: Epoch 015 - training loss (MAE): 0.5307, validation MSE: 0.1566\n",
      "2025-06-23 21:20:12 [INFO]: Epoch 016 - training loss (MAE): 0.4886, validation MSE: 0.1315\n",
      "2025-06-23 21:20:22 [INFO]: Epoch 017 - training loss (MAE): 0.5433, validation MSE: 0.1193\n",
      "2025-06-23 21:20:32 [INFO]: Epoch 018 - training loss (MAE): 0.4692, validation MSE: 0.1112\n",
      "2025-06-23 21:20:42 [INFO]: Epoch 019 - training loss (MAE): 0.4623, validation MSE: 0.1021\n",
      "2025-06-23 21:20:52 [INFO]: Epoch 020 - training loss (MAE): 0.4501, validation MSE: 0.0880\n",
      "2025-06-23 21:21:02 [INFO]: Epoch 021 - training loss (MAE): 0.4344, validation MSE: 0.0750\n",
      "2025-06-23 21:21:11 [INFO]: Epoch 022 - training loss (MAE): 0.4507, validation MSE: 0.0641\n",
      "2025-06-23 21:21:21 [INFO]: Epoch 023 - training loss (MAE): 0.4374, validation MSE: 0.0579\n",
      "2025-06-23 21:21:31 [INFO]: Epoch 024 - training loss (MAE): 0.4166, validation MSE: 0.0502\n",
      "2025-06-23 21:21:41 [INFO]: Epoch 025 - training loss (MAE): 0.4328, validation MSE: 0.0441\n",
      "2025-06-23 21:21:41 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:21:41 [INFO]: Saved the model to ./brits_model\\20250623_T211730\\BRITS.pypots\n",
      "2025-06-23 21:21:41 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:21:41 [INFO]: Model files will be saved to ./brits_model\\20250623_T212141\n",
      "2025-06-23 21:21:41 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T212141\\tensorboard\n",
      "2025-06-23 21:21:41 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:21:41 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:21:41 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:21:55 [INFO]: Epoch 001 - training loss (MAE): 0.7553, validation MSE: 0.3506\n",
      "2025-06-23 21:22:05 [INFO]: Epoch 002 - training loss (MAE): 0.7314, validation MSE: 0.3456\n",
      "2025-06-23 21:22:15 [INFO]: Epoch 003 - training loss (MAE): 0.7057, validation MSE: 0.3409\n",
      "2025-06-23 21:22:25 [INFO]: Epoch 004 - training loss (MAE): 0.7009, validation MSE: 0.3363\n",
      "2025-06-23 21:22:35 [INFO]: Epoch 005 - training loss (MAE): 0.6689, validation MSE: 0.3313\n",
      "2025-06-23 21:22:45 [INFO]: Epoch 006 - training loss (MAE): 0.6733, validation MSE: 0.3254\n",
      "2025-06-23 21:22:54 [INFO]: Epoch 007 - training loss (MAE): 0.6751, validation MSE: 0.3184\n",
      "2025-06-23 21:23:04 [INFO]: Epoch 008 - training loss (MAE): 0.6335, validation MSE: 0.3107\n",
      "2025-06-23 21:23:14 [INFO]: Epoch 009 - training loss (MAE): 0.6104, validation MSE: 0.3017\n",
      "2025-06-23 21:23:24 [INFO]: Epoch 010 - training loss (MAE): 0.6258, validation MSE: 0.2920\n",
      "2025-06-23 21:23:34 [INFO]: Epoch 011 - training loss (MAE): 0.6362, validation MSE: 0.2843\n",
      "2025-06-23 21:23:44 [INFO]: Epoch 012 - training loss (MAE): 0.5740, validation MSE: 0.2782\n",
      "2025-06-23 21:23:53 [INFO]: Epoch 013 - training loss (MAE): 0.6298, validation MSE: 0.2702\n",
      "2025-06-23 21:24:03 [INFO]: Epoch 014 - training loss (MAE): 0.5605, validation MSE: 0.2570\n",
      "2025-06-23 21:24:13 [INFO]: Epoch 015 - training loss (MAE): 0.5430, validation MSE: 0.2369\n",
      "2025-06-23 21:24:23 [INFO]: Epoch 016 - training loss (MAE): 0.5528, validation MSE: 0.2178\n",
      "2025-06-23 21:24:33 [INFO]: Epoch 017 - training loss (MAE): 0.5455, validation MSE: 0.2046\n",
      "2025-06-23 21:24:42 [INFO]: Epoch 018 - training loss (MAE): 0.5366, validation MSE: 0.1952\n",
      "2025-06-23 21:24:52 [INFO]: Epoch 019 - training loss (MAE): 0.5190, validation MSE: 0.1895\n",
      "2025-06-23 21:25:02 [INFO]: Epoch 020 - training loss (MAE): 0.5193, validation MSE: 0.1762\n",
      "2025-06-23 21:25:11 [INFO]: Epoch 021 - training loss (MAE): 0.4980, validation MSE: 0.1658\n",
      "2025-06-23 21:25:21 [INFO]: Epoch 022 - training loss (MAE): 0.4876, validation MSE: 0.1549\n",
      "2025-06-23 21:25:31 [INFO]: Epoch 023 - training loss (MAE): 0.4539, validation MSE: 0.1493\n",
      "2025-06-23 21:25:41 [INFO]: Epoch 024 - training loss (MAE): 0.4688, validation MSE: 0.1386\n",
      "2025-06-23 21:25:50 [INFO]: Epoch 025 - training loss (MAE): 0.4615, validation MSE: 0.1273\n",
      "2025-06-23 21:25:50 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:25:50 [INFO]: Saved the model to ./brits_model\\20250623_T212141\\BRITS.pypots\n",
      "2025-06-23 21:25:50 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:25:50 [INFO]: Model files will be saved to ./brits_model\\20250623_T212550\n",
      "2025-06-23 21:25:50 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T212550\\tensorboard\n",
      "2025-06-23 21:25:50 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:25:50 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:25:50 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.9 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:26:05 [INFO]: Epoch 001 - training loss (MAE): 0.7479, validation MSE: 0.4014\n",
      "2025-06-23 21:26:15 [INFO]: Epoch 002 - training loss (MAE): 0.7147, validation MSE: 0.3968\n",
      "2025-06-23 21:26:25 [INFO]: Epoch 003 - training loss (MAE): 0.6758, validation MSE: 0.3922\n",
      "2025-06-23 21:26:35 [INFO]: Epoch 004 - training loss (MAE): 0.6809, validation MSE: 0.3874\n",
      "2025-06-23 21:26:45 [INFO]: Epoch 005 - training loss (MAE): 0.6552, validation MSE: 0.3822\n",
      "2025-06-23 21:26:55 [INFO]: Epoch 006 - training loss (MAE): 0.6420, validation MSE: 0.3759\n",
      "2025-06-23 21:27:04 [INFO]: Epoch 007 - training loss (MAE): 0.6263, validation MSE: 0.3684\n",
      "2025-06-23 21:27:14 [INFO]: Epoch 008 - training loss (MAE): 0.6082, validation MSE: 0.3613\n",
      "2025-06-23 21:27:24 [INFO]: Epoch 009 - training loss (MAE): 0.5850, validation MSE: 0.3571\n",
      "2025-06-23 21:27:34 [INFO]: Epoch 010 - training loss (MAE): 0.5760, validation MSE: 0.3552\n",
      "2025-06-23 21:27:43 [INFO]: Epoch 011 - training loss (MAE): 0.5727, validation MSE: 0.3524\n",
      "2025-06-23 21:27:53 [INFO]: Epoch 012 - training loss (MAE): 0.5824, validation MSE: 0.3487\n",
      "2025-06-23 21:28:03 [INFO]: Epoch 013 - training loss (MAE): 0.5494, validation MSE: 0.3444\n",
      "2025-06-23 21:28:13 [INFO]: Epoch 014 - training loss (MAE): 0.5545, validation MSE: 0.3408\n",
      "2025-06-23 21:28:23 [INFO]: Epoch 015 - training loss (MAE): 0.5745, validation MSE: 0.3378\n",
      "2025-06-23 21:28:32 [INFO]: Epoch 016 - training loss (MAE): 0.5423, validation MSE: 0.3354\n",
      "2025-06-23 21:28:42 [INFO]: Epoch 017 - training loss (MAE): 0.5481, validation MSE: 0.3341\n",
      "2025-06-23 21:28:52 [INFO]: Epoch 018 - training loss (MAE): 0.5208, validation MSE: 0.3333\n",
      "2025-06-23 21:29:01 [INFO]: Epoch 019 - training loss (MAE): 0.5237, validation MSE: 0.3342\n",
      "2025-06-23 21:29:11 [INFO]: Epoch 020 - training loss (MAE): 0.5461, validation MSE: 0.3343\n",
      "2025-06-23 21:29:21 [INFO]: Epoch 021 - training loss (MAE): 0.5203, validation MSE: 0.3330\n",
      "2025-06-23 21:29:30 [INFO]: Epoch 022 - training loss (MAE): 0.5206, validation MSE: 0.3303\n",
      "2025-06-23 21:29:40 [INFO]: Epoch 023 - training loss (MAE): 0.5067, validation MSE: 0.3273\n",
      "2025-06-23 21:29:50 [INFO]: Epoch 024 - training loss (MAE): 0.5052, validation MSE: 0.3237\n",
      "2025-06-23 21:30:00 [INFO]: Epoch 025 - training loss (MAE): 0.5046, validation MSE: 0.3189\n",
      "2025-06-23 21:30:00 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:30:00 [INFO]: Saved the model to ./brits_model\\20250623_T212550\\BRITS.pypots\n",
      "2025-06-23 21:30:00 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:30:00 [INFO]: Model files will be saved to ./brits_model\\20250623_T213000\n",
      "2025-06-23 21:30:00 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T213000\\tensorboard\n",
      "2025-06-23 21:30:00 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:30:00 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:30:00 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 3...\n",
      "Training model for missing rate 0.05 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:30:15 [INFO]: Epoch 001 - training loss (MAE): 1.5286, validation MSE: 0.7317\n",
      "2025-06-23 21:30:24 [INFO]: Epoch 002 - training loss (MAE): 1.4933, validation MSE: 0.7080\n",
      "2025-06-23 21:30:34 [INFO]: Epoch 003 - training loss (MAE): 1.4557, validation MSE: 0.6829\n",
      "2025-06-23 21:30:43 [INFO]: Epoch 004 - training loss (MAE): 1.4214, validation MSE: 0.6548\n",
      "2025-06-23 21:30:53 [INFO]: Epoch 005 - training loss (MAE): 1.3537, validation MSE: 0.6221\n",
      "2025-06-23 21:31:03 [INFO]: Epoch 006 - training loss (MAE): 1.2942, validation MSE: 0.5840\n",
      "2025-06-23 21:31:12 [INFO]: Epoch 007 - training loss (MAE): 1.2286, validation MSE: 0.5392\n",
      "2025-06-23 21:31:22 [INFO]: Epoch 008 - training loss (MAE): 1.1486, validation MSE: 0.4877\n",
      "2025-06-23 21:31:31 [INFO]: Epoch 009 - training loss (MAE): 1.0111, validation MSE: 0.4342\n",
      "2025-06-23 21:31:41 [INFO]: Epoch 010 - training loss (MAE): 0.8928, validation MSE: 0.3869\n",
      "2025-06-23 21:31:50 [INFO]: Epoch 011 - training loss (MAE): 0.8376, validation MSE: 0.3433\n",
      "2025-06-23 21:32:00 [INFO]: Epoch 012 - training loss (MAE): 0.7632, validation MSE: 0.2980\n",
      "2025-06-23 21:32:09 [INFO]: Epoch 013 - training loss (MAE): 0.7157, validation MSE: 0.2563\n",
      "2025-06-23 21:32:19 [INFO]: Epoch 014 - training loss (MAE): 0.6843, validation MSE: 0.2220\n",
      "2025-06-23 21:32:29 [INFO]: Epoch 015 - training loss (MAE): 0.6383, validation MSE: 0.1983\n",
      "2025-06-23 21:32:38 [INFO]: Epoch 016 - training loss (MAE): 0.6189, validation MSE: 0.1807\n",
      "2025-06-23 21:32:48 [INFO]: Epoch 017 - training loss (MAE): 0.5891, validation MSE: 0.1715\n",
      "2025-06-23 21:32:58 [INFO]: Epoch 018 - training loss (MAE): 0.5728, validation MSE: 0.1682\n",
      "2025-06-23 21:33:07 [INFO]: Epoch 019 - training loss (MAE): 0.5515, validation MSE: 0.1595\n",
      "2025-06-23 21:33:17 [INFO]: Epoch 020 - training loss (MAE): 0.5271, validation MSE: 0.1515\n",
      "2025-06-23 21:33:26 [INFO]: Epoch 021 - training loss (MAE): 0.5111, validation MSE: 0.1454\n",
      "2025-06-23 21:33:36 [INFO]: Epoch 022 - training loss (MAE): 0.4997, validation MSE: 0.1357\n",
      "2025-06-23 21:33:45 [INFO]: Epoch 023 - training loss (MAE): 0.4855, validation MSE: 0.1278\n",
      "2025-06-23 21:33:55 [INFO]: Epoch 024 - training loss (MAE): 0.4707, validation MSE: 0.1217\n",
      "2025-06-23 21:34:05 [INFO]: Epoch 025 - training loss (MAE): 0.4715, validation MSE: 0.1190\n",
      "2025-06-23 21:34:05 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:34:05 [INFO]: Saved the model to ./brits_model\\20250623_T213000\\BRITS.pypots\n",
      "2025-06-23 21:34:05 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:34:05 [INFO]: Model files will be saved to ./brits_model\\20250623_T213405\n",
      "2025-06-23 21:34:05 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T213405\\tensorboard\n",
      "2025-06-23 21:34:05 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:34:05 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:34:05 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:34:19 [INFO]: Epoch 001 - training loss (MAE): 1.8416, validation MSE: 1.2510\n",
      "2025-06-23 21:34:28 [INFO]: Epoch 002 - training loss (MAE): 1.8140, validation MSE: 1.2323\n",
      "2025-06-23 21:34:38 [INFO]: Epoch 003 - training loss (MAE): 1.7911, validation MSE: 1.2121\n",
      "2025-06-23 21:34:47 [INFO]: Epoch 004 - training loss (MAE): 1.7380, validation MSE: 1.1888\n",
      "2025-06-23 21:34:57 [INFO]: Epoch 005 - training loss (MAE): 1.7058, validation MSE: 1.1622\n",
      "2025-06-23 21:35:07 [INFO]: Epoch 006 - training loss (MAE): 1.6557, validation MSE: 1.1304\n",
      "2025-06-23 21:35:16 [INFO]: Epoch 007 - training loss (MAE): 1.5917, validation MSE: 1.0914\n",
      "2025-06-23 21:35:26 [INFO]: Epoch 008 - training loss (MAE): 1.5107, validation MSE: 1.0472\n",
      "2025-06-23 21:35:38 [INFO]: Epoch 009 - training loss (MAE): 1.4486, validation MSE: 0.9983\n",
      "2025-06-23 21:35:47 [INFO]: Epoch 010 - training loss (MAE): 1.3829, validation MSE: 0.9455\n",
      "2025-06-23 21:35:56 [INFO]: Epoch 011 - training loss (MAE): 1.3502, validation MSE: 0.8903\n",
      "2025-06-23 21:36:06 [INFO]: Epoch 012 - training loss (MAE): 1.2840, validation MSE: 0.8363\n",
      "2025-06-23 21:36:16 [INFO]: Epoch 013 - training loss (MAE): 1.2508, validation MSE: 0.7854\n",
      "2025-06-23 21:36:26 [INFO]: Epoch 014 - training loss (MAE): 1.2006, validation MSE: 0.7311\n",
      "2025-06-23 21:36:35 [INFO]: Epoch 015 - training loss (MAE): 1.1601, validation MSE: 0.6751\n",
      "2025-06-23 21:36:45 [INFO]: Epoch 016 - training loss (MAE): 1.0961, validation MSE: 0.6233\n",
      "2025-06-23 21:36:54 [INFO]: Epoch 017 - training loss (MAE): 1.0697, validation MSE: 0.5793\n",
      "2025-06-23 21:37:04 [INFO]: Epoch 018 - training loss (MAE): 1.0480, validation MSE: 0.5419\n",
      "2025-06-23 21:37:14 [INFO]: Epoch 019 - training loss (MAE): 1.0000, validation MSE: 0.5109\n",
      "2025-06-23 21:37:23 [INFO]: Epoch 020 - training loss (MAE): 0.9774, validation MSE: 0.4832\n",
      "2025-06-23 21:37:33 [INFO]: Epoch 021 - training loss (MAE): 0.9420, validation MSE: 0.4553\n",
      "2025-06-23 21:37:42 [INFO]: Epoch 022 - training loss (MAE): 0.9079, validation MSE: 0.4270\n",
      "2025-06-23 21:37:52 [INFO]: Epoch 023 - training loss (MAE): 0.8799, validation MSE: 0.4028\n",
      "2025-06-23 21:38:02 [INFO]: Epoch 024 - training loss (MAE): 0.8480, validation MSE: 0.3896\n",
      "2025-06-23 21:38:11 [INFO]: Epoch 025 - training loss (MAE): 0.8426, validation MSE: 0.3794\n",
      "2025-06-23 21:38:11 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:38:11 [INFO]: Saved the model to ./brits_model\\20250623_T213405\\BRITS.pypots\n",
      "2025-06-23 21:38:11 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:38:11 [INFO]: Model files will be saved to ./brits_model\\20250623_T213811\n",
      "2025-06-23 21:38:11 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T213811\\tensorboard\n",
      "2025-06-23 21:38:11 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:38:11 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:38:11 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:38:26 [INFO]: Epoch 001 - training loss (MAE): 1.7752, validation MSE: 1.0666\n",
      "2025-06-23 21:38:35 [INFO]: Epoch 002 - training loss (MAE): 1.7520, validation MSE: 1.0538\n",
      "2025-06-23 21:38:45 [INFO]: Epoch 003 - training loss (MAE): 1.7234, validation MSE: 1.0407\n",
      "2025-06-23 21:38:54 [INFO]: Epoch 004 - training loss (MAE): 1.6859, validation MSE: 1.0269\n",
      "2025-06-23 21:39:04 [INFO]: Epoch 005 - training loss (MAE): 1.6598, validation MSE: 1.0120\n",
      "2025-06-23 21:39:14 [INFO]: Epoch 006 - training loss (MAE): 1.6375, validation MSE: 0.9956\n",
      "2025-06-23 21:39:23 [INFO]: Epoch 007 - training loss (MAE): 1.5321, validation MSE: 0.9772\n",
      "2025-06-23 21:39:33 [INFO]: Epoch 008 - training loss (MAE): 1.4786, validation MSE: 0.9590\n",
      "2025-06-23 21:39:42 [INFO]: Epoch 009 - training loss (MAE): 1.4411, validation MSE: 0.9329\n",
      "2025-06-23 21:39:52 [INFO]: Epoch 010 - training loss (MAE): 1.3471, validation MSE: 0.8743\n",
      "2025-06-23 21:40:01 [INFO]: Epoch 011 - training loss (MAE): 1.3175, validation MSE: 0.8022\n",
      "2025-06-23 21:40:11 [INFO]: Epoch 012 - training loss (MAE): 1.2359, validation MSE: 0.7318\n",
      "2025-06-23 21:40:20 [INFO]: Epoch 013 - training loss (MAE): 1.1840, validation MSE: 0.6632\n",
      "2025-06-23 21:40:30 [INFO]: Epoch 014 - training loss (MAE): 1.1382, validation MSE: 0.6036\n",
      "2025-06-23 21:40:40 [INFO]: Epoch 015 - training loss (MAE): 1.1031, validation MSE: 0.5527\n",
      "2025-06-23 21:40:49 [INFO]: Epoch 016 - training loss (MAE): 1.0475, validation MSE: 0.5028\n",
      "2025-06-23 21:40:59 [INFO]: Epoch 017 - training loss (MAE): 0.9876, validation MSE: 0.4562\n",
      "2025-06-23 21:41:08 [INFO]: Epoch 018 - training loss (MAE): 0.9503, validation MSE: 0.4133\n",
      "2025-06-23 21:41:18 [INFO]: Epoch 019 - training loss (MAE): 0.9101, validation MSE: 0.3764\n",
      "2025-06-23 21:41:28 [INFO]: Epoch 020 - training loss (MAE): 0.8605, validation MSE: 0.3438\n",
      "2025-06-23 21:41:38 [INFO]: Epoch 021 - training loss (MAE): 0.8295, validation MSE: 0.3187\n",
      "2025-06-23 21:41:47 [INFO]: Epoch 022 - training loss (MAE): 0.8132, validation MSE: 0.2999\n",
      "2025-06-23 21:41:57 [INFO]: Epoch 023 - training loss (MAE): 0.7774, validation MSE: 0.2845\n",
      "2025-06-23 21:42:06 [INFO]: Epoch 024 - training loss (MAE): 0.7399, validation MSE: 0.2715\n",
      "2025-06-23 21:42:16 [INFO]: Epoch 025 - training loss (MAE): 0.7424, validation MSE: 0.2582\n",
      "2025-06-23 21:42:16 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:42:16 [INFO]: Saved the model to ./brits_model\\20250623_T213811\\BRITS.pypots\n",
      "2025-06-23 21:42:16 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:42:16 [INFO]: Model files will be saved to ./brits_model\\20250623_T214216\n",
      "2025-06-23 21:42:16 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T214216\\tensorboard\n",
      "2025-06-23 21:42:16 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:42:16 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:42:16 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.9 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:42:30 [INFO]: Epoch 001 - training loss (MAE): 1.7464, validation MSE: 1.2337\n",
      "2025-06-23 21:42:39 [INFO]: Epoch 002 - training loss (MAE): 1.7343, validation MSE: 1.2385\n",
      "2025-06-23 21:42:49 [INFO]: Epoch 003 - training loss (MAE): 1.7167, validation MSE: 1.2438\n",
      "2025-06-23 21:42:58 [INFO]: Epoch 004 - training loss (MAE): 1.7212, validation MSE: 1.2496\n",
      "2025-06-23 21:43:07 [INFO]: Epoch 005 - training loss (MAE): 1.7128, validation MSE: 1.2566\n",
      "2025-06-23 21:43:17 [INFO]: Epoch 006 - training loss (MAE): 1.6924, validation MSE: 1.2657\n",
      "2025-06-23 21:43:17 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-06-23 21:43:17 [INFO]: Finished training. The best model is from epoch#1.\n",
      "2025-06-23 21:43:17 [INFO]: Saved the model to ./brits_model\\20250623_T214216\\BRITS.pypots\n",
      "2025-06-23 21:43:17 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:43:17 [INFO]: Model files will be saved to ./brits_model\\20250623_T214317\n",
      "2025-06-23 21:43:17 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T214317\\tensorboard\n",
      "2025-06-23 21:43:17 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:43:17 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:43:17 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 4...\n",
      "Training model for missing rate 0.05 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:43:31 [INFO]: Epoch 001 - training loss (MAE): 1.8912, validation MSE: 1.5314\n",
      "2025-06-23 21:43:41 [INFO]: Epoch 002 - training loss (MAE): 1.8510, validation MSE: 1.4903\n",
      "2025-06-23 21:43:51 [INFO]: Epoch 003 - training loss (MAE): 1.8544, validation MSE: 1.4525\n",
      "2025-06-23 21:44:01 [INFO]: Epoch 004 - training loss (MAE): 1.8368, validation MSE: 1.4104\n",
      "2025-06-23 21:44:11 [INFO]: Epoch 005 - training loss (MAE): 1.7518, validation MSE: 1.3665\n",
      "2025-06-23 21:44:20 [INFO]: Epoch 006 - training loss (MAE): 1.7354, validation MSE: 1.3164\n",
      "2025-06-23 21:44:30 [INFO]: Epoch 007 - training loss (MAE): 1.6638, validation MSE: 1.2530\n",
      "2025-06-23 21:44:40 [INFO]: Epoch 008 - training loss (MAE): 1.6038, validation MSE: 1.1867\n",
      "2025-06-23 21:44:50 [INFO]: Epoch 009 - training loss (MAE): 1.5506, validation MSE: 1.1100\n",
      "2025-06-23 21:45:00 [INFO]: Epoch 010 - training loss (MAE): 1.4917, validation MSE: 1.0284\n",
      "2025-06-23 21:45:09 [INFO]: Epoch 011 - training loss (MAE): 1.4318, validation MSE: 0.9467\n",
      "2025-06-23 21:45:19 [INFO]: Epoch 012 - training loss (MAE): 1.3596, validation MSE: 0.8644\n",
      "2025-06-23 21:45:28 [INFO]: Epoch 013 - training loss (MAE): 1.3506, validation MSE: 0.7834\n",
      "2025-06-23 21:45:38 [INFO]: Epoch 014 - training loss (MAE): 1.2699, validation MSE: 0.7138\n",
      "2025-06-23 21:45:48 [INFO]: Epoch 015 - training loss (MAE): 1.1946, validation MSE: 0.6387\n",
      "2025-06-23 21:45:58 [INFO]: Epoch 016 - training loss (MAE): 1.1599, validation MSE: 0.5727\n",
      "2025-06-23 21:46:07 [INFO]: Epoch 017 - training loss (MAE): 1.1104, validation MSE: 0.5174\n",
      "2025-06-23 21:46:17 [INFO]: Epoch 018 - training loss (MAE): 1.0740, validation MSE: 0.4732\n",
      "2025-06-23 21:46:27 [INFO]: Epoch 019 - training loss (MAE): 1.0211, validation MSE: 0.4364\n",
      "2025-06-23 21:46:37 [INFO]: Epoch 020 - training loss (MAE): 1.0069, validation MSE: 0.4067\n",
      "2025-06-23 21:46:46 [INFO]: Epoch 021 - training loss (MAE): 0.9965, validation MSE: 0.3820\n",
      "2025-06-23 21:46:56 [INFO]: Epoch 022 - training loss (MAE): 0.9624, validation MSE: 0.3545\n",
      "2025-06-23 21:47:06 [INFO]: Epoch 023 - training loss (MAE): 0.9380, validation MSE: 0.3304\n",
      "2025-06-23 21:47:16 [INFO]: Epoch 024 - training loss (MAE): 0.9339, validation MSE: 0.3075\n",
      "2025-06-23 21:47:25 [INFO]: Epoch 025 - training loss (MAE): 0.9038, validation MSE: 0.2826\n",
      "2025-06-23 21:47:25 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:47:25 [INFO]: Saved the model to ./brits_model\\20250623_T214317\\BRITS.pypots\n",
      "2025-06-23 21:47:25 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:47:25 [INFO]: Model files will be saved to ./brits_model\\20250623_T214725\n",
      "2025-06-23 21:47:25 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T214725\\tensorboard\n",
      "2025-06-23 21:47:25 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:47:25 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:47:25 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:47:40 [INFO]: Epoch 001 - training loss (MAE): 1.5643, validation MSE: 0.7756\n",
      "2025-06-23 21:47:50 [INFO]: Epoch 002 - training loss (MAE): 1.5542, validation MSE: 0.7503\n",
      "2025-06-23 21:47:59 [INFO]: Epoch 003 - training loss (MAE): 1.5457, validation MSE: 0.7260\n",
      "2025-06-23 21:48:09 [INFO]: Epoch 004 - training loss (MAE): 1.5089, validation MSE: 0.7050\n",
      "2025-06-23 21:48:18 [INFO]: Epoch 005 - training loss (MAE): 1.4719, validation MSE: 0.6841\n",
      "2025-06-23 21:48:28 [INFO]: Epoch 006 - training loss (MAE): 1.4222, validation MSE: 0.6625\n",
      "2025-06-23 21:48:38 [INFO]: Epoch 007 - training loss (MAE): 1.3686, validation MSE: 0.6384\n",
      "2025-06-23 21:48:48 [INFO]: Epoch 008 - training loss (MAE): 1.3311, validation MSE: 0.6162\n",
      "2025-06-23 21:48:58 [INFO]: Epoch 009 - training loss (MAE): 1.2864, validation MSE: 0.5971\n",
      "2025-06-23 21:49:07 [INFO]: Epoch 010 - training loss (MAE): 1.2130, validation MSE: 0.5649\n",
      "2025-06-23 21:49:17 [INFO]: Epoch 011 - training loss (MAE): 1.1829, validation MSE: 0.5201\n",
      "2025-06-23 21:49:27 [INFO]: Epoch 012 - training loss (MAE): 1.1354, validation MSE: 0.4744\n",
      "2025-06-23 21:49:37 [INFO]: Epoch 013 - training loss (MAE): 1.1227, validation MSE: 0.4336\n",
      "2025-06-23 21:49:46 [INFO]: Epoch 014 - training loss (MAE): 1.0609, validation MSE: 0.3888\n",
      "2025-06-23 21:49:56 [INFO]: Epoch 015 - training loss (MAE): 1.0168, validation MSE: 0.3422\n",
      "2025-06-23 21:50:06 [INFO]: Epoch 016 - training loss (MAE): 0.9536, validation MSE: 0.3004\n",
      "2025-06-23 21:50:16 [INFO]: Epoch 017 - training loss (MAE): 0.9130, validation MSE: 0.2636\n",
      "2025-06-23 21:50:26 [INFO]: Epoch 018 - training loss (MAE): 0.8709, validation MSE: 0.2276\n",
      "2025-06-23 21:50:35 [INFO]: Epoch 019 - training loss (MAE): 0.8213, validation MSE: 0.1963\n",
      "2025-06-23 21:50:45 [INFO]: Epoch 020 - training loss (MAE): 0.7750, validation MSE: 0.1760\n",
      "2025-06-23 21:50:55 [INFO]: Epoch 021 - training loss (MAE): 0.7311, validation MSE: 0.1596\n",
      "2025-06-23 21:51:05 [INFO]: Epoch 022 - training loss (MAE): 0.7170, validation MSE: 0.1468\n",
      "2025-06-23 21:51:15 [INFO]: Epoch 023 - training loss (MAE): 0.6929, validation MSE: 0.1375\n",
      "2025-06-23 21:51:24 [INFO]: Epoch 024 - training loss (MAE): 0.6797, validation MSE: 0.1259\n",
      "2025-06-23 21:51:34 [INFO]: Epoch 025 - training loss (MAE): 0.6749, validation MSE: 0.1141\n",
      "2025-06-23 21:51:34 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:51:34 [INFO]: Saved the model to ./brits_model\\20250623_T214725\\BRITS.pypots\n",
      "2025-06-23 21:51:34 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:51:34 [INFO]: Model files will be saved to ./brits_model\\20250623_T215134\n",
      "2025-06-23 21:51:34 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T215134\\tensorboard\n",
      "2025-06-23 21:51:34 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:51:34 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:51:34 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:51:49 [INFO]: Epoch 001 - training loss (MAE): 1.7632, validation MSE: 1.1928\n",
      "2025-06-23 21:51:58 [INFO]: Epoch 002 - training loss (MAE): 1.7717, validation MSE: 1.1845\n",
      "2025-06-23 21:52:08 [INFO]: Epoch 003 - training loss (MAE): 1.7504, validation MSE: 1.1761\n",
      "2025-06-23 21:52:18 [INFO]: Epoch 004 - training loss (MAE): 1.7409, validation MSE: 1.1688\n",
      "2025-06-23 21:52:27 [INFO]: Epoch 005 - training loss (MAE): 1.7017, validation MSE: 1.1615\n",
      "2025-06-23 21:52:38 [INFO]: Epoch 006 - training loss (MAE): 1.6744, validation MSE: 1.1533\n",
      "2025-06-23 21:52:47 [INFO]: Epoch 007 - training loss (MAE): 1.6784, validation MSE: 1.1434\n",
      "2025-06-23 21:52:57 [INFO]: Epoch 008 - training loss (MAE): 1.6517, validation MSE: 1.1334\n",
      "2025-06-23 21:53:07 [INFO]: Epoch 009 - training loss (MAE): 1.6068, validation MSE: 1.1192\n",
      "2025-06-23 21:53:16 [INFO]: Epoch 010 - training loss (MAE): 1.5762, validation MSE: 1.0969\n",
      "2025-06-23 21:53:26 [INFO]: Epoch 011 - training loss (MAE): 1.5526, validation MSE: 1.0623\n",
      "2025-06-23 21:53:36 [INFO]: Epoch 012 - training loss (MAE): 1.4848, validation MSE: 1.0229\n",
      "2025-06-23 21:53:45 [INFO]: Epoch 013 - training loss (MAE): 1.4713, validation MSE: 0.9887\n",
      "2025-06-23 21:53:55 [INFO]: Epoch 014 - training loss (MAE): 1.4139, validation MSE: 0.9546\n",
      "2025-06-23 21:54:05 [INFO]: Epoch 015 - training loss (MAE): 1.3966, validation MSE: 0.9102\n",
      "2025-06-23 21:54:15 [INFO]: Epoch 016 - training loss (MAE): 1.3570, validation MSE: 0.8659\n",
      "2025-06-23 21:54:24 [INFO]: Epoch 017 - training loss (MAE): 1.3376, validation MSE: 0.8164\n",
      "2025-06-23 21:54:34 [INFO]: Epoch 018 - training loss (MAE): 1.2877, validation MSE: 0.7587\n",
      "2025-06-23 21:54:44 [INFO]: Epoch 019 - training loss (MAE): 1.2701, validation MSE: 0.6980\n",
      "2025-06-23 21:54:54 [INFO]: Epoch 020 - training loss (MAE): 1.1970, validation MSE: 0.6365\n",
      "2025-06-23 21:55:03 [INFO]: Epoch 021 - training loss (MAE): 1.1233, validation MSE: 0.5774\n",
      "2025-06-23 21:55:13 [INFO]: Epoch 022 - training loss (MAE): 1.0891, validation MSE: 0.5243\n",
      "2025-06-23 21:55:23 [INFO]: Epoch 023 - training loss (MAE): 1.0404, validation MSE: 0.4819\n",
      "2025-06-23 21:55:33 [INFO]: Epoch 024 - training loss (MAE): 1.0029, validation MSE: 0.4451\n",
      "2025-06-23 21:55:42 [INFO]: Epoch 025 - training loss (MAE): 0.9447, validation MSE: 0.3982\n",
      "2025-06-23 21:55:42 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 21:55:42 [INFO]: Saved the model to ./brits_model\\20250623_T215134\\BRITS.pypots\n",
      "2025-06-23 21:55:42 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:55:42 [INFO]: Model files will be saved to ./brits_model\\20250623_T215542\n",
      "2025-06-23 21:55:42 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T215542\\tensorboard\n",
      "2025-06-23 21:55:42 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:55:42 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:55:42 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.9 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:55:57 [INFO]: Epoch 001 - training loss (MAE): 1.6915, validation MSE: 1.0018\n",
      "2025-06-23 21:56:07 [INFO]: Epoch 002 - training loss (MAE): 1.7013, validation MSE: 1.0018\n",
      "2025-06-23 21:56:17 [INFO]: Epoch 003 - training loss (MAE): 1.7260, validation MSE: 1.0025\n",
      "2025-06-23 21:56:26 [INFO]: Epoch 004 - training loss (MAE): 1.6835, validation MSE: 1.0054\n",
      "2025-06-23 21:56:36 [INFO]: Epoch 005 - training loss (MAE): 1.6705, validation MSE: 1.0083\n",
      "2025-06-23 21:56:46 [INFO]: Epoch 006 - training loss (MAE): 1.6594, validation MSE: 1.0114\n",
      "2025-06-23 21:56:46 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-06-23 21:56:46 [INFO]: Finished training. The best model is from epoch#1.\n",
      "2025-06-23 21:56:46 [INFO]: Saved the model to ./brits_model\\20250623_T215542\\BRITS.pypots\n",
      "2025-06-23 21:56:46 [INFO]: Using the given device: cpu\n",
      "2025-06-23 21:56:46 [INFO]: Model files will be saved to ./brits_model\\20250623_T215646\n",
      "2025-06-23 21:56:46 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T215646\\tensorboard\n",
      "2025-06-23 21:56:46 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 21:56:46 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 21:56:46 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 31,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 5...\n",
      "Training model for missing rate 0.05 in cluster 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 21:57:01 [INFO]: Epoch 001 - training loss (MAE): 1.3832, validation MSE: 0.8865\n",
      "2025-06-23 21:57:12 [INFO]: Epoch 002 - training loss (MAE): 1.2690, validation MSE: 0.8101\n",
      "2025-06-23 21:57:23 [INFO]: Epoch 003 - training loss (MAE): 1.1655, validation MSE: 0.7503\n",
      "2025-06-23 21:57:34 [INFO]: Epoch 004 - training loss (MAE): 1.1078, validation MSE: 0.6846\n",
      "2025-06-23 21:57:45 [INFO]: Epoch 005 - training loss (MAE): 1.0392, validation MSE: 0.6141\n",
      "2025-06-23 21:57:56 [INFO]: Epoch 006 - training loss (MAE): 0.9589, validation MSE: 0.5473\n",
      "2025-06-23 21:58:06 [INFO]: Epoch 007 - training loss (MAE): 0.8981, validation MSE: 0.4820\n",
      "2025-06-23 21:58:17 [INFO]: Epoch 008 - training loss (MAE): 0.8237, validation MSE: 0.4179\n",
      "2025-06-23 21:58:28 [INFO]: Epoch 009 - training loss (MAE): 0.7606, validation MSE: 0.3534\n",
      "2025-06-23 21:58:39 [INFO]: Epoch 010 - training loss (MAE): 0.7007, validation MSE: 0.2984\n",
      "2025-06-23 21:58:50 [INFO]: Epoch 011 - training loss (MAE): 0.6615, validation MSE: 0.2565\n",
      "2025-06-23 21:59:01 [INFO]: Epoch 012 - training loss (MAE): 0.6057, validation MSE: 0.2285\n",
      "2025-06-23 21:59:11 [INFO]: Epoch 013 - training loss (MAE): 0.5639, validation MSE: 0.2085\n",
      "2025-06-23 21:59:22 [INFO]: Epoch 014 - training loss (MAE): 0.5215, validation MSE: 0.1923\n",
      "2025-06-23 21:59:33 [INFO]: Epoch 015 - training loss (MAE): 0.4916, validation MSE: 0.1806\n",
      "2025-06-23 21:59:43 [INFO]: Epoch 016 - training loss (MAE): 0.4618, validation MSE: 0.1714\n",
      "2025-06-23 21:59:54 [INFO]: Epoch 017 - training loss (MAE): 0.4366, validation MSE: 0.1643\n",
      "2025-06-23 22:00:05 [INFO]: Epoch 018 - training loss (MAE): 0.4192, validation MSE: 0.1570\n",
      "2025-06-23 22:00:16 [INFO]: Epoch 019 - training loss (MAE): 0.4038, validation MSE: 0.1505\n",
      "2025-06-23 22:00:27 [INFO]: Epoch 020 - training loss (MAE): 0.3871, validation MSE: 0.1446\n",
      "2025-06-23 22:00:38 [INFO]: Epoch 021 - training loss (MAE): 0.3728, validation MSE: 0.1392\n",
      "2025-06-23 22:00:48 [INFO]: Epoch 022 - training loss (MAE): 0.3573, validation MSE: 0.1340\n",
      "2025-06-23 22:00:59 [INFO]: Epoch 023 - training loss (MAE): 0.3551, validation MSE: 0.1299\n",
      "2025-06-23 22:01:10 [INFO]: Epoch 024 - training loss (MAE): 0.3366, validation MSE: 0.1268\n",
      "2025-06-23 22:01:21 [INFO]: Epoch 025 - training loss (MAE): 0.3356, validation MSE: 0.1225\n",
      "2025-06-23 22:01:21 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 22:01:21 [INFO]: Saved the model to ./brits_model\\20250623_T215646\\BRITS.pypots\n",
      "2025-06-23 22:01:21 [INFO]: Using the given device: cpu\n",
      "2025-06-23 22:01:21 [INFO]: Model files will be saved to ./brits_model\\20250623_T220121\n",
      "2025-06-23 22:01:21 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T220121\\tensorboard\n",
      "2025-06-23 22:01:21 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 22:01:21 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 22:01:21 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 31,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:01:36 [INFO]: Epoch 001 - training loss (MAE): 1.3069, validation MSE: 0.8063\n",
      "2025-06-23 22:01:47 [INFO]: Epoch 002 - training loss (MAE): 1.2138, validation MSE: 0.7307\n",
      "2025-06-23 22:01:58 [INFO]: Epoch 003 - training loss (MAE): 1.1486, validation MSE: 0.6586\n",
      "2025-06-23 22:02:09 [INFO]: Epoch 004 - training loss (MAE): 1.0556, validation MSE: 0.5907\n",
      "2025-06-23 22:02:20 [INFO]: Epoch 005 - training loss (MAE): 0.9679, validation MSE: 0.5251\n",
      "2025-06-23 22:02:31 [INFO]: Epoch 006 - training loss (MAE): 0.8816, validation MSE: 0.4569\n",
      "2025-06-23 22:02:41 [INFO]: Epoch 007 - training loss (MAE): 0.8294, validation MSE: 0.3944\n",
      "2025-06-23 22:02:52 [INFO]: Epoch 008 - training loss (MAE): 0.7679, validation MSE: 0.3332\n",
      "2025-06-23 22:03:03 [INFO]: Epoch 009 - training loss (MAE): 0.7124, validation MSE: 0.2873\n",
      "2025-06-23 22:03:14 [INFO]: Epoch 010 - training loss (MAE): 0.6444, validation MSE: 0.2525\n",
      "2025-06-23 22:03:25 [INFO]: Epoch 011 - training loss (MAE): 0.6099, validation MSE: 0.2303\n",
      "2025-06-23 22:03:36 [INFO]: Epoch 012 - training loss (MAE): 0.5769, validation MSE: 0.2138\n",
      "2025-06-23 22:03:46 [INFO]: Epoch 013 - training loss (MAE): 0.5310, validation MSE: 0.1995\n",
      "2025-06-23 22:03:57 [INFO]: Epoch 014 - training loss (MAE): 0.4993, validation MSE: 0.1882\n",
      "2025-06-23 22:04:08 [INFO]: Epoch 015 - training loss (MAE): 0.4991, validation MSE: 0.1803\n",
      "2025-06-23 22:04:19 [INFO]: Epoch 016 - training loss (MAE): 0.4530, validation MSE: 0.1737\n",
      "2025-06-23 22:04:30 [INFO]: Epoch 017 - training loss (MAE): 0.4389, validation MSE: 0.1690\n",
      "2025-06-23 22:04:41 [INFO]: Epoch 018 - training loss (MAE): 0.4274, validation MSE: 0.1638\n",
      "2025-06-23 22:04:51 [INFO]: Epoch 019 - training loss (MAE): 0.4124, validation MSE: 0.1587\n",
      "2025-06-23 22:05:02 [INFO]: Epoch 020 - training loss (MAE): 0.3896, validation MSE: 0.1532\n",
      "2025-06-23 22:05:13 [INFO]: Epoch 021 - training loss (MAE): 0.3815, validation MSE: 0.1483\n",
      "2025-06-23 22:05:24 [INFO]: Epoch 022 - training loss (MAE): 0.3771, validation MSE: 0.1447\n",
      "2025-06-23 22:05:35 [INFO]: Epoch 023 - training loss (MAE): 0.3609, validation MSE: 0.1411\n",
      "2025-06-23 22:05:46 [INFO]: Epoch 024 - training loss (MAE): 0.3494, validation MSE: 0.1371\n",
      "2025-06-23 22:05:57 [INFO]: Epoch 025 - training loss (MAE): 0.3489, validation MSE: 0.1322\n",
      "2025-06-23 22:05:57 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 22:05:57 [INFO]: Saved the model to ./brits_model\\20250623_T220121\\BRITS.pypots\n",
      "2025-06-23 22:05:57 [INFO]: Using the given device: cpu\n",
      "2025-06-23 22:05:57 [INFO]: Model files will be saved to ./brits_model\\20250623_T220557\n",
      "2025-06-23 22:05:57 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T220557\\tensorboard\n",
      "2025-06-23 22:05:57 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 22:05:57 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 22:05:57 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 31,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:06:12 [INFO]: Epoch 001 - training loss (MAE): 1.3058, validation MSE: 0.9350\n",
      "2025-06-23 22:06:23 [INFO]: Epoch 002 - training loss (MAE): 1.2780, validation MSE: 0.8880\n",
      "2025-06-23 22:06:34 [INFO]: Epoch 003 - training loss (MAE): 1.1977, validation MSE: 0.8383\n",
      "2025-06-23 22:06:45 [INFO]: Epoch 004 - training loss (MAE): 1.1428, validation MSE: 0.7787\n",
      "2025-06-23 22:06:56 [INFO]: Epoch 005 - training loss (MAE): 1.0790, validation MSE: 0.7094\n",
      "2025-06-23 22:07:07 [INFO]: Epoch 006 - training loss (MAE): 1.0130, validation MSE: 0.6448\n",
      "2025-06-23 22:07:18 [INFO]: Epoch 007 - training loss (MAE): 0.9571, validation MSE: 0.5845\n",
      "2025-06-23 22:07:28 [INFO]: Epoch 008 - training loss (MAE): 0.8951, validation MSE: 0.5265\n",
      "2025-06-23 22:07:40 [INFO]: Epoch 009 - training loss (MAE): 0.8084, validation MSE: 0.4713\n",
      "2025-06-23 22:07:50 [INFO]: Epoch 010 - training loss (MAE): 0.7703, validation MSE: 0.4232\n",
      "2025-06-23 22:08:01 [INFO]: Epoch 011 - training loss (MAE): 0.7059, validation MSE: 0.3723\n",
      "2025-06-23 22:08:12 [INFO]: Epoch 012 - training loss (MAE): 0.6395, validation MSE: 0.3323\n",
      "2025-06-23 22:08:23 [INFO]: Epoch 013 - training loss (MAE): 0.6128, validation MSE: 0.2996\n",
      "2025-06-23 22:08:34 [INFO]: Epoch 014 - training loss (MAE): 0.5733, validation MSE: 0.2731\n",
      "2025-06-23 22:08:45 [INFO]: Epoch 015 - training loss (MAE): 0.5492, validation MSE: 0.2565\n",
      "2025-06-23 22:08:55 [INFO]: Epoch 016 - training loss (MAE): 0.5216, validation MSE: 0.2421\n",
      "2025-06-23 22:09:06 [INFO]: Epoch 017 - training loss (MAE): 0.5066, validation MSE: 0.2294\n",
      "2025-06-23 22:09:17 [INFO]: Epoch 018 - training loss (MAE): 0.4742, validation MSE: 0.2212\n",
      "2025-06-23 22:09:28 [INFO]: Epoch 019 - training loss (MAE): 0.4677, validation MSE: 0.2117\n",
      "2025-06-23 22:09:39 [INFO]: Epoch 020 - training loss (MAE): 0.4483, validation MSE: 0.2047\n",
      "2025-06-23 22:09:49 [INFO]: Epoch 021 - training loss (MAE): 0.4186, validation MSE: 0.1984\n",
      "2025-06-23 22:10:00 [INFO]: Epoch 022 - training loss (MAE): 0.4152, validation MSE: 0.1932\n",
      "2025-06-23 22:10:11 [INFO]: Epoch 023 - training loss (MAE): 0.4000, validation MSE: 0.1886\n",
      "2025-06-23 22:10:21 [INFO]: Epoch 024 - training loss (MAE): 0.4033, validation MSE: 0.1820\n",
      "2025-06-23 22:10:32 [INFO]: Epoch 025 - training loss (MAE): 0.3720, validation MSE: 0.1761\n",
      "2025-06-23 22:10:32 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 22:10:32 [INFO]: Saved the model to ./brits_model\\20250623_T220557\\BRITS.pypots\n",
      "2025-06-23 22:10:32 [INFO]: Using the given device: cpu\n",
      "2025-06-23 22:10:32 [INFO]: Model files will be saved to ./brits_model\\20250623_T221032\n",
      "2025-06-23 22:10:32 [INFO]: Tensorboard file will be saved to ./brits_model\\20250623_T221032\\tensorboard\n",
      "2025-06-23 22:10:32 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-23 22:10:32 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-23 22:10:32 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 31,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.9 in cluster 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 22:10:48 [INFO]: Epoch 001 - training loss (MAE): 1.2833, validation MSE: 0.9183\n",
      "2025-06-23 22:10:59 [INFO]: Epoch 002 - training loss (MAE): 1.2476, validation MSE: 0.9037\n",
      "2025-06-23 22:11:10 [INFO]: Epoch 003 - training loss (MAE): 1.2136, validation MSE: 0.8858\n",
      "2025-06-23 22:11:20 [INFO]: Epoch 004 - training loss (MAE): 1.2292, validation MSE: 0.8618\n",
      "2025-06-23 22:11:31 [INFO]: Epoch 005 - training loss (MAE): 1.1572, validation MSE: 0.8308\n",
      "2025-06-23 22:11:42 [INFO]: Epoch 006 - training loss (MAE): 1.1226, validation MSE: 0.8041\n",
      "2025-06-23 22:11:53 [INFO]: Epoch 007 - training loss (MAE): 1.0736, validation MSE: 0.7890\n",
      "2025-06-23 22:12:04 [INFO]: Epoch 008 - training loss (MAE): 1.0226, validation MSE: 0.7617\n",
      "2025-06-23 22:12:15 [INFO]: Epoch 009 - training loss (MAE): 0.9778, validation MSE: 0.7022\n",
      "2025-06-23 22:12:25 [INFO]: Epoch 010 - training loss (MAE): 0.9434, validation MSE: 0.6866\n",
      "2025-06-23 22:12:36 [INFO]: Epoch 011 - training loss (MAE): 0.8832, validation MSE: 0.6602\n",
      "2025-06-23 22:12:47 [INFO]: Epoch 012 - training loss (MAE): 0.8490, validation MSE: 0.6397\n",
      "2025-06-23 22:12:58 [INFO]: Epoch 013 - training loss (MAE): 0.8360, validation MSE: 0.6100\n",
      "2025-06-23 22:13:08 [INFO]: Epoch 014 - training loss (MAE): 0.8015, validation MSE: 0.5873\n",
      "2025-06-23 22:13:19 [INFO]: Epoch 015 - training loss (MAE): 0.7904, validation MSE: 0.5541\n",
      "2025-06-23 22:13:30 [INFO]: Epoch 016 - training loss (MAE): 0.7581, validation MSE: 0.5220\n",
      "2025-06-23 22:13:41 [INFO]: Epoch 017 - training loss (MAE): 0.7182, validation MSE: 0.4953\n",
      "2025-06-23 22:13:52 [INFO]: Epoch 018 - training loss (MAE): 0.6823, validation MSE: 0.4599\n",
      "2025-06-23 22:14:02 [INFO]: Epoch 019 - training loss (MAE): 0.6586, validation MSE: 0.4229\n",
      "2025-06-23 22:14:13 [INFO]: Epoch 020 - training loss (MAE): 0.6457, validation MSE: 0.3880\n",
      "2025-06-23 22:14:24 [INFO]: Epoch 021 - training loss (MAE): 0.6273, validation MSE: 0.3588\n",
      "2025-06-23 22:14:35 [INFO]: Epoch 022 - training loss (MAE): 0.6115, validation MSE: 0.3409\n",
      "2025-06-23 22:14:46 [INFO]: Epoch 023 - training loss (MAE): 0.5579, validation MSE: 0.3200\n",
      "2025-06-23 22:14:56 [INFO]: Epoch 024 - training loss (MAE): 0.5408, validation MSE: 0.3040\n",
      "2025-06-23 22:15:08 [INFO]: Epoch 025 - training loss (MAE): 0.4997, validation MSE: 0.2876\n",
      "2025-06-23 22:15:08 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-23 22:15:08 [INFO]: Saved the model to ./brits_model\\20250623_T221032\\BRITS.pypots\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "rnn_hidden = 0\n",
    "# Initialize and fit BRITS models for each missing rate\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    print(f\"Training BRITS models for cluster {cluster_id}...\")\n",
    "    models[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        print(f\"Training model for missing rate {rate} in cluster {cluster_id}...\")\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        _, n_steps, n_features = train_data[cluster_id][key][\"X\"].shape\n",
    "\n",
    "        # Reduce complexity of model for less features\n",
    "        if cluster_id != len(clusters) - 1:\n",
    "            rnn_hidden = 16\n",
    "        else:\n",
    "            rnn_hidden = 32\n",
    "        \n",
    "        models[cluster_id][key] = intialize_BRITS(n_steps, n_features, rnn_hidden)\n",
    "        models[cluster_id][key].fit(train_data[cluster_id][key], val_set=val_data[cluster_id][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b09f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluation, since BRITS does not have passed ground truth without missing values.\n",
    "\n",
    "imputed = {}\n",
    "\n",
    "# Impute missing values using the trained models\n",
    "for cluster_id in range(len(clusters)):\n",
    "    imputed[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        imputed[cluster_id][key] = models[cluster_id][key].impute(val_data[cluster_id][key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d55299",
   "metadata": {},
   "source": [
    "### Unscale data before evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab456f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_group_feature_indices(columns):\n",
    "    group_feature_indices = {\n",
    "        'temp': [columns.index(col) for col in temp_cols if col in columns],\n",
    "        'humidity': [columns.index(col) for col in humidity_cols if col in columns],\n",
    "        'water_flow': [columns.index(col) for col in water_flow_cols if col in columns],\n",
    "        'air_flow': [columns.index(col) for col in air_flow_cols if col in columns],\n",
    "        'power': [columns.index(col) for col in power_cols if col in columns],\n",
    "        'speed': [columns.index(col) for col in speed_cols if col in columns],\n",
    "        # Binary skipped\n",
    "    }\n",
    "    return group_feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca1113ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "def unscale_imputed_by_group(imputed_data, cluster_id, group_feature_indices):\n",
    "    n_samples, n_steps, _ = imputed_data.shape\n",
    "    unscaled = np.zeros_like(imputed_data)\n",
    "\n",
    "    # Unscale for each group inside each cluster\n",
    "    for group_name, indices in group_feature_indices.items():\n",
    "        if not indices:\n",
    "            continue  # Skip if no features in this group\n",
    "\n",
    "        scaler_path = f\"{group_name}_scaler_{cluster_id}.pkl\"\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        \n",
    "        # Extract and reshape group data\n",
    "        group_data = imputed_data[:, :, indices].reshape(-1, len(indices))\n",
    "\n",
    "        # Inverse transform\n",
    "        group_data_unscaled = scaler.inverse_transform(group_data)\n",
    "\n",
    "        # Reshape back to original\n",
    "        group_data_unscaled = group_data_unscaled.reshape(n_samples, n_steps, len(indices))\n",
    "\n",
    "        # Insert into final tensor\n",
    "        for i, f_idx in enumerate(indices):\n",
    "            unscaled[:, :, f_idx] = group_data_unscaled[:, :, i]\n",
    "\n",
    "    return unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a8df37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_unscaled = {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    imputed_unscaled[cluster_id] = {}\n",
    "\n",
    "    # Extract column names of the cluster to recompute group_feature_indices\n",
    "    cluster_columns = list(clusters[cluster_id].columns)\n",
    "    group_feature_indices = build_group_feature_indices(cluster_columns)\n",
    "\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        imputed_unscaled[cluster_id][key] = unscale_imputed_by_group(\n",
    "            imputed_data=imputed[cluster_id][key],\n",
    "            cluster_id=cluster_id,\n",
    "            group_feature_indices=group_feature_indices\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dde7bf3",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a4b015",
   "metadata": {},
   "source": [
    "### Compute Average NRMSE per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6121a51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Cluster 0 Rate 5%: 0.036\n",
      "R² Cluster 0 Rate 20%: 0.015\n",
      "R² Cluster 0 Rate 60%: -0.329\n",
      "R² Cluster 0 Rate 90%: -0.396\n",
      "R² Cluster 1 Rate 5%: -0.770\n",
      "R² Cluster 1 Rate 20%: -1.008\n",
      "R² Cluster 1 Rate 60%: -1.239\n",
      "R² Cluster 1 Rate 90%: -2.139\n",
      "R² Cluster 2 Rate 5%: 0.725\n",
      "R² Cluster 2 Rate 20%: 0.709\n",
      "R² Cluster 2 Rate 60%: 0.621\n",
      "R² Cluster 2 Rate 90%: 0.387\n",
      "R² Cluster 3 Rate 5%: 0.909\n",
      "R² Cluster 3 Rate 20%: 0.715\n",
      "R² Cluster 3 Rate 60%: 0.812\n",
      "R² Cluster 3 Rate 90%: -0.033\n",
      "R² Cluster 4 Rate 5%: 0.597\n",
      "R² Cluster 4 Rate 20%: 0.826\n",
      "R² Cluster 4 Rate 60%: 0.311\n",
      "R² Cluster 4 Rate 90%: -0.422\n",
      "R² Cluster 5 Rate 5%: 0.022\n",
      "R² Cluster 5 Rate 20%: -0.044\n",
      "R² Cluster 5 Rate 60%: -0.134\n",
      "R² Cluster 5 Rate 90%: -0.371\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_scores = {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    r2_scores[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        imputed = imputed_unscaled[cluster_id][key]\n",
    "        original = X_val_full_unscaled_seq_tensor[cluster_id]\n",
    "        mask = val_masks_seq[cluster_id][key]\n",
    "\n",
    "        # Initialize list for per-feature R²\n",
    "        feature_r2 = []\n",
    "\n",
    "        for f in range(original.shape[2]):  # loop over features\n",
    "            f_mask = mask[:, :, f]\n",
    "            if not np.any(f_mask):\n",
    "                continue  # skip if no missing values for this feature\n",
    "\n",
    "            y_true = original[:, :, f][f_mask]\n",
    "            y_pred = imputed[:, :, f][f_mask]\n",
    "\n",
    "            if len(y_true) < 2:\n",
    "                continue  # not enough points to compute R²\n",
    "\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            feature_r2.append(r2)\n",
    "\n",
    "        if feature_r2:\n",
    "            r2_scores[cluster_id][key] = np.mean(feature_r2)\n",
    "        else:\n",
    "            r2_scores[cluster_id][key] = np.nan \n",
    "\n",
    "        print(f\"R² Cluster {cluster_id} Rate {rate*100:.0f}%: {r2_scores[cluster_id][key]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66f09187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE Cluster 0 Rate 5.0%: 73.61%\n",
      "SMAPE Cluster 0 Rate 20.0%: 76.58%\n",
      "SMAPE Cluster 0 Rate 60.0%: 82.12%\n",
      "SMAPE Cluster 0 Rate 90.0%: 81.25%\n",
      "SMAPE Cluster 1 Rate 5.0%: 47.64%\n",
      "SMAPE Cluster 1 Rate 20.0%: 42.72%\n",
      "SMAPE Cluster 1 Rate 60.0%: 47.11%\n",
      "SMAPE Cluster 1 Rate 90.0%: 60.07%\n",
      "SMAPE Cluster 2 Rate 5.0%: 50.40%\n",
      "SMAPE Cluster 2 Rate 20.0%: 50.60%\n",
      "SMAPE Cluster 2 Rate 60.0%: 51.20%\n",
      "SMAPE Cluster 2 Rate 90.0%: 52.29%\n",
      "SMAPE Cluster 3 Rate 5.0%: 140.75%\n",
      "SMAPE Cluster 3 Rate 20.0%: 145.59%\n",
      "SMAPE Cluster 3 Rate 60.0%: 142.21%\n",
      "SMAPE Cluster 3 Rate 90.0%: 170.13%\n",
      "SMAPE Cluster 4 Rate 5.0%: 3.12%\n",
      "SMAPE Cluster 4 Rate 20.0%: 1.83%\n",
      "SMAPE Cluster 4 Rate 60.0%: 3.40%\n",
      "SMAPE Cluster 4 Rate 90.0%: 7.13%\n",
      "SMAPE Cluster 5 Rate 5.0%: 51.72%\n",
      "SMAPE Cluster 5 Rate 20.0%: 51.87%\n",
      "SMAPE Cluster 5 Rate 60.0%: 52.83%\n",
      "SMAPE Cluster 5 Rate 90.0%: 55.56%\n"
     ]
    }
   ],
   "source": [
    "smape = {}\n",
    "for cluster_id in range(len(clusters)):\n",
    "    smape[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        imputed = imputed_unscaled[cluster_id][key]  # shape (n_samples, n_steps, n_features)\n",
    "        original = X_val_full_unscaled_seq_tensor[cluster_id]  # same shape\n",
    "        mask = val_masks_seq[cluster_id][key]  # same shape (bool mask)\n",
    "\n",
    "        n_samples, n_steps, n_features = original.shape\n",
    "\n",
    "        feature_smapes = []\n",
    "        for f in range(n_features):\n",
    "            # Select the mask and data for feature f\n",
    "            f_mask = mask[:, :, f]\n",
    "            if not np.any(f_mask):\n",
    "                continue  # skip if no missing values for this feature\n",
    "\n",
    "            numerator = np.abs(imputed[:, :, f][f_mask] - original[:, :, f][f_mask])\n",
    "            denominator = np.abs(imputed[:, :, f][f_mask]) + np.abs(original[:, :, f][f_mask]) + 1e-8\n",
    "            smape_f = 100 * np.mean(2 * numerator / denominator)\n",
    "            feature_smapes.append(smape_f)\n",
    "\n",
    "        smape[cluster_id][key] = np.mean(feature_smapes) if feature_smapes else np.nan\n",
    "        print(f\"SMAPE Cluster {cluster_id} Rate {rate*100}%: {smape[cluster_id][key]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c3072",
   "metadata": {},
   "source": [
    "### Average errors per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f5647fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_per_cluster = {i: X_val_full_unscaled_seq_tensor[i].shape[-1] for i in range(len(clusters))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8571d9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4, 1: 11, 2: 4, 3: 2, 4: 3, 5: 26}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4bb9d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average NRMSE for rate 5.0%: -0.08%\n",
      "NRMSE for full at rate 5.0%: 0.02%\n",
      "Weighted Average NRMSE for rate 20.0%: -0.18%\n",
      "NRMSE for full at rate 20.0%: -0.04%\n",
      "Weighted Average NRMSE for rate 60.0%: -0.41%\n",
      "NRMSE for full at rate 60.0%: -0.13%\n",
      "Weighted Average NRMSE for rate 90.0%: -1.04%\n",
      "NRMSE for full at rate 90.0%: -0.37%\n"
     ]
    }
   ],
   "source": [
    "n_clusters = len(clusters) - 1  # number of actual clusters\n",
    "flow_all_id = len(clusters) - 1  # index of the full dataset\n",
    "\n",
    "avg_r2_cluster = {}\n",
    "r2_all = {}\n",
    "\n",
    "for rate in missing_rates:\n",
    "    key = int(rate * 100)\n",
    "\n",
    "    # Gather NRMSE and weights (number of features per cluster)\n",
    "    r2_values = np.array([r2_scores[cluster_id][key] for cluster_id in range(n_clusters)])\n",
    "    feature_counts = np.array([features_per_cluster[cluster_id] for cluster_id in range(n_clusters)])\n",
    "\n",
    "    # Compute weighted average\n",
    "    weighted_avg = np.average(r2_values, weights=feature_counts)\n",
    "    \n",
    "    avg_r2_cluster[key] = weighted_avg\n",
    "    r2_all[key] = r2_scores[flow_all_id][key]  # for full feature set\n",
    "\n",
    "    print(f\"Weighted Average NRMSE for rate {rate*100}%: {avg_r2_cluster[key]:.2f}%\")\n",
    "    print(f\"NRMSE for full at rate {rate*100}%: {r2_all[key]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49077fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average SMAPE for rate 5.0%: 54.62%\n",
      "SMAPE for full at rate 5.0%: 51.72%\n",
      "Weighted Average SMAPE for rate 20.0%: 53.14%\n",
      "SMAPE for full at rate 20.0%: 51.87%\n",
      "Weighted Average SMAPE for rate 60.0%: 56.09%\n",
      "SMAPE for full at rate 60.0%: 52.83%\n",
      "Weighted Average SMAPE for rate 90.0%: 64.85%\n",
      "SMAPE for full at rate 90.0%: 55.56%\n"
     ]
    }
   ],
   "source": [
    "avg_smape_cluster = {}\n",
    "smape_all = {}\n",
    "\n",
    "for rate in missing_rates:\n",
    "    key = int(rate * 100)\n",
    "    \n",
    "    # Gather SMAPE and weights (number of features per cluster)\n",
    "    smape_values = np.array([smape[cluster_id][key] for cluster_id in range(n_clusters)])\n",
    "    feature_counts = np.array([features_per_cluster[cluster_id] for cluster_id in range(n_clusters)])\n",
    "    \n",
    "    # Compute weighted average\n",
    "    weighted_avg = np.average(smape_values, weights=feature_counts)\n",
    "    \n",
    "    avg_smape_cluster[key] = weighted_avg\n",
    "    smape_all[key] = smape[flow_all_id][key]  # for full feature set\n",
    "    \n",
    "    print(f\"Weighted Average SMAPE for rate {rate*100}%: {avg_smape_cluster[key]:.2f}%\")\n",
    "    print(f\"SMAPE for full at rate {rate*100}%: {smape_all[key]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "533c079a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_missing_vs_observed(data, mask, feature_name=\"flow\"):\n",
    "    \"\"\"\n",
    "    data: 1D array of original values\n",
    "    mask: 1D boolean array, True if missing\n",
    "    feature_name: for labeling\n",
    "    \"\"\"\n",
    "    data_missing = data[mask]\n",
    "    data_observed = data[~mask]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(data_observed, color='blue', label='Observed', kde=True, stat=\"density\", bins=30)\n",
    "    sns.histplot(data_missing, color='red', label='Missing', kde=True, stat=\"density\", bins=30)\n",
    "    plt.title(f\"Distribution of {feature_name} - Observed vs Missing\")\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_missing_vs_observed(X_val_full_unscaled_seq_tensor[0].flatten(), val_masks_seq[0][90].flatten(), feature_name=\"Flow at 20% missingness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e8d714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Missingness levels\n",
    "missing_levels = ['5%', '20%', '60%', '90%']\n",
    "\n",
    "# Bar chart setup\n",
    "x = np.arange(len(missing_levels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# --- MAE plot ---\n",
    "ax[0].bar(x - width/2, r2_all.values(), width, label='Without Semantics', color='tab:blue')\n",
    "ax[0].bar(x + width/2, avg_r2_cluster.values(), width, label='With Semantics', color='tab:orange')\n",
    "ax[0].set_ylabel('MAE')\n",
    "ax[0].set_title('MAE by Missingness Level')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# --- SMAPE plot ---\n",
    "ax[1].bar(x - width/2, smape_all.values(), width, label='Without Semantics', color='tab:blue')\n",
    "ax[1].bar(x + width/2, avg_smape_cluster.values(), width, label='With Semantics', color='tab:orange')\n",
    "ax[1].set_ylabel('SMAPE (%)')\n",
    "ax[1].set_title('SMAPE by Missingness Level')\n",
    "ax[1].set_xticks(x)\n",
    "ax[1].set_xticklabels(missing_levels)\n",
    "ax[1].legend()\n",
    "ax[1].grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
