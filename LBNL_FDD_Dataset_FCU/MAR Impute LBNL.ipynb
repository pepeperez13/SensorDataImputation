{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b07a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc3e8d",
   "metadata": {},
   "source": [
    "## Get measurements from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5161bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_readings = pd.read_csv(\"D:\\Master\\Thesis\\Code\\LBNL_FDD_Dataset_FCU\\measurements_LBNL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3646f3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>measurement</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-01 00:00:00</td>\n",
       "      <td>FCU_CTRL</td>\n",
       "      <td>2.000</td>\n",
       "      <td>FCU_CTRL_2018-02-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-01 00:10:00</td>\n",
       "      <td>FCU_CTRL</td>\n",
       "      <td>2.000</td>\n",
       "      <td>FCU_CTRL_2018-02-01 00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-01 00:20:00</td>\n",
       "      <td>FCU_CTRL</td>\n",
       "      <td>2.000</td>\n",
       "      <td>FCU_CTRL_2018-02-01 00:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-02-01 00:30:00</td>\n",
       "      <td>FCU_CTRL</td>\n",
       "      <td>2.000</td>\n",
       "      <td>FCU_CTRL_2018-02-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-02-01 00:40:00</td>\n",
       "      <td>FCU_CTRL</td>\n",
       "      <td>2.000</td>\n",
       "      <td>FCU_CTRL_2018-02-01 00:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793723</th>\n",
       "      <td>793723</td>\n",
       "      <td>2018-08-31 23:10:00</td>\n",
       "      <td>FCU_RA_HUMD</td>\n",
       "      <td>80.966</td>\n",
       "      <td>FCU_RA_HUMD_2018-08-31 23:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793724</th>\n",
       "      <td>793724</td>\n",
       "      <td>2018-08-31 23:20:00</td>\n",
       "      <td>FCU_RA_HUMD</td>\n",
       "      <td>81.204</td>\n",
       "      <td>FCU_RA_HUMD_2018-08-31 23:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793725</th>\n",
       "      <td>793725</td>\n",
       "      <td>2018-08-31 23:30:00</td>\n",
       "      <td>FCU_RA_HUMD</td>\n",
       "      <td>81.387</td>\n",
       "      <td>FCU_RA_HUMD_2018-08-31 23:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793726</th>\n",
       "      <td>793726</td>\n",
       "      <td>2018-08-31 23:40:00</td>\n",
       "      <td>FCU_RA_HUMD</td>\n",
       "      <td>81.536</td>\n",
       "      <td>FCU_RA_HUMD_2018-08-31 23:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793727</th>\n",
       "      <td>793727</td>\n",
       "      <td>2018-08-31 23:50:00</td>\n",
       "      <td>FCU_RA_HUMD</td>\n",
       "      <td>81.664</td>\n",
       "      <td>FCU_RA_HUMD_2018-08-31 23:50:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>793728 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0             Datetime    sensor_id  measurement  \\\n",
       "0                0  2018-02-01 00:00:00     FCU_CTRL        2.000   \n",
       "1                1  2018-02-01 00:10:00     FCU_CTRL        2.000   \n",
       "2                2  2018-02-01 00:20:00     FCU_CTRL        2.000   \n",
       "3                3  2018-02-01 00:30:00     FCU_CTRL        2.000   \n",
       "4                4  2018-02-01 00:40:00     FCU_CTRL        2.000   \n",
       "...            ...                  ...          ...          ...   \n",
       "793723      793723  2018-08-31 23:10:00  FCU_RA_HUMD       80.966   \n",
       "793724      793724  2018-08-31 23:20:00  FCU_RA_HUMD       81.204   \n",
       "793725      793725  2018-08-31 23:30:00  FCU_RA_HUMD       81.387   \n",
       "793726      793726  2018-08-31 23:40:00  FCU_RA_HUMD       81.536   \n",
       "793727      793727  2018-08-31 23:50:00  FCU_RA_HUMD       81.664   \n",
       "\n",
       "                              unique_id  \n",
       "0          FCU_CTRL_2018-02-01 00:00:00  \n",
       "1          FCU_CTRL_2018-02-01 00:10:00  \n",
       "2          FCU_CTRL_2018-02-01 00:20:00  \n",
       "3          FCU_CTRL_2018-02-01 00:30:00  \n",
       "4          FCU_CTRL_2018-02-01 00:40:00  \n",
       "...                                 ...  \n",
       "793723  FCU_RA_HUMD_2018-08-31 23:10:00  \n",
       "793724  FCU_RA_HUMD_2018-08-31 23:20:00  \n",
       "793725  FCU_RA_HUMD_2018-08-31 23:30:00  \n",
       "793726  FCU_RA_HUMD_2018-08-31 23:40:00  \n",
       "793727  FCU_RA_HUMD_2018-08-31 23:50:00  \n",
       "\n",
       "[793728 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74ad359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df = sensor_readings.pivot(index='Datetime', columns='sensor_id', values='measurement')\n",
    "pivoted_df.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b167858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FCU_CLG_GPM</th>\n",
       "      <th>FCU_CLG_RWT</th>\n",
       "      <th>FCU_CTRL</th>\n",
       "      <th>FCU_CVLV</th>\n",
       "      <th>FCU_CVLV_DM</th>\n",
       "      <th>FCU_DAT</th>\n",
       "      <th>FCU_DA_CFM</th>\n",
       "      <th>FCU_DA_HUMD</th>\n",
       "      <th>FCU_DMPR</th>\n",
       "      <th>FCU_DMPR_DM</th>\n",
       "      <th>...</th>\n",
       "      <th>FCU_OAT</th>\n",
       "      <th>FCU_OA_CFM</th>\n",
       "      <th>FCU_OA_HUMD</th>\n",
       "      <th>FCU_RAT</th>\n",
       "      <th>FCU_RA_HUMD</th>\n",
       "      <th>FCU_SPD</th>\n",
       "      <th>FCU_WAT</th>\n",
       "      <th>RMCLGSPT</th>\n",
       "      <th>RMHTGSPT</th>\n",
       "      <th>RM_TEMP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>54.652</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.186</td>\n",
       "      <td>0.007</td>\n",
       "      <td>71.668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.144</td>\n",
       "      <td>0.88</td>\n",
       "      <td>82.015</td>\n",
       "      <td>64.898</td>\n",
       "      <td>87.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:10:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>54.284</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.874</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>72.390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.214</td>\n",
       "      <td>0.88</td>\n",
       "      <td>76.755</td>\n",
       "      <td>64.754</td>\n",
       "      <td>88.086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:20:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53.912</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.558</td>\n",
       "      <td>0.001</td>\n",
       "      <td>73.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.284</td>\n",
       "      <td>0.88</td>\n",
       "      <td>71.091</td>\n",
       "      <td>64.608</td>\n",
       "      <td>88.264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53.535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.235</td>\n",
       "      <td>0.011</td>\n",
       "      <td>73.912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.354</td>\n",
       "      <td>0.88</td>\n",
       "      <td>65.328</td>\n",
       "      <td>64.463</td>\n",
       "      <td>88.411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:40:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53.155</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.909</td>\n",
       "      <td>0.014</td>\n",
       "      <td>74.713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.424</td>\n",
       "      <td>0.88</td>\n",
       "      <td>59.767</td>\n",
       "      <td>64.318</td>\n",
       "      <td>88.525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:10:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>67.976</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.763</td>\n",
       "      <td>0.010</td>\n",
       "      <td>49.449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.190</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84.538</td>\n",
       "      <td>75.970</td>\n",
       "      <td>80.966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:20:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.875</td>\n",
       "      <td>0.003</td>\n",
       "      <td>49.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.985</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84.690</td>\n",
       "      <td>75.908</td>\n",
       "      <td>81.204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.524</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.962</td>\n",
       "      <td>0.009</td>\n",
       "      <td>49.075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.777</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84.672</td>\n",
       "      <td>75.868</td>\n",
       "      <td>81.387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:40:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.774</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.020</td>\n",
       "      <td>0.008</td>\n",
       "      <td>48.967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.565</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84.508</td>\n",
       "      <td>75.841</td>\n",
       "      <td>81.536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:50:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>69.001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.055</td>\n",
       "      <td>0.002</td>\n",
       "      <td>48.903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.350</td>\n",
       "      <td>0.88</td>\n",
       "      <td>84.220</td>\n",
       "      <td>75.822</td>\n",
       "      <td>81.664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>75.822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30528 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FCU_CLG_GPM  FCU_CLG_RWT  FCU_CTRL  FCU_CVLV  \\\n",
       "Datetime                                                            \n",
       "2018-02-01 00:00:00          0.0       54.652       2.0       0.0   \n",
       "2018-02-01 00:10:00          0.0       54.284       2.0       0.0   \n",
       "2018-02-01 00:20:00          0.0       53.912       2.0       0.0   \n",
       "2018-02-01 00:30:00          0.0       53.535       2.0       0.0   \n",
       "2018-02-01 00:40:00          0.0       53.155       2.0       0.0   \n",
       "...                          ...          ...       ...       ...   \n",
       "2018-08-31 23:10:00          0.0       67.976       2.0       0.0   \n",
       "2018-08-31 23:20:00          0.0       68.258       2.0       0.0   \n",
       "2018-08-31 23:30:00          0.0       68.524       2.0       0.0   \n",
       "2018-08-31 23:40:00          0.0       68.774       2.0       0.0   \n",
       "2018-08-31 23:50:00          0.0       69.001       2.0       0.0   \n",
       "\n",
       "                     FCU_CVLV_DM  FCU_DAT  FCU_DA_CFM  FCU_DA_HUMD  FCU_DMPR  \\\n",
       "Datetime                                                                       \n",
       "2018-02-01 00:00:00          0.0   58.186       0.007       71.668       0.0   \n",
       "2018-02-01 00:10:00          0.0   57.874      -0.004       72.390       0.0   \n",
       "2018-02-01 00:20:00          0.0   57.558       0.001       73.137       0.0   \n",
       "2018-02-01 00:30:00          0.0   57.235       0.011       73.912       0.0   \n",
       "2018-02-01 00:40:00          0.0   56.909       0.014       74.713       0.0   \n",
       "...                          ...      ...         ...          ...       ...   \n",
       "2018-08-31 23:10:00          0.0   68.763       0.010       49.449       0.0   \n",
       "2018-08-31 23:20:00          0.0   68.875       0.003       49.234       0.0   \n",
       "2018-08-31 23:30:00          0.0   68.962       0.009       49.075       0.0   \n",
       "2018-08-31 23:40:00          0.0   69.020       0.008       48.967       0.0   \n",
       "2018-08-31 23:50:00          0.0   69.055       0.002       48.903       0.0   \n",
       "\n",
       "                     FCU_DMPR_DM  ...  FCU_OAT  FCU_OA_CFM  FCU_OA_HUMD  \\\n",
       "Datetime                          ...                                     \n",
       "2018-02-01 00:00:00          0.0  ...   16.144        0.88       82.015   \n",
       "2018-02-01 00:10:00          0.0  ...   15.214        0.88       76.755   \n",
       "2018-02-01 00:20:00          0.0  ...   14.284        0.88       71.091   \n",
       "2018-02-01 00:30:00          0.0  ...   13.354        0.88       65.328   \n",
       "2018-02-01 00:40:00          0.0  ...   12.424        0.88       59.767   \n",
       "...                          ...  ...      ...         ...          ...   \n",
       "2018-08-31 23:10:00          0.0  ...   74.190        0.88       84.538   \n",
       "2018-08-31 23:20:00          0.0  ...   73.985        0.88       84.690   \n",
       "2018-08-31 23:30:00          0.0  ...   73.777        0.88       84.672   \n",
       "2018-08-31 23:40:00          0.0  ...   73.565        0.88       84.508   \n",
       "2018-08-31 23:50:00          0.0  ...   73.350        0.88       84.220   \n",
       "\n",
       "                     FCU_RAT  FCU_RA_HUMD  FCU_SPD  FCU_WAT  RMCLGSPT  \\\n",
       "Datetime                                                                \n",
       "2018-02-01 00:00:00   64.898       87.883      0.0      0.0      85.0   \n",
       "2018-02-01 00:10:00   64.754       88.086      0.0      0.0      85.0   \n",
       "2018-02-01 00:20:00   64.608       88.264      0.0      0.0      85.0   \n",
       "2018-02-01 00:30:00   64.463       88.411      0.0      0.0      85.0   \n",
       "2018-02-01 00:40:00   64.318       88.525      0.0      0.0      85.0   \n",
       "...                      ...          ...      ...      ...       ...   \n",
       "2018-08-31 23:10:00   75.970       80.966      0.0      0.0      85.0   \n",
       "2018-08-31 23:20:00   75.908       81.204      0.0      0.0      85.0   \n",
       "2018-08-31 23:30:00   75.868       81.387      0.0      0.0      85.0   \n",
       "2018-08-31 23:40:00   75.841       81.536      0.0      0.0      85.0   \n",
       "2018-08-31 23:50:00   75.822       81.664      0.0      0.0      85.0   \n",
       "\n",
       "                     RMHTGSPT  RM_TEMP  \n",
       "Datetime                                \n",
       "2018-02-01 00:00:00      55.0   64.898  \n",
       "2018-02-01 00:10:00      55.0   64.754  \n",
       "2018-02-01 00:20:00      55.0   64.608  \n",
       "2018-02-01 00:30:00      55.0   64.463  \n",
       "2018-02-01 00:40:00      55.0   64.318  \n",
       "...                       ...      ...  \n",
       "2018-08-31 23:10:00      55.0   75.970  \n",
       "2018-08-31 23:20:00      55.0   75.908  \n",
       "2018-08-31 23:30:00      55.0   75.868  \n",
       "2018-08-31 23:40:00      55.0   75.841  \n",
       "2018-08-31 23:50:00      55.0   75.822  \n",
       "\n",
       "[30528 rows x 26 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be116b2",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a5060",
   "metadata": {},
   "source": [
    "### Split train/val, and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85c7ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "temp_cols, humidity_cols, air_flow_cols, water_flow_cols, power_cols, binary_cols, speed_cols = [], [], [], [], [], [], []\n",
    "\n",
    "for column in pivoted_df.columns:\n",
    "    if \"HUMD\" in column:\n",
    "        humidity_cols.append(column)\n",
    "    elif \"GPM\" in column:\n",
    "        water_flow_cols.append(column)\n",
    "    elif \"CFM\" in column:\n",
    "        air_flow_cols.append(column)\n",
    "    elif \"WAT\" in column:\n",
    "        power_cols.append(column)\n",
    "    elif any(sub in column for sub in [\"CTRL\", \"CVLV\", \"HVLV\", \"DMPR\"]):\n",
    "        binary_cols.append(column)\n",
    "    elif \"SPD\" in column:\n",
    "        speed_cols.append(column)\n",
    "    else:\n",
    "        temp_cols.append(column)\n",
    "\n",
    "# Create scalers for each feature type\n",
    "scalers = {\n",
    "    'temp': StandardScaler(),\n",
    "    'humidity': MinMaxScaler(),\n",
    "    'water_flow': StandardScaler(),\n",
    "    'air_flow': StandardScaler(),\n",
    "    'power': StandardScaler(),\n",
    "    'binary': None,\n",
    "    'speed': StandardScaler()\n",
    "}\n",
    "\n",
    "column_groups = {\n",
    "    'temp': temp_cols,\n",
    "    'humidity': humidity_cols,\n",
    "    'water_flow': water_flow_cols,\n",
    "    'air_flow': air_flow_cols,\n",
    "    'power': power_cols,\n",
    "    'binary': binary_cols,\n",
    "    'speed': speed_cols\n",
    "}\n",
    "\n",
    "\n",
    "def split_scale(measurements, cluster):\n",
    "    # Train/validation split\n",
    "    X_train_full, X_val_full = train_test_split(measurements, test_size=0.2, shuffle = False, random_state=42)\n",
    "\n",
    "    # Deep copies\n",
    "    X_train_full_scaled = X_train_full.copy()\n",
    "    X_val_full_scaled = X_val_full.copy()\n",
    "\n",
    "    fitted_scalers = {}\n",
    "\n",
    "    for group, cols in column_groups.items():\n",
    "        # Only use columns present in the current data\n",
    "        present_cols = [col for col in cols if col in X_train_full.columns]\n",
    "\n",
    "        if not present_cols:\n",
    "            continue  # Skip if no columns from this group are in the dataset\n",
    "\n",
    "        scaler = scalers[group]\n",
    "        if scaler is not None:\n",
    "            scaler_instance = scaler.fit(X_train_full[present_cols])\n",
    "            X_train_full_scaled[present_cols] = scaler_instance.transform(X_train_full[present_cols])\n",
    "            X_val_full_scaled[present_cols] = scaler_instance.transform(X_val_full[present_cols])\n",
    "            joblib.dump(scaler_instance, f\"{group}_scaler_{cluster}.pkl\")\n",
    "            fitted_scalers[group] = scaler_instance\n",
    "\n",
    "    return X_train_full_scaled, X_val_full_scaled, X_train_full, X_val_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090c844",
   "metadata": {},
   "source": [
    "### Select semantically relevant pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cooling_coil = pivoted_df[['FCU_CVLV_DM', 'FCU_CLG_GPM', 'FCU_CVLV', 'FCU_CLG_RWT']]\n",
    "c_FCU = pivoted_df[['FCU_RA_HUMD', 'FCU_DA_HUMD', 'FCU_RAT', 'FCU_MAT', 'FCU_OAT', 'FCU_OA_CFM', 'FCU_CTRL', 'FCU_DAT', 'FCU_DA_CFM', 'FCU_MA_HUMD', 'FCU_OA_HUMD']]\n",
    "c_heating_coil = pivoted_df[['FCU_HVLV_DM', 'FCU_HVLV', 'FCU_HTG_GPM', 'FCU_HTG_RWT']]\n",
    "c_supply_air = pivoted_df[['FCU_WAT', 'FCU_SPD']]\n",
    "c_zone = pivoted_df[['RMCLGSPT', 'RM_TEMP', 'RMHTGSPT']]\n",
    "c_all = pivoted_df.copy()\n",
    "\n",
    "# Initialize the containers\n",
    "X_train_full_scaled = {}\n",
    "X_val_full_scaled = {}\n",
    "X_train_full_unscaled = {}\n",
    "X_val_full_unscaled = {}\n",
    "clusters = [c_cooling_coil, c_FCU, c_supply_air, c_zone, c_all]\n",
    "\n",
    "# Iterate over the clusters\n",
    "for i, cluster in enumerate(clusters):\n",
    "    X_train_full_scaled[i], X_val_full_scaled[i], X_train_full_unscaled[i], X_val_full_unscaled[i] = split_scale(cluster, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f7840a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FCU_CVLV_DM</th>\n",
       "      <th>FCU_CLG_GPM</th>\n",
       "      <th>FCU_CVLV</th>\n",
       "      <th>FCU_CLG_RWT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>54.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:10:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>54.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:20:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>53.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:30:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>53.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:40:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>53.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 13:30:00</th>\n",
       "      <td>0.230</td>\n",
       "      <td>1.079</td>\n",
       "      <td>0.230</td>\n",
       "      <td>63.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 13:40:00</th>\n",
       "      <td>0.230</td>\n",
       "      <td>1.095</td>\n",
       "      <td>0.230</td>\n",
       "      <td>63.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 13:50:00</th>\n",
       "      <td>0.235</td>\n",
       "      <td>1.118</td>\n",
       "      <td>0.235</td>\n",
       "      <td>63.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:00:00</th>\n",
       "      <td>0.240</td>\n",
       "      <td>1.141</td>\n",
       "      <td>0.240</td>\n",
       "      <td>63.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:10:00</th>\n",
       "      <td>0.240</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.240</td>\n",
       "      <td>63.514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24422 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FCU_CVLV_DM  FCU_CLG_GPM  FCU_CVLV  FCU_CLG_RWT\n",
       "Datetime                                                            \n",
       "2018-02-01 00:00:00        0.000        0.000     0.000       54.652\n",
       "2018-02-01 00:10:00        0.000        0.000     0.000       54.284\n",
       "2018-02-01 00:20:00        0.000        0.000     0.000       53.912\n",
       "2018-02-01 00:30:00        0.000        0.000     0.000       53.535\n",
       "2018-02-01 00:40:00        0.000        0.000     0.000       53.155\n",
       "...                          ...          ...       ...          ...\n",
       "2018-07-20 13:30:00        0.230        1.079     0.230       63.779\n",
       "2018-07-20 13:40:00        0.230        1.095     0.230       63.745\n",
       "2018-07-20 13:50:00        0.235        1.118     0.235       63.675\n",
       "2018-07-20 14:00:00        0.240        1.141     0.240       63.592\n",
       "2018-07-20 14:10:00        0.240        1.163     0.240       63.514\n",
       "\n",
       "[24422 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full_unscaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b85c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_3d(data, window_size, stride):\n",
    "    \"\"\"\n",
    "    Converts a long time series [1, T, F] into [N, window_size, F]\n",
    "    \"\"\"\n",
    "    data = data.squeeze(0)  # [T, F]\n",
    "    total_steps, n_features = data.shape\n",
    "    windows = []\n",
    "\n",
    "    for i in range(0, total_steps - window_size + 1, stride):\n",
    "        window = data[i:i+window_size]\n",
    "        windows.append(window)\n",
    "\n",
    "    return np.stack(windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac3e0a",
   "metadata": {},
   "source": [
    "### Introduce MAR Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b9f98fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FCU_WAT</th>\n",
       "      <th>FCU_SPD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:20:00</th>\n",
       "      <td>1.360936</td>\n",
       "      <td>1.386426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:30:00</th>\n",
       "      <td>1.360936</td>\n",
       "      <td>1.386426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:40:00</th>\n",
       "      <td>1.360936</td>\n",
       "      <td>1.386426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 14:50:00</th>\n",
       "      <td>1.360936</td>\n",
       "      <td>1.386426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20 15:00:00</th>\n",
       "      <td>1.360936</td>\n",
       "      <td>1.386426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:10:00</th>\n",
       "      <td>-0.726345</td>\n",
       "      <td>-0.732504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:20:00</th>\n",
       "      <td>-0.726345</td>\n",
       "      <td>-0.732504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:30:00</th>\n",
       "      <td>-0.726345</td>\n",
       "      <td>-0.732504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:40:00</th>\n",
       "      <td>-0.726345</td>\n",
       "      <td>-0.732504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-31 23:50:00</th>\n",
       "      <td>-0.726345</td>\n",
       "      <td>-0.732504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6106 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      FCU_WAT   FCU_SPD\n",
       "Datetime                               \n",
       "2018-07-20 14:20:00  1.360936  1.386426\n",
       "2018-07-20 14:30:00  1.360936  1.386426\n",
       "2018-07-20 14:40:00  1.360936  1.386426\n",
       "2018-07-20 14:50:00  1.360936  1.386426\n",
       "2018-07-20 15:00:00  1.360936  1.386426\n",
       "...                       ...       ...\n",
       "2018-08-31 23:10:00 -0.726345 -0.732504\n",
       "2018-08-31 23:20:00 -0.726345 -0.732504\n",
       "2018-08-31 23:30:00 -0.726345 -0.732504\n",
       "2018-08-31 23:40:00 -0.726345 -0.732504\n",
       "2018-08-31 23:50:00 -0.726345 -0.732504\n",
       "\n",
       "[6106 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_full_scaled[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16d71795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing 5.0% missingness for cluster 0 with key 5\n",
      "Actual missing rate: 2.42%\n",
      "Introducing 20.0% missingness for cluster 0 with key 20\n",
      "Actual missing rate: 10.07%\n",
      "Introducing 60.0% missingness for cluster 0 with key 60\n",
      "Actual missing rate: 29.98%\n",
      "Introducing 90.0% missingness for cluster 0 with key 90\n",
      "Actual missing rate: 44.94%\n",
      "Introducing 5.0% missingness for cluster 1 with key 5\n",
      "Actual missing rate: 2.27%\n",
      "Introducing 20.0% missingness for cluster 1 with key 20\n",
      "Actual missing rate: 9.12%\n",
      "Introducing 60.0% missingness for cluster 1 with key 60\n",
      "Actual missing rate: 27.24%\n",
      "Introducing 90.0% missingness for cluster 1 with key 90\n",
      "Actual missing rate: 40.95%\n",
      "Introducing 5.0% missingness for cluster 2 with key 5\n",
      "Actual missing rate: 2.57%\n",
      "Introducing 20.0% missingness for cluster 2 with key 20\n",
      "Actual missing rate: 10.27%\n",
      "Introducing 60.0% missingness for cluster 2 with key 60\n",
      "Actual missing rate: 29.91%\n",
      "Introducing 90.0% missingness for cluster 2 with key 90\n",
      "Actual missing rate: 45.15%\n",
      "Introducing 5.0% missingness for cluster 3 with key 5\n",
      "Actual missing rate: 3.34%\n",
      "Introducing 20.0% missingness for cluster 3 with key 20\n",
      "Actual missing rate: 13.44%\n",
      "Introducing 60.0% missingness for cluster 3 with key 60\n",
      "Actual missing rate: 40.20%\n",
      "Introducing 90.0% missingness for cluster 3 with key 90\n",
      "Actual missing rate: 60.14%\n",
      "Introducing 5.0% missingness for cluster 4 with key 5\n",
      "Actual missing rate: 2.12%\n",
      "Introducing 20.0% missingness for cluster 4 with key 20\n",
      "Actual missing rate: 8.46%\n",
      "Introducing 60.0% missingness for cluster 4 with key 60\n",
      "Actual missing rate: 25.33%\n",
      "Introducing 90.0% missingness for cluster 4 with key 90\n",
      "Actual missing rate: 38.06%\n"
     ]
    }
   ],
   "source": [
    "from pygrinder import mar_logistic\n",
    "\n",
    "missing_rates = [0.05, 0.2, 0.6, 0.90]\n",
    "\n",
    "# Training and validation sets for each cluster\n",
    "X_train_incomplete = {}\n",
    "X_val_incomplete = {}\n",
    "train_masks = {}\n",
    "val_masks = {}\n",
    "X_train_seq = {}\n",
    "X_val_seq = {}\n",
    "train_masks_seq = {}\n",
    "val_masks_seq = {}\n",
    "\n",
    "# Full tensors for each cluster\n",
    "X_train_full_tensor = {}\n",
    "X_val_full_tensor = {}\n",
    "X_val_full_seq = {}\n",
    "X_train_full_seq = {}\n",
    "X_train_full_unscaled_seq_tensor = {}\n",
    "X_val_full_unscaled_seq_tensor = {}\n",
    "\n",
    "\n",
    "for cluster_id, flow_cluster in enumerate(clusters):\n",
    "    X_train_incomplete[cluster_id] = {}\n",
    "    X_val_incomplete[cluster_id] = {}\n",
    "    train_masks[cluster_id] = {}\n",
    "    val_masks[cluster_id] = {}\n",
    "    X_train_seq[cluster_id] = {}\n",
    "    X_val_seq[cluster_id] = {}\n",
    "    train_masks_seq[cluster_id] = {}\n",
    "    val_masks_seq[cluster_id] = {}\n",
    "\n",
    "    n_steps = 504  # 3.5 days each window\n",
    "    stride = 144  # 1 day stride\n",
    "\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        # Introduce missingness per cluster & rate\n",
    "        print(f\"Introducing {rate*100}% missingness for cluster {cluster_id} with key {key}\")\n",
    "\n",
    "        # Apply MNAR-x missingness\n",
    "        X_train_incomplete[cluster_id][key] = mar_logistic(X_train_full_scaled[cluster_id].values, obs_rate=0.6, missing_rate=rate)\n",
    "        X_val_incomplete[cluster_id][key] = mar_logistic(X_val_full_scaled[cluster_id].values, obs_rate=0.6, missing_rate=rate)\n",
    "\n",
    "        # Masks for missingness\n",
    "        train_masks[cluster_id][key] = np.isnan(X_train_incomplete[cluster_id][key])\n",
    "        val_masks[cluster_id][key] = np.isnan(X_val_incomplete[cluster_id][key])\n",
    "\n",
    "        actual_missing_rate = train_masks[cluster_id][key].mean()\n",
    "        print(f\"Actual missing rate: {actual_missing_rate:.2%}\")\n",
    "        \n",
    "        # Expand dims for batch axis (needed for sliding window)\n",
    "        X_train_tensor = np.expand_dims(X_train_incomplete[cluster_id][key], axis=0)\n",
    "        X_val_tensor = np.expand_dims(X_val_incomplete[cluster_id][key], axis=0)\n",
    "        train_mask_tensor = np.expand_dims(train_masks[cluster_id][key], axis=0)\n",
    "        val_mask_tensor = np.expand_dims(val_masks[cluster_id][key], axis=0)\n",
    "\n",
    "        # Sliding window on data\n",
    "        X_train_seq[cluster_id][key] = sliding_window_3d(X_train_tensor, window_size=n_steps, stride=stride)\n",
    "        X_val_seq[cluster_id][key] = sliding_window_3d(X_val_tensor, window_size=n_steps, stride=stride)\n",
    "\n",
    "        # Sliding window on masks\n",
    "        train_masks_seq[cluster_id][key] = sliding_window_3d(train_mask_tensor, window_size=n_steps, stride=stride)\n",
    "        val_masks_seq[cluster_id][key] = sliding_window_3d(val_mask_tensor, window_size=n_steps, stride=stride)\n",
    "\n",
    "\n",
    "    # Expand full training tensors\n",
    "    X_train_full_tensor[cluster_id] = np.expand_dims(X_train_full_scaled[cluster_id].values, axis = 0)\n",
    "\n",
    "    # Expand full validation tensors\n",
    "    X_val_full_tensor[cluster_id] = np.expand_dims(X_val_full_scaled[cluster_id].values, axis = 0)\n",
    "\n",
    "    # Convert scaled data to tensor\n",
    "    X_val_full_seq[cluster_id] = sliding_window_3d(X_val_full_tensor[cluster_id], window_size=n_steps, stride=stride)\n",
    "    X_train_full_seq[cluster_id] = sliding_window_3d(X_train_full_tensor[cluster_id], window_size=n_steps, stride=stride)\n",
    "\n",
    "    # Convert unscaled data to tensor\n",
    "    X_train_full_unscaled_values = np.expand_dims(X_train_full_unscaled[cluster_id].values, axis=0)\n",
    "    X_train_full_unscaled_seq_tensor[cluster_id] = sliding_window_3d(X_train_full_unscaled_values, window_size=n_steps, stride=stride)\n",
    "\n",
    "    X_val_full_unscaled_values = np.expand_dims(X_val_full_unscaled[cluster_id].values, axis=0)\n",
    "    X_val_full_unscaled_seq_tensor[cluster_id] = sliding_window_3d(X_val_full_unscaled_values, window_size=n_steps, stride=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "887a25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare the final datasets with 'X' (incomplete) and 'X_ori' (full data)\n",
    "\n",
    "# 20 percent missing\n",
    "train_data, val_data = {}, {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    train_data[cluster_id] = {}\n",
    "    val_data[cluster_id] = {}\n",
    "    \n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        \n",
    "        # Prepare the train and validation data dictionaries for each missing rate\n",
    "        train_data[cluster_id][key] = {\"X\": X_train_seq[cluster_id][key]}\n",
    "        val_data[cluster_id][key] = {\"X\": X_val_seq[cluster_id][key], \"X_ori\": X_val_full_seq[cluster_id]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222cb3dd",
   "metadata": {},
   "source": [
    "### BRITS Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f544ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pypots.imputation import BRITS\n",
    "from pypots.nn.modules.loss import MAE, MSE\n",
    "from pypots.optim.adam import Adam\n",
    "import torch\n",
    "\n",
    "def intialize_BRITS(n_steps, num_features, rnn_hidden_size):\n",
    "\n",
    "    # Basic configuration\n",
    "    model = BRITS(\n",
    "        n_steps=n_steps,\n",
    "        n_features=num_features,\n",
    "        rnn_hidden_size=rnn_hidden_size,               # Reasonable hidden size\n",
    "        batch_size=32,                    # Standard for most datasets\n",
    "        epochs=25,                       # Higher epochs for better convergence\n",
    "        patience=5,                      # Early stopping if no improvement\n",
    "        training_loss=MAE,                # MAE often performs well for imputation\n",
    "        validation_metric=MSE,           # Use MSE for validation comparison\n",
    "        optimizer=Adam,                   # Adam optimizer (default)\n",
    "        num_workers=0,                    # Adjust if using DataLoader with multiprocessing\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # Use GPU if available\n",
    "        saving_path=\"./brits_model\",     # Directory to save model checkpoints\n",
    "        model_saving_strategy=\"best\",    # Save best model only\n",
    "        verbose=True                      # Print training progress\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08ab868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:00:00 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:00:00 [INFO]: Model files will be saved to ./brits_model\\20250624_T000000\n",
      "2025-06-24 00:00:00 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T000000\\tensorboard\n",
      "2025-06-24 00:00:00 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:00:00 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:00:00 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 0...\n",
      "Training model for missing rate 0.05 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:00:13 [INFO]: Epoch 001 - training loss (MAE): 0.9083, validation MSE: 0.5491\n",
      "2025-06-24 00:00:22 [INFO]: Epoch 002 - training loss (MAE): 0.8802, validation MSE: 0.5451\n",
      "2025-06-24 00:00:37 [INFO]: Epoch 003 - training loss (MAE): 0.8640, validation MSE: 0.5417\n",
      "2025-06-24 00:00:46 [INFO]: Epoch 004 - training loss (MAE): 0.8026, validation MSE: 0.5349\n",
      "2025-06-24 00:00:54 [INFO]: Epoch 005 - training loss (MAE): 0.8072, validation MSE: 0.5143\n",
      "2025-06-24 00:01:03 [INFO]: Epoch 006 - training loss (MAE): 0.7829, validation MSE: 0.4881\n",
      "2025-06-24 00:01:11 [INFO]: Epoch 007 - training loss (MAE): 0.7469, validation MSE: 0.4605\n",
      "2025-06-24 00:01:20 [INFO]: Epoch 008 - training loss (MAE): 0.7073, validation MSE: 0.4385\n",
      "2025-06-24 00:01:28 [INFO]: Epoch 009 - training loss (MAE): 0.7036, validation MSE: 0.4170\n",
      "2025-06-24 00:01:36 [INFO]: Epoch 010 - training loss (MAE): 0.6778, validation MSE: 0.3864\n",
      "2025-06-24 00:01:45 [INFO]: Epoch 011 - training loss (MAE): 0.6597, validation MSE: 0.3540\n",
      "2025-06-24 00:01:54 [INFO]: Epoch 012 - training loss (MAE): 0.6313, validation MSE: 0.3238\n",
      "2025-06-24 00:02:02 [INFO]: Epoch 013 - training loss (MAE): 0.6146, validation MSE: 0.2946\n",
      "2025-06-24 00:02:11 [INFO]: Epoch 014 - training loss (MAE): 0.5778, validation MSE: 0.2633\n",
      "2025-06-24 00:02:19 [INFO]: Epoch 015 - training loss (MAE): 0.5523, validation MSE: 0.2400\n",
      "2025-06-24 00:02:27 [INFO]: Epoch 016 - training loss (MAE): 0.5348, validation MSE: 0.2178\n",
      "2025-06-24 00:02:36 [INFO]: Epoch 017 - training loss (MAE): 0.5350, validation MSE: 0.1979\n",
      "2025-06-24 00:02:44 [INFO]: Epoch 018 - training loss (MAE): 0.5272, validation MSE: 0.1804\n",
      "2025-06-24 00:02:52 [INFO]: Epoch 019 - training loss (MAE): 0.4897, validation MSE: 0.1647\n",
      "2025-06-24 00:03:01 [INFO]: Epoch 020 - training loss (MAE): 0.4851, validation MSE: 0.1506\n",
      "2025-06-24 00:03:09 [INFO]: Epoch 021 - training loss (MAE): 0.4901, validation MSE: 0.1364\n",
      "2025-06-24 00:03:18 [INFO]: Epoch 022 - training loss (MAE): 0.4480, validation MSE: 0.1235\n",
      "2025-06-24 00:03:26 [INFO]: Epoch 023 - training loss (MAE): 0.4567, validation MSE: 0.1146\n",
      "2025-06-24 00:03:34 [INFO]: Epoch 024 - training loss (MAE): 0.4429, validation MSE: 0.1073\n",
      "2025-06-24 00:03:43 [INFO]: Epoch 025 - training loss (MAE): 0.4183, validation MSE: 0.1008\n",
      "2025-06-24 00:03:43 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:03:43 [INFO]: Saved the model to ./brits_model\\20250624_T000000\\BRITS.pypots\n",
      "2025-06-24 00:03:43 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:03:43 [INFO]: Model files will be saved to ./brits_model\\20250624_T000343\n",
      "2025-06-24 00:03:43 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T000343\\tensorboard\n",
      "2025-06-24 00:03:43 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:03:43 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:03:43 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:03:55 [INFO]: Epoch 001 - training loss (MAE): 0.9282, validation MSE: 0.3799\n",
      "2025-06-24 00:04:04 [INFO]: Epoch 002 - training loss (MAE): 0.9293, validation MSE: 0.3748\n",
      "2025-06-24 00:04:12 [INFO]: Epoch 003 - training loss (MAE): 0.9242, validation MSE: 0.3694\n",
      "2025-06-24 00:04:21 [INFO]: Epoch 004 - training loss (MAE): 0.8772, validation MSE: 0.3651\n",
      "2025-06-24 00:04:29 [INFO]: Epoch 005 - training loss (MAE): 0.8665, validation MSE: 0.3607\n",
      "2025-06-24 00:04:38 [INFO]: Epoch 006 - training loss (MAE): 0.8493, validation MSE: 0.3551\n",
      "2025-06-24 00:04:47 [INFO]: Epoch 007 - training loss (MAE): 0.8075, validation MSE: 0.3474\n",
      "2025-06-24 00:04:55 [INFO]: Epoch 008 - training loss (MAE): 0.7991, validation MSE: 0.3398\n",
      "2025-06-24 00:05:04 [INFO]: Epoch 009 - training loss (MAE): 0.7941, validation MSE: 0.3307\n",
      "2025-06-24 00:05:12 [INFO]: Epoch 010 - training loss (MAE): 0.7804, validation MSE: 0.3177\n",
      "2025-06-24 00:05:21 [INFO]: Epoch 011 - training loss (MAE): 0.7751, validation MSE: 0.3020\n",
      "2025-06-24 00:05:29 [INFO]: Epoch 012 - training loss (MAE): 0.7717, validation MSE: 0.2842\n",
      "2025-06-24 00:05:37 [INFO]: Epoch 013 - training loss (MAE): 0.7131, validation MSE: 0.2619\n",
      "2025-06-24 00:05:46 [INFO]: Epoch 014 - training loss (MAE): 0.6698, validation MSE: 0.2375\n",
      "2025-06-24 00:05:54 [INFO]: Epoch 015 - training loss (MAE): 0.6693, validation MSE: 0.2161\n",
      "2025-06-24 00:06:03 [INFO]: Epoch 016 - training loss (MAE): 0.6406, validation MSE: 0.1974\n",
      "2025-06-24 00:06:12 [INFO]: Epoch 017 - training loss (MAE): 0.6171, validation MSE: 0.1789\n",
      "2025-06-24 00:06:20 [INFO]: Epoch 018 - training loss (MAE): 0.5953, validation MSE: 0.1610\n",
      "2025-06-24 00:06:29 [INFO]: Epoch 019 - training loss (MAE): 0.5852, validation MSE: 0.1462\n",
      "2025-06-24 00:06:37 [INFO]: Epoch 020 - training loss (MAE): 0.5722, validation MSE: 0.1329\n",
      "2025-06-24 00:06:45 [INFO]: Epoch 021 - training loss (MAE): 0.5728, validation MSE: 0.1229\n",
      "2025-06-24 00:06:54 [INFO]: Epoch 022 - training loss (MAE): 0.5313, validation MSE: 0.1139\n",
      "2025-06-24 00:07:02 [INFO]: Epoch 023 - training loss (MAE): 0.5288, validation MSE: 0.1044\n",
      "2025-06-24 00:07:11 [INFO]: Epoch 024 - training loss (MAE): 0.5274, validation MSE: 0.0952\n",
      "2025-06-24 00:07:19 [INFO]: Epoch 025 - training loss (MAE): 0.4926, validation MSE: 0.0860\n",
      "2025-06-24 00:07:19 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:07:19 [INFO]: Saved the model to ./brits_model\\20250624_T000343\\BRITS.pypots\n",
      "2025-06-24 00:07:19 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:07:19 [INFO]: Model files will be saved to ./brits_model\\20250624_T000719\n",
      "2025-06-24 00:07:19 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T000719\\tensorboard\n",
      "2025-06-24 00:07:19 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:07:19 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:07:19 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:07:32 [INFO]: Epoch 001 - training loss (MAE): 1.1085, validation MSE: 3.2101\n",
      "2025-06-24 00:07:40 [INFO]: Epoch 002 - training loss (MAE): 1.0645, validation MSE: 3.2358\n",
      "2025-06-24 00:07:48 [INFO]: Epoch 003 - training loss (MAE): 1.0523, validation MSE: 3.2630\n",
      "2025-06-24 00:07:57 [INFO]: Epoch 004 - training loss (MAE): 1.0304, validation MSE: 3.2931\n",
      "2025-06-24 00:08:05 [INFO]: Epoch 005 - training loss (MAE): 1.0112, validation MSE: 3.3229\n",
      "2025-06-24 00:08:13 [INFO]: Epoch 006 - training loss (MAE): 0.9805, validation MSE: 3.3429\n",
      "2025-06-24 00:08:13 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-06-24 00:08:13 [INFO]: Finished training. The best model is from epoch#1.\n",
      "2025-06-24 00:08:13 [INFO]: Saved the model to ./brits_model\\20250624_T000719\\BRITS.pypots\n",
      "2025-06-24 00:08:13 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:08:13 [INFO]: Model files will be saved to ./brits_model\\20250624_T000813\n",
      "2025-06-24 00:08:13 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T000813\\tensorboard\n",
      "2025-06-24 00:08:13 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:08:13 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:08:13 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.9 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:08:26 [INFO]: Epoch 001 - training loss (MAE): 0.8431, validation MSE: 2.5086\n",
      "2025-06-24 00:08:34 [INFO]: Epoch 002 - training loss (MAE): 0.8171, validation MSE: 2.5175\n",
      "2025-06-24 00:08:43 [INFO]: Epoch 003 - training loss (MAE): 0.7524, validation MSE: 2.5277\n",
      "2025-06-24 00:08:51 [INFO]: Epoch 004 - training loss (MAE): 0.7443, validation MSE: 2.5404\n",
      "2025-06-24 00:09:00 [INFO]: Epoch 005 - training loss (MAE): 0.6996, validation MSE: 2.5556\n",
      "2025-06-24 00:09:08 [INFO]: Epoch 006 - training loss (MAE): 0.6538, validation MSE: 2.5704\n",
      "2025-06-24 00:09:08 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-06-24 00:09:08 [INFO]: Finished training. The best model is from epoch#1.\n",
      "2025-06-24 00:09:08 [INFO]: Saved the model to ./brits_model\\20250624_T000813\\BRITS.pypots\n",
      "2025-06-24 00:09:08 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:09:08 [INFO]: Model files will be saved to ./brits_model\\20250624_T000908\n",
      "2025-06-24 00:09:08 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T000908\\tensorboard\n",
      "2025-06-24 00:09:08 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:09:08 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:09:08 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 1...\n",
      "Training model for missing rate 0.05 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:09:21 [INFO]: Epoch 001 - training loss (MAE): 1.6564, validation MSE: 1.2562\n",
      "2025-06-24 00:09:29 [INFO]: Epoch 002 - training loss (MAE): 1.6169, validation MSE: 1.2304\n",
      "2025-06-24 00:09:38 [INFO]: Epoch 003 - training loss (MAE): 1.5895, validation MSE: 1.2013\n",
      "2025-06-24 00:09:47 [INFO]: Epoch 004 - training loss (MAE): 1.5258, validation MSE: 1.1708\n",
      "2025-06-24 00:09:56 [INFO]: Epoch 005 - training loss (MAE): 1.4451, validation MSE: 1.1419\n",
      "2025-06-24 00:10:05 [INFO]: Epoch 006 - training loss (MAE): 1.3833, validation MSE: 1.1171\n",
      "2025-06-24 00:10:14 [INFO]: Epoch 007 - training loss (MAE): 1.3172, validation MSE: 1.0939\n",
      "2025-06-24 00:10:22 [INFO]: Epoch 008 - training loss (MAE): 1.2668, validation MSE: 1.0645\n",
      "2025-06-24 00:10:31 [INFO]: Epoch 009 - training loss (MAE): 1.1989, validation MSE: 1.0283\n",
      "2025-06-24 00:10:41 [INFO]: Epoch 010 - training loss (MAE): 1.1678, validation MSE: 0.9901\n",
      "2025-06-24 00:10:49 [INFO]: Epoch 011 - training loss (MAE): 1.1229, validation MSE: 0.9573\n",
      "2025-06-24 00:10:58 [INFO]: Epoch 012 - training loss (MAE): 1.0465, validation MSE: 0.9061\n",
      "2025-06-24 00:11:07 [INFO]: Epoch 013 - training loss (MAE): 1.0010, validation MSE: 0.8413\n",
      "2025-06-24 00:11:16 [INFO]: Epoch 014 - training loss (MAE): 0.9682, validation MSE: 0.7727\n",
      "2025-06-24 00:11:24 [INFO]: Epoch 015 - training loss (MAE): 0.9252, validation MSE: 0.6972\n",
      "2025-06-24 00:11:33 [INFO]: Epoch 016 - training loss (MAE): 0.9061, validation MSE: 0.6362\n",
      "2025-06-24 00:11:42 [INFO]: Epoch 017 - training loss (MAE): 0.8558, validation MSE: 0.5952\n",
      "2025-06-24 00:11:51 [INFO]: Epoch 018 - training loss (MAE): 0.8256, validation MSE: 0.5613\n",
      "2025-06-24 00:11:59 [INFO]: Epoch 019 - training loss (MAE): 0.7878, validation MSE: 0.5172\n",
      "2025-06-24 00:12:08 [INFO]: Epoch 020 - training loss (MAE): 0.7693, validation MSE: 0.4798\n",
      "2025-06-24 00:12:17 [INFO]: Epoch 021 - training loss (MAE): 0.7368, validation MSE: 0.4456\n",
      "2025-06-24 00:12:26 [INFO]: Epoch 022 - training loss (MAE): 0.7080, validation MSE: 0.4023\n",
      "2025-06-24 00:12:35 [INFO]: Epoch 023 - training loss (MAE): 0.6773, validation MSE: 0.3632\n",
      "2025-06-24 00:12:44 [INFO]: Epoch 024 - training loss (MAE): 0.6850, validation MSE: 0.3183\n",
      "2025-06-24 00:12:52 [INFO]: Epoch 025 - training loss (MAE): 0.6564, validation MSE: 0.2948\n",
      "2025-06-24 00:12:52 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:12:53 [INFO]: Saved the model to ./brits_model\\20250624_T000908\\BRITS.pypots\n",
      "2025-06-24 00:12:53 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:12:53 [INFO]: Model files will be saved to ./brits_model\\20250624_T001253\n",
      "2025-06-24 00:12:53 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T001253\\tensorboard\n",
      "2025-06-24 00:12:53 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:12:53 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:12:53 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:13:05 [INFO]: Epoch 001 - training loss (MAE): 1.5639, validation MSE: 1.6194\n",
      "2025-06-24 00:13:14 [INFO]: Epoch 002 - training loss (MAE): 1.5017, validation MSE: 1.5216\n",
      "2025-06-24 00:13:23 [INFO]: Epoch 003 - training loss (MAE): 1.4272, validation MSE: 1.4179\n",
      "2025-06-24 00:13:31 [INFO]: Epoch 004 - training loss (MAE): 1.3823, validation MSE: 1.3166\n",
      "2025-06-24 00:13:40 [INFO]: Epoch 005 - training loss (MAE): 1.3082, validation MSE: 1.2227\n",
      "2025-06-24 00:13:49 [INFO]: Epoch 006 - training loss (MAE): 1.2507, validation MSE: 1.1348\n",
      "2025-06-24 00:13:58 [INFO]: Epoch 007 - training loss (MAE): 1.2159, validation MSE: 1.0560\n",
      "2025-06-24 00:14:06 [INFO]: Epoch 008 - training loss (MAE): 1.1572, validation MSE: 0.9933\n",
      "2025-06-24 00:14:15 [INFO]: Epoch 009 - training loss (MAE): 1.0837, validation MSE: 0.9436\n",
      "2025-06-24 00:14:24 [INFO]: Epoch 010 - training loss (MAE): 1.0497, validation MSE: 0.8976\n",
      "2025-06-24 00:14:33 [INFO]: Epoch 011 - training loss (MAE): 1.0060, validation MSE: 0.8427\n",
      "2025-06-24 00:14:41 [INFO]: Epoch 012 - training loss (MAE): 0.9954, validation MSE: 0.7816\n",
      "2025-06-24 00:14:50 [INFO]: Epoch 013 - training loss (MAE): 0.9438, validation MSE: 0.7350\n",
      "2025-06-24 00:14:59 [INFO]: Epoch 014 - training loss (MAE): 0.9249, validation MSE: 0.6956\n",
      "2025-06-24 00:15:08 [INFO]: Epoch 015 - training loss (MAE): 0.8725, validation MSE: 0.6587\n",
      "2025-06-24 00:15:16 [INFO]: Epoch 016 - training loss (MAE): 0.8474, validation MSE: 0.6271\n",
      "2025-06-24 00:15:25 [INFO]: Epoch 017 - training loss (MAE): 0.8091, validation MSE: 0.5938\n",
      "2025-06-24 00:15:34 [INFO]: Epoch 018 - training loss (MAE): 0.7827, validation MSE: 0.5558\n",
      "2025-06-24 00:15:43 [INFO]: Epoch 019 - training loss (MAE): 0.7697, validation MSE: 0.5114\n",
      "2025-06-24 00:15:51 [INFO]: Epoch 020 - training loss (MAE): 0.7315, validation MSE: 0.4632\n",
      "2025-06-24 00:16:00 [INFO]: Epoch 021 - training loss (MAE): 0.7065, validation MSE: 0.4157\n",
      "2025-06-24 00:16:09 [INFO]: Epoch 022 - training loss (MAE): 0.7065, validation MSE: 0.3720\n",
      "2025-06-24 00:16:17 [INFO]: Epoch 023 - training loss (MAE): 0.6544, validation MSE: 0.3319\n",
      "2025-06-24 00:16:26 [INFO]: Epoch 024 - training loss (MAE): 0.6373, validation MSE: 0.2937\n",
      "2025-06-24 00:16:35 [INFO]: Epoch 025 - training loss (MAE): 0.6190, validation MSE: 0.2616\n",
      "2025-06-24 00:16:35 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:16:35 [INFO]: Saved the model to ./brits_model\\20250624_T001253\\BRITS.pypots\n",
      "2025-06-24 00:16:35 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:16:35 [INFO]: Model files will be saved to ./brits_model\\20250624_T001635\n",
      "2025-06-24 00:16:35 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T001635\\tensorboard\n",
      "2025-06-24 00:16:35 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:16:35 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:16:35 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:16:48 [INFO]: Epoch 001 - training loss (MAE): 1.6234, validation MSE: 0.9833\n",
      "2025-06-24 00:16:56 [INFO]: Epoch 002 - training loss (MAE): 1.5828, validation MSE: 0.9561\n",
      "2025-06-24 00:17:05 [INFO]: Epoch 003 - training loss (MAE): 1.5552, validation MSE: 0.9298\n",
      "2025-06-24 00:17:14 [INFO]: Epoch 004 - training loss (MAE): 1.4857, validation MSE: 0.9089\n",
      "2025-06-24 00:17:23 [INFO]: Epoch 005 - training loss (MAE): 1.4405, validation MSE: 0.8903\n",
      "2025-06-24 00:17:32 [INFO]: Epoch 006 - training loss (MAE): 1.3991, validation MSE: 0.8691\n",
      "2025-06-24 00:17:40 [INFO]: Epoch 007 - training loss (MAE): 1.3204, validation MSE: 0.8511\n",
      "2025-06-24 00:17:49 [INFO]: Epoch 008 - training loss (MAE): 1.2831, validation MSE: 0.8339\n",
      "2025-06-24 00:17:58 [INFO]: Epoch 009 - training loss (MAE): 1.2149, validation MSE: 0.8255\n",
      "2025-06-24 00:18:07 [INFO]: Epoch 010 - training loss (MAE): 1.1687, validation MSE: 0.8217\n",
      "2025-06-24 00:18:15 [INFO]: Epoch 011 - training loss (MAE): 1.1284, validation MSE: 0.8163\n",
      "2025-06-24 00:18:24 [INFO]: Epoch 012 - training loss (MAE): 1.0928, validation MSE: 0.7897\n",
      "2025-06-24 00:18:33 [INFO]: Epoch 013 - training loss (MAE): 1.0773, validation MSE: 0.7649\n",
      "2025-06-24 00:18:42 [INFO]: Epoch 014 - training loss (MAE): 1.0105, validation MSE: 0.7434\n",
      "2025-06-24 00:18:50 [INFO]: Epoch 015 - training loss (MAE): 1.0022, validation MSE: 0.7145\n",
      "2025-06-24 00:18:59 [INFO]: Epoch 016 - training loss (MAE): 0.9432, validation MSE: 0.6967\n",
      "2025-06-24 00:19:08 [INFO]: Epoch 017 - training loss (MAE): 0.9019, validation MSE: 0.6566\n",
      "2025-06-24 00:19:17 [INFO]: Epoch 018 - training loss (MAE): 0.8697, validation MSE: 0.6197\n",
      "2025-06-24 00:19:26 [INFO]: Epoch 019 - training loss (MAE): 0.8541, validation MSE: 0.5744\n",
      "2025-06-24 00:19:34 [INFO]: Epoch 020 - training loss (MAE): 0.8277, validation MSE: 0.5385\n",
      "2025-06-24 00:19:43 [INFO]: Epoch 021 - training loss (MAE): 0.7765, validation MSE: 0.5063\n",
      "2025-06-24 00:19:52 [INFO]: Epoch 022 - training loss (MAE): 0.7729, validation MSE: 0.4818\n",
      "2025-06-24 00:20:01 [INFO]: Epoch 023 - training loss (MAE): 0.7247, validation MSE: 0.4607\n",
      "2025-06-24 00:20:10 [INFO]: Epoch 024 - training loss (MAE): 0.7188, validation MSE: 0.4397\n",
      "2025-06-24 00:20:18 [INFO]: Epoch 025 - training loss (MAE): 0.6893, validation MSE: 0.4249\n",
      "2025-06-24 00:20:18 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:20:18 [INFO]: Saved the model to ./brits_model\\20250624_T001635\\BRITS.pypots\n",
      "2025-06-24 00:20:18 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:20:18 [INFO]: Model files will be saved to ./brits_model\\20250624_T002018\n",
      "2025-06-24 00:20:18 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T002018\\tensorboard\n",
      "2025-06-24 00:20:18 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:20:18 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:20:18 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.9 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:20:31 [INFO]: Epoch 001 - training loss (MAE): 1.5736, validation MSE: 1.1539\n",
      "2025-06-24 00:20:40 [INFO]: Epoch 002 - training loss (MAE): 1.5482, validation MSE: 1.1088\n",
      "2025-06-24 00:20:49 [INFO]: Epoch 003 - training loss (MAE): 1.4740, validation MSE: 1.0671\n",
      "2025-06-24 00:20:57 [INFO]: Epoch 004 - training loss (MAE): 1.4523, validation MSE: 1.0220\n",
      "2025-06-24 00:21:06 [INFO]: Epoch 005 - training loss (MAE): 1.3890, validation MSE: 0.9753\n",
      "2025-06-24 00:21:15 [INFO]: Epoch 006 - training loss (MAE): 1.3087, validation MSE: 0.9255\n",
      "2025-06-24 00:21:24 [INFO]: Epoch 007 - training loss (MAE): 1.2325, validation MSE: 0.8724\n",
      "2025-06-24 00:21:32 [INFO]: Epoch 008 - training loss (MAE): 1.1659, validation MSE: 0.8209\n",
      "2025-06-24 00:21:41 [INFO]: Epoch 009 - training loss (MAE): 1.0909, validation MSE: 0.7731\n",
      "2025-06-24 00:21:50 [INFO]: Epoch 010 - training loss (MAE): 1.0454, validation MSE: 0.7334\n",
      "2025-06-24 00:21:59 [INFO]: Epoch 011 - training loss (MAE): 0.9637, validation MSE: 0.7041\n",
      "2025-06-24 00:22:08 [INFO]: Epoch 012 - training loss (MAE): 0.9379, validation MSE: 0.6823\n",
      "2025-06-24 00:22:16 [INFO]: Epoch 013 - training loss (MAE): 0.9002, validation MSE: 0.6614\n",
      "2025-06-24 00:22:25 [INFO]: Epoch 014 - training loss (MAE): 0.8925, validation MSE: 0.6460\n",
      "2025-06-24 00:22:34 [INFO]: Epoch 015 - training loss (MAE): 0.8413, validation MSE: 0.6339\n",
      "2025-06-24 00:22:42 [INFO]: Epoch 016 - training loss (MAE): 0.7915, validation MSE: 0.6194\n",
      "2025-06-24 00:22:51 [INFO]: Epoch 017 - training loss (MAE): 0.7743, validation MSE: 0.6088\n",
      "2025-06-24 00:23:00 [INFO]: Epoch 018 - training loss (MAE): 0.7435, validation MSE: 0.5947\n",
      "2025-06-24 00:23:09 [INFO]: Epoch 019 - training loss (MAE): 0.6904, validation MSE: 0.5873\n",
      "2025-06-24 00:23:17 [INFO]: Epoch 020 - training loss (MAE): 0.6545, validation MSE: 0.5716\n",
      "2025-06-24 00:23:26 [INFO]: Epoch 021 - training loss (MAE): 0.6330, validation MSE: 0.5715\n",
      "2025-06-24 00:23:35 [INFO]: Epoch 022 - training loss (MAE): 0.6117, validation MSE: 0.5596\n",
      "2025-06-24 00:23:45 [INFO]: Epoch 023 - training loss (MAE): 0.5770, validation MSE: 0.5509\n",
      "2025-06-24 00:23:54 [INFO]: Epoch 024 - training loss (MAE): 0.5551, validation MSE: 0.5403\n",
      "2025-06-24 00:24:03 [INFO]: Epoch 025 - training loss (MAE): 0.5439, validation MSE: 0.5293\n",
      "2025-06-24 00:24:03 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:24:04 [INFO]: Saved the model to ./brits_model\\20250624_T002018\\BRITS.pypots\n",
      "2025-06-24 00:24:04 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:24:04 [INFO]: Model files will be saved to ./brits_model\\20250624_T002404\n",
      "2025-06-24 00:24:04 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T002404\\tensorboard\n",
      "2025-06-24 00:24:04 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:24:04 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:24:04 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 2...\n",
      "Training model for missing rate 0.05 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:24:16 [INFO]: Epoch 001 - training loss (MAE): 2.1131, validation MSE: 3.1239\n",
      "2025-06-24 00:24:24 [INFO]: Epoch 002 - training loss (MAE): 2.0867, validation MSE: 3.0866\n",
      "2025-06-24 00:24:33 [INFO]: Epoch 003 - training loss (MAE): 2.0358, validation MSE: 3.0500\n",
      "2025-06-24 00:24:44 [INFO]: Epoch 004 - training loss (MAE): 1.9745, validation MSE: 3.0155\n",
      "2025-06-24 00:24:54 [INFO]: Epoch 005 - training loss (MAE): 1.9167, validation MSE: 2.9819\n",
      "2025-06-24 00:25:03 [INFO]: Epoch 006 - training loss (MAE): 1.8464, validation MSE: 2.9230\n",
      "2025-06-24 00:25:11 [INFO]: Epoch 007 - training loss (MAE): 1.8077, validation MSE: 2.8371\n",
      "2025-06-24 00:25:19 [INFO]: Epoch 008 - training loss (MAE): 1.7157, validation MSE: 2.7375\n",
      "2025-06-24 00:25:28 [INFO]: Epoch 009 - training loss (MAE): 1.6563, validation MSE: 2.6254\n",
      "2025-06-24 00:25:38 [INFO]: Epoch 010 - training loss (MAE): 1.6002, validation MSE: 2.5111\n",
      "2025-06-24 00:25:48 [INFO]: Epoch 011 - training loss (MAE): 1.5438, validation MSE: 2.3962\n",
      "2025-06-24 00:25:57 [INFO]: Epoch 012 - training loss (MAE): 1.5131, validation MSE: 2.2827\n",
      "2025-06-24 00:26:06 [INFO]: Epoch 013 - training loss (MAE): 1.4680, validation MSE: 2.1730\n",
      "2025-06-24 00:26:16 [INFO]: Epoch 014 - training loss (MAE): 1.4370, validation MSE: 2.0677\n",
      "2025-06-24 00:26:24 [INFO]: Epoch 015 - training loss (MAE): 1.4083, validation MSE: 1.9638\n",
      "2025-06-24 00:26:32 [INFO]: Epoch 016 - training loss (MAE): 1.3625, validation MSE: 1.8580\n",
      "2025-06-24 00:26:40 [INFO]: Epoch 017 - training loss (MAE): 1.3282, validation MSE: 1.7473\n",
      "2025-06-24 00:26:48 [INFO]: Epoch 018 - training loss (MAE): 1.2792, validation MSE: 1.6352\n",
      "2025-06-24 00:26:56 [INFO]: Epoch 019 - training loss (MAE): 1.2470, validation MSE: 1.5280\n",
      "2025-06-24 00:27:04 [INFO]: Epoch 020 - training loss (MAE): 1.2049, validation MSE: 1.4449\n",
      "2025-06-24 00:27:12 [INFO]: Epoch 021 - training loss (MAE): 1.1622, validation MSE: 1.3781\n",
      "2025-06-24 00:27:20 [INFO]: Epoch 022 - training loss (MAE): 1.1297, validation MSE: 1.3208\n",
      "2025-06-24 00:27:28 [INFO]: Epoch 023 - training loss (MAE): 1.1003, validation MSE: 1.2678\n",
      "2025-06-24 00:27:38 [INFO]: Epoch 024 - training loss (MAE): 1.0734, validation MSE: 1.2172\n",
      "2025-06-24 00:27:47 [INFO]: Epoch 025 - training loss (MAE): 1.0411, validation MSE: 1.1676\n",
      "2025-06-24 00:27:47 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:27:47 [INFO]: Saved the model to ./brits_model\\20250624_T002404\\BRITS.pypots\n",
      "2025-06-24 00:27:47 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:27:47 [INFO]: Model files will be saved to ./brits_model\\20250624_T002747\n",
      "2025-06-24 00:27:47 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T002747\\tensorboard\n",
      "2025-06-24 00:27:47 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:27:47 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:27:47 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:28:00 [INFO]: Epoch 001 - training loss (MAE): 1.7701, validation MSE: 0.3972\n",
      "2025-06-24 00:28:08 [INFO]: Epoch 002 - training loss (MAE): 1.6984, validation MSE: 0.3791\n",
      "2025-06-24 00:28:16 [INFO]: Epoch 003 - training loss (MAE): 1.6669, validation MSE: 0.3576\n",
      "2025-06-24 00:28:25 [INFO]: Epoch 004 - training loss (MAE): 1.6494, validation MSE: 0.3328\n",
      "2025-06-24 00:28:34 [INFO]: Epoch 005 - training loss (MAE): 1.5911, validation MSE: 0.3034\n",
      "2025-06-24 00:28:42 [INFO]: Epoch 006 - training loss (MAE): 1.5327, validation MSE: 0.2689\n",
      "2025-06-24 00:28:51 [INFO]: Epoch 007 - training loss (MAE): 1.4381, validation MSE: 0.2338\n",
      "2025-06-24 00:28:59 [INFO]: Epoch 008 - training loss (MAE): 1.4013, validation MSE: 0.2032\n",
      "2025-06-24 00:29:08 [INFO]: Epoch 009 - training loss (MAE): 1.3348, validation MSE: 0.1766\n",
      "2025-06-24 00:29:16 [INFO]: Epoch 010 - training loss (MAE): 1.2641, validation MSE: 0.1522\n",
      "2025-06-24 00:29:25 [INFO]: Epoch 011 - training loss (MAE): 1.2160, validation MSE: 0.1390\n",
      "2025-06-24 00:29:33 [INFO]: Epoch 012 - training loss (MAE): 1.1638, validation MSE: 0.1261\n",
      "2025-06-24 00:29:42 [INFO]: Epoch 013 - training loss (MAE): 1.1093, validation MSE: 0.1142\n",
      "2025-06-24 00:29:50 [INFO]: Epoch 014 - training loss (MAE): 1.0400, validation MSE: 0.1016\n",
      "2025-06-24 00:29:58 [INFO]: Epoch 015 - training loss (MAE): 0.9937, validation MSE: 0.0896\n",
      "2025-06-24 00:30:07 [INFO]: Epoch 016 - training loss (MAE): 0.9569, validation MSE: 0.0817\n",
      "2025-06-24 00:30:15 [INFO]: Epoch 017 - training loss (MAE): 0.9180, validation MSE: 0.0747\n",
      "2025-06-24 00:30:24 [INFO]: Epoch 018 - training loss (MAE): 0.8884, validation MSE: 0.0684\n",
      "2025-06-24 00:30:32 [INFO]: Epoch 019 - training loss (MAE): 0.8629, validation MSE: 0.0645\n",
      "2025-06-24 00:30:40 [INFO]: Epoch 020 - training loss (MAE): 0.8502, validation MSE: 0.0612\n",
      "2025-06-24 00:30:49 [INFO]: Epoch 021 - training loss (MAE): 0.8241, validation MSE: 0.0579\n",
      "2025-06-24 00:30:57 [INFO]: Epoch 022 - training loss (MAE): 0.8143, validation MSE: 0.0550\n",
      "2025-06-24 00:31:05 [INFO]: Epoch 023 - training loss (MAE): 0.7900, validation MSE: 0.0539\n",
      "2025-06-24 00:31:14 [INFO]: Epoch 024 - training loss (MAE): 0.7746, validation MSE: 0.0517\n",
      "2025-06-24 00:31:22 [INFO]: Epoch 025 - training loss (MAE): 0.7676, validation MSE: 0.0490\n",
      "2025-06-24 00:31:22 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:31:22 [INFO]: Saved the model to ./brits_model\\20250624_T002747\\BRITS.pypots\n",
      "2025-06-24 00:31:22 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:31:22 [INFO]: Model files will be saved to ./brits_model\\20250624_T003122\n",
      "2025-06-24 00:31:22 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T003122\\tensorboard\n",
      "2025-06-24 00:31:22 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:31:22 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:31:22 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:31:35 [INFO]: Epoch 001 - training loss (MAE): 1.8314, validation MSE: 0.9038\n",
      "2025-06-24 00:31:43 [INFO]: Epoch 002 - training loss (MAE): 1.7886, validation MSE: 0.8701\n",
      "2025-06-24 00:31:51 [INFO]: Epoch 003 - training loss (MAE): 1.7747, validation MSE: 0.8335\n",
      "2025-06-24 00:32:00 [INFO]: Epoch 004 - training loss (MAE): 1.6999, validation MSE: 0.7919\n",
      "2025-06-24 00:32:09 [INFO]: Epoch 005 - training loss (MAE): 1.6492, validation MSE: 0.7426\n",
      "2025-06-24 00:32:17 [INFO]: Epoch 006 - training loss (MAE): 1.5638, validation MSE: 0.6834\n",
      "2025-06-24 00:32:25 [INFO]: Epoch 007 - training loss (MAE): 1.4723, validation MSE: 0.6187\n",
      "2025-06-24 00:32:34 [INFO]: Epoch 008 - training loss (MAE): 1.4382, validation MSE: 0.5699\n",
      "2025-06-24 00:32:42 [INFO]: Epoch 009 - training loss (MAE): 1.3753, validation MSE: 0.5462\n",
      "2025-06-24 00:32:50 [INFO]: Epoch 010 - training loss (MAE): 1.3375, validation MSE: 0.5397\n",
      "2025-06-24 00:32:59 [INFO]: Epoch 011 - training loss (MAE): 1.2782, validation MSE: 0.5311\n",
      "2025-06-24 00:33:07 [INFO]: Epoch 012 - training loss (MAE): 1.2479, validation MSE: 0.5121\n",
      "2025-06-24 00:33:15 [INFO]: Epoch 013 - training loss (MAE): 1.2107, validation MSE: 0.4865\n",
      "2025-06-24 00:33:24 [INFO]: Epoch 014 - training loss (MAE): 1.1616, validation MSE: 0.4641\n",
      "2025-06-24 00:33:32 [INFO]: Epoch 015 - training loss (MAE): 1.1261, validation MSE: 0.4486\n",
      "2025-06-24 00:33:40 [INFO]: Epoch 016 - training loss (MAE): 1.0864, validation MSE: 0.4297\n",
      "2025-06-24 00:33:49 [INFO]: Epoch 017 - training loss (MAE): 1.0188, validation MSE: 0.4022\n",
      "2025-06-24 00:33:58 [INFO]: Epoch 018 - training loss (MAE): 0.9813, validation MSE: 0.3794\n",
      "2025-06-24 00:34:08 [INFO]: Epoch 019 - training loss (MAE): 0.9265, validation MSE: 0.3636\n",
      "2025-06-24 00:34:17 [INFO]: Epoch 020 - training loss (MAE): 0.8695, validation MSE: 0.3461\n",
      "2025-06-24 00:34:27 [INFO]: Epoch 021 - training loss (MAE): 0.8186, validation MSE: 0.3221\n",
      "2025-06-24 00:34:35 [INFO]: Epoch 022 - training loss (MAE): 0.7990, validation MSE: 0.2969\n",
      "2025-06-24 00:34:44 [INFO]: Epoch 023 - training loss (MAE): 0.7636, validation MSE: 0.2754\n",
      "2025-06-24 00:34:53 [INFO]: Epoch 024 - training loss (MAE): 0.7530, validation MSE: 0.2594\n",
      "2025-06-24 00:35:02 [INFO]: Epoch 025 - training loss (MAE): 0.7383, validation MSE: 0.2493\n",
      "2025-06-24 00:35:02 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:35:02 [INFO]: Saved the model to ./brits_model\\20250624_T003122\\BRITS.pypots\n",
      "2025-06-24 00:35:02 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:35:02 [INFO]: Model files will be saved to ./brits_model\\20250624_T003502\n",
      "2025-06-24 00:35:02 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T003502\\tensorboard\n",
      "2025-06-24 00:35:02 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:35:02 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:35:02 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.9 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:35:15 [INFO]: Epoch 001 - training loss (MAE): 1.8487, validation MSE: 1.5346\n",
      "2025-06-24 00:35:23 [INFO]: Epoch 002 - training loss (MAE): 1.8255, validation MSE: 1.5249\n",
      "2025-06-24 00:35:32 [INFO]: Epoch 003 - training loss (MAE): 1.8032, validation MSE: 1.5146\n",
      "2025-06-24 00:35:41 [INFO]: Epoch 004 - training loss (MAE): 1.7519, validation MSE: 1.5041\n",
      "2025-06-24 00:35:49 [INFO]: Epoch 005 - training loss (MAE): 1.6971, validation MSE: 1.4934\n",
      "2025-06-24 00:35:58 [INFO]: Epoch 006 - training loss (MAE): 1.6611, validation MSE: 1.4841\n",
      "2025-06-24 00:36:06 [INFO]: Epoch 007 - training loss (MAE): 1.5876, validation MSE: 1.4759\n",
      "2025-06-24 00:36:15 [INFO]: Epoch 008 - training loss (MAE): 1.5722, validation MSE: 1.4710\n",
      "2025-06-24 00:36:24 [INFO]: Epoch 009 - training loss (MAE): 1.5159, validation MSE: 1.4669\n",
      "2025-06-24 00:36:33 [INFO]: Epoch 010 - training loss (MAE): 1.4647, validation MSE: 1.4647\n",
      "2025-06-24 00:36:41 [INFO]: Epoch 011 - training loss (MAE): 1.4009, validation MSE: 1.4656\n",
      "2025-06-24 00:36:50 [INFO]: Epoch 012 - training loss (MAE): 1.3583, validation MSE: 1.4635\n",
      "2025-06-24 00:36:59 [INFO]: Epoch 013 - training loss (MAE): 1.2872, validation MSE: 1.4654\n",
      "2025-06-24 00:37:08 [INFO]: Epoch 014 - training loss (MAE): 1.2683, validation MSE: 1.4717\n",
      "2025-06-24 00:37:15 [INFO]: Epoch 015 - training loss (MAE): 1.2239, validation MSE: 1.4796\n",
      "2025-06-24 00:37:23 [INFO]: Epoch 016 - training loss (MAE): 1.1535, validation MSE: 1.4880\n",
      "2025-06-24 00:37:31 [INFO]: Epoch 017 - training loss (MAE): 1.0934, validation MSE: 1.5014\n",
      "2025-06-24 00:37:31 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-06-24 00:37:31 [INFO]: Finished training. The best model is from epoch#12.\n",
      "2025-06-24 00:37:31 [INFO]: Saved the model to ./brits_model\\20250624_T003502\\BRITS.pypots\n",
      "2025-06-24 00:37:31 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:37:31 [INFO]: Model files will be saved to ./brits_model\\20250624_T003731\n",
      "2025-06-24 00:37:31 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T003731\\tensorboard\n",
      "2025-06-24 00:37:31 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:37:31 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:37:31 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 3...\n",
      "Training model for missing rate 0.05 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:37:44 [INFO]: Epoch 001 - training loss (MAE): 1.9744, validation MSE: 0.8877\n",
      "2025-06-24 00:37:52 [INFO]: Epoch 002 - training loss (MAE): 1.9267, validation MSE: 0.8685\n",
      "2025-06-24 00:38:00 [INFO]: Epoch 003 - training loss (MAE): 1.8731, validation MSE: 0.8501\n",
      "2025-06-24 00:38:09 [INFO]: Epoch 004 - training loss (MAE): 1.8064, validation MSE: 0.8285\n",
      "2025-06-24 00:38:17 [INFO]: Epoch 005 - training loss (MAE): 1.7653, validation MSE: 0.7990\n",
      "2025-06-24 00:38:26 [INFO]: Epoch 006 - training loss (MAE): 1.7221, validation MSE: 0.7572\n",
      "2025-06-24 00:38:34 [INFO]: Epoch 007 - training loss (MAE): 1.6383, validation MSE: 0.7048\n",
      "2025-06-24 00:38:43 [INFO]: Epoch 008 - training loss (MAE): 1.5674, validation MSE: 0.6344\n",
      "2025-06-24 00:38:51 [INFO]: Epoch 009 - training loss (MAE): 1.5262, validation MSE: 0.5518\n",
      "2025-06-24 00:39:01 [INFO]: Epoch 010 - training loss (MAE): 1.4605, validation MSE: 0.4682\n",
      "2025-06-24 00:39:10 [INFO]: Epoch 011 - training loss (MAE): 1.4533, validation MSE: 0.3898\n",
      "2025-06-24 00:39:19 [INFO]: Epoch 012 - training loss (MAE): 1.3449, validation MSE: 0.3195\n",
      "2025-06-24 00:39:28 [INFO]: Epoch 013 - training loss (MAE): 1.2973, validation MSE: 0.2586\n",
      "2025-06-24 00:39:38 [INFO]: Epoch 014 - training loss (MAE): 1.2657, validation MSE: 0.2123\n",
      "2025-06-24 00:39:47 [INFO]: Epoch 015 - training loss (MAE): 1.2364, validation MSE: 0.1869\n",
      "2025-06-24 00:39:56 [INFO]: Epoch 016 - training loss (MAE): 1.1992, validation MSE: 0.1756\n",
      "2025-06-24 00:40:06 [INFO]: Epoch 017 - training loss (MAE): 1.1444, validation MSE: 0.1745\n",
      "2025-06-24 00:40:15 [INFO]: Epoch 018 - training loss (MAE): 1.1553, validation MSE: 0.1713\n",
      "2025-06-24 00:40:24 [INFO]: Epoch 019 - training loss (MAE): 1.0959, validation MSE: 0.1636\n",
      "2025-06-24 00:40:34 [INFO]: Epoch 020 - training loss (MAE): 1.0770, validation MSE: 0.1572\n",
      "2025-06-24 00:40:43 [INFO]: Epoch 021 - training loss (MAE): 1.0484, validation MSE: 0.1484\n",
      "2025-06-24 00:40:53 [INFO]: Epoch 022 - training loss (MAE): 1.0392, validation MSE: 0.1366\n",
      "2025-06-24 00:41:02 [INFO]: Epoch 023 - training loss (MAE): 0.9891, validation MSE: 0.1234\n",
      "2025-06-24 00:41:11 [INFO]: Epoch 024 - training loss (MAE): 0.9676, validation MSE: 0.1150\n",
      "2025-06-24 00:41:21 [INFO]: Epoch 025 - training loss (MAE): 0.9393, validation MSE: 0.1090\n",
      "2025-06-24 00:41:21 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:41:21 [INFO]: Saved the model to ./brits_model\\20250624_T003731\\BRITS.pypots\n",
      "2025-06-24 00:41:21 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:41:21 [INFO]: Model files will be saved to ./brits_model\\20250624_T004121\n",
      "2025-06-24 00:41:21 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T004121\\tensorboard\n",
      "2025-06-24 00:41:21 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:41:21 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:41:21 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:41:34 [INFO]: Epoch 001 - training loss (MAE): 1.8105, validation MSE: 0.7727\n",
      "2025-06-24 00:41:44 [INFO]: Epoch 002 - training loss (MAE): 1.7777, validation MSE: 0.7535\n",
      "2025-06-24 00:41:53 [INFO]: Epoch 003 - training loss (MAE): 1.7386, validation MSE: 0.7349\n",
      "2025-06-24 00:42:02 [INFO]: Epoch 004 - training loss (MAE): 1.7343, validation MSE: 0.7149\n",
      "2025-06-24 00:42:11 [INFO]: Epoch 005 - training loss (MAE): 1.7104, validation MSE: 0.6958\n",
      "2025-06-24 00:42:21 [INFO]: Epoch 006 - training loss (MAE): 1.6724, validation MSE: 0.6764\n",
      "2025-06-24 00:42:30 [INFO]: Epoch 007 - training loss (MAE): 1.6209, validation MSE: 0.6538\n",
      "2025-06-24 00:42:39 [INFO]: Epoch 008 - training loss (MAE): 1.5589, validation MSE: 0.6259\n",
      "2025-06-24 00:42:48 [INFO]: Epoch 009 - training loss (MAE): 1.5270, validation MSE: 0.5920\n",
      "2025-06-24 00:42:57 [INFO]: Epoch 010 - training loss (MAE): 1.4498, validation MSE: 0.5542\n",
      "2025-06-24 00:43:07 [INFO]: Epoch 011 - training loss (MAE): 1.4278, validation MSE: 0.5149\n",
      "2025-06-24 00:43:16 [INFO]: Epoch 012 - training loss (MAE): 1.3165, validation MSE: 0.4862\n",
      "2025-06-24 00:43:25 [INFO]: Epoch 013 - training loss (MAE): 1.2597, validation MSE: 0.4584\n",
      "2025-06-24 00:43:34 [INFO]: Epoch 014 - training loss (MAE): 1.2010, validation MSE: 0.4223\n",
      "2025-06-24 00:43:44 [INFO]: Epoch 015 - training loss (MAE): 1.1621, validation MSE: 0.3730\n",
      "2025-06-24 00:43:53 [INFO]: Epoch 016 - training loss (MAE): 1.1059, validation MSE: 0.3278\n",
      "2025-06-24 00:44:02 [INFO]: Epoch 017 - training loss (MAE): 1.0675, validation MSE: 0.2947\n",
      "2025-06-24 00:44:11 [INFO]: Epoch 018 - training loss (MAE): 1.0319, validation MSE: 0.2663\n",
      "2025-06-24 00:44:20 [INFO]: Epoch 019 - training loss (MAE): 1.0015, validation MSE: 0.2452\n",
      "2025-06-24 00:44:29 [INFO]: Epoch 020 - training loss (MAE): 0.9607, validation MSE: 0.2291\n",
      "2025-06-24 00:44:39 [INFO]: Epoch 021 - training loss (MAE): 0.9060, validation MSE: 0.2151\n",
      "2025-06-24 00:44:48 [INFO]: Epoch 022 - training loss (MAE): 0.8720, validation MSE: 0.2015\n",
      "2025-06-24 00:44:57 [INFO]: Epoch 023 - training loss (MAE): 0.8513, validation MSE: 0.1889\n",
      "2025-06-24 00:45:07 [INFO]: Epoch 024 - training loss (MAE): 0.8500, validation MSE: 0.1782\n",
      "2025-06-24 00:45:16 [INFO]: Epoch 025 - training loss (MAE): 0.8225, validation MSE: 0.1636\n",
      "2025-06-24 00:45:16 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:45:16 [INFO]: Saved the model to ./brits_model\\20250624_T004121\\BRITS.pypots\n",
      "2025-06-24 00:45:16 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:45:16 [INFO]: Model files will be saved to ./brits_model\\20250624_T004516\n",
      "2025-06-24 00:45:16 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T004516\\tensorboard\n",
      "2025-06-24 00:45:16 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:45:16 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:45:16 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:45:29 [INFO]: Epoch 001 - training loss (MAE): 1.8662, validation MSE: 0.9795\n",
      "2025-06-24 00:45:39 [INFO]: Epoch 002 - training loss (MAE): 1.8297, validation MSE: 0.9623\n",
      "2025-06-24 00:45:48 [INFO]: Epoch 003 - training loss (MAE): 1.7978, validation MSE: 0.9436\n",
      "2025-06-24 00:45:57 [INFO]: Epoch 004 - training loss (MAE): 1.7648, validation MSE: 0.9234\n",
      "2025-06-24 00:46:07 [INFO]: Epoch 005 - training loss (MAE): 1.7163, validation MSE: 0.9003\n",
      "2025-06-24 00:46:16 [INFO]: Epoch 006 - training loss (MAE): 1.6484, validation MSE: 0.8730\n",
      "2025-06-24 00:46:25 [INFO]: Epoch 007 - training loss (MAE): 1.5890, validation MSE: 0.8397\n",
      "2025-06-24 00:46:35 [INFO]: Epoch 008 - training loss (MAE): 1.5120, validation MSE: 0.7977\n",
      "2025-06-24 00:46:44 [INFO]: Epoch 009 - training loss (MAE): 1.4108, validation MSE: 0.7446\n",
      "2025-06-24 00:46:53 [INFO]: Epoch 010 - training loss (MAE): 1.3026, validation MSE: 0.6825\n",
      "2025-06-24 00:47:02 [INFO]: Epoch 011 - training loss (MAE): 1.1966, validation MSE: 0.6288\n",
      "2025-06-24 00:47:12 [INFO]: Epoch 012 - training loss (MAE): 1.1506, validation MSE: 0.6104\n",
      "2025-06-24 00:47:21 [INFO]: Epoch 013 - training loss (MAE): 1.0974, validation MSE: 0.6543\n",
      "2025-06-24 00:47:30 [INFO]: Epoch 014 - training loss (MAE): 1.0387, validation MSE: 0.7234\n",
      "2025-06-24 00:47:39 [INFO]: Epoch 015 - training loss (MAE): 1.0180, validation MSE: 0.6909\n",
      "2025-06-24 00:47:48 [INFO]: Epoch 016 - training loss (MAE): 0.9592, validation MSE: 0.6156\n",
      "2025-06-24 00:47:57 [INFO]: Epoch 017 - training loss (MAE): 0.9222, validation MSE: 0.5604\n",
      "2025-06-24 00:48:07 [INFO]: Epoch 018 - training loss (MAE): 0.8942, validation MSE: 0.5205\n",
      "2025-06-24 00:48:16 [INFO]: Epoch 019 - training loss (MAE): 0.8775, validation MSE: 0.4823\n",
      "2025-06-24 00:48:25 [INFO]: Epoch 020 - training loss (MAE): 0.8514, validation MSE: 0.4529\n",
      "2025-06-24 00:48:34 [INFO]: Epoch 021 - training loss (MAE): 0.8306, validation MSE: 0.4264\n",
      "2025-06-24 00:48:43 [INFO]: Epoch 022 - training loss (MAE): 0.7953, validation MSE: 0.3979\n",
      "2025-06-24 00:48:52 [INFO]: Epoch 023 - training loss (MAE): 0.7820, validation MSE: 0.3717\n",
      "2025-06-24 00:49:02 [INFO]: Epoch 024 - training loss (MAE): 0.7670, validation MSE: 0.3484\n",
      "2025-06-24 00:49:11 [INFO]: Epoch 025 - training loss (MAE): 0.7440, validation MSE: 0.3294\n",
      "2025-06-24 00:49:11 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:49:11 [INFO]: Saved the model to ./brits_model\\20250624_T004516\\BRITS.pypots\n",
      "2025-06-24 00:49:11 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:49:11 [INFO]: Model files will be saved to ./brits_model\\20250624_T004911\n",
      "2025-06-24 00:49:11 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T004911\\tensorboard\n",
      "2025-06-24 00:49:11 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:49:11 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:49:11 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.9 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:49:24 [INFO]: Epoch 001 - training loss (MAE): 1.5909, validation MSE: 1.0814\n",
      "2025-06-24 00:49:34 [INFO]: Epoch 002 - training loss (MAE): 1.5088, validation MSE: 1.0840\n",
      "2025-06-24 00:49:43 [INFO]: Epoch 003 - training loss (MAE): 1.5340, validation MSE: 1.0865\n",
      "2025-06-24 00:49:53 [INFO]: Epoch 004 - training loss (MAE): 1.5034, validation MSE: 1.0906\n",
      "2025-06-24 00:50:02 [INFO]: Epoch 005 - training loss (MAE): 1.4300, validation MSE: 1.0950\n",
      "2025-06-24 00:50:12 [INFO]: Epoch 006 - training loss (MAE): 1.4189, validation MSE: 1.1000\n",
      "2025-06-24 00:50:12 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-06-24 00:50:12 [INFO]: Finished training. The best model is from epoch#1.\n",
      "2025-06-24 00:50:12 [INFO]: Saved the model to ./brits_model\\20250624_T004911\\BRITS.pypots\n",
      "2025-06-24 00:50:12 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:50:12 [INFO]: Model files will be saved to ./brits_model\\20250624_T005012\n",
      "2025-06-24 00:50:12 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T005012\\tensorboard\n",
      "2025-06-24 00:50:12 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:50:12 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:50:12 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 31,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 4...\n",
      "Training model for missing rate 0.05 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:50:28 [INFO]: Epoch 001 - training loss (MAE): 1.2542, validation MSE: 2.1679\n",
      "2025-06-24 00:50:39 [INFO]: Epoch 002 - training loss (MAE): 1.1806, validation MSE: 2.0003\n",
      "2025-06-24 00:50:50 [INFO]: Epoch 003 - training loss (MAE): 1.0680, validation MSE: 1.8542\n",
      "2025-06-24 00:51:01 [INFO]: Epoch 004 - training loss (MAE): 1.0039, validation MSE: 1.7060\n",
      "2025-06-24 00:51:13 [INFO]: Epoch 005 - training loss (MAE): 0.9267, validation MSE: 1.5731\n",
      "2025-06-24 00:51:24 [INFO]: Epoch 006 - training loss (MAE): 0.9017, validation MSE: 1.4468\n",
      "2025-06-24 00:51:35 [INFO]: Epoch 007 - training loss (MAE): 0.8144, validation MSE: 1.3236\n",
      "2025-06-24 00:51:46 [INFO]: Epoch 008 - training loss (MAE): 0.7381, validation MSE: 1.2132\n",
      "2025-06-24 00:51:58 [INFO]: Epoch 009 - training loss (MAE): 0.6892, validation MSE: 1.1210\n",
      "2025-06-24 00:52:09 [INFO]: Epoch 010 - training loss (MAE): 0.6523, validation MSE: 1.0490\n",
      "2025-06-24 00:52:21 [INFO]: Epoch 011 - training loss (MAE): 0.6142, validation MSE: 0.9844\n",
      "2025-06-24 00:52:32 [INFO]: Epoch 012 - training loss (MAE): 0.5662, validation MSE: 0.9236\n",
      "2025-06-24 00:52:43 [INFO]: Epoch 013 - training loss (MAE): 0.5249, validation MSE: 0.8748\n",
      "2025-06-24 00:52:55 [INFO]: Epoch 014 - training loss (MAE): 0.4892, validation MSE: 0.8381\n",
      "2025-06-24 00:53:06 [INFO]: Epoch 015 - training loss (MAE): 0.4549, validation MSE: 0.8070\n",
      "2025-06-24 00:53:17 [INFO]: Epoch 016 - training loss (MAE): 0.4378, validation MSE: 0.7821\n",
      "2025-06-24 00:53:28 [INFO]: Epoch 017 - training loss (MAE): 0.4274, validation MSE: 0.7543\n",
      "2025-06-24 00:53:38 [INFO]: Epoch 018 - training loss (MAE): 0.4037, validation MSE: 0.7233\n",
      "2025-06-24 00:53:48 [INFO]: Epoch 019 - training loss (MAE): 0.4178, validation MSE: 0.6928\n",
      "2025-06-24 00:53:59 [INFO]: Epoch 020 - training loss (MAE): 0.3776, validation MSE: 0.6695\n",
      "2025-06-24 00:54:09 [INFO]: Epoch 021 - training loss (MAE): 0.3622, validation MSE: 0.6437\n",
      "2025-06-24 00:54:19 [INFO]: Epoch 022 - training loss (MAE): 0.3508, validation MSE: 0.6162\n",
      "2025-06-24 00:54:29 [INFO]: Epoch 023 - training loss (MAE): 0.3415, validation MSE: 0.5989\n",
      "2025-06-24 00:54:40 [INFO]: Epoch 024 - training loss (MAE): 0.3315, validation MSE: 0.5790\n",
      "2025-06-24 00:54:50 [INFO]: Epoch 025 - training loss (MAE): 0.3172, validation MSE: 0.5629\n",
      "2025-06-24 00:54:50 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 00:54:50 [INFO]: Saved the model to ./brits_model\\20250624_T005012\\BRITS.pypots\n",
      "2025-06-24 00:54:50 [INFO]: Using the given device: cpu\n",
      "2025-06-24 00:54:50 [INFO]: Model files will be saved to ./brits_model\\20250624_T005450\n",
      "2025-06-24 00:54:50 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T005450\\tensorboard\n",
      "2025-06-24 00:54:50 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 00:54:50 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 00:54:50 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 31,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 00:55:05 [INFO]: Epoch 001 - training loss (MAE): 1.3028, validation MSE: 1.4618\n",
      "2025-06-24 00:55:15 [INFO]: Epoch 002 - training loss (MAE): 1.2428, validation MSE: 1.3710\n",
      "2025-06-24 00:55:26 [INFO]: Epoch 003 - training loss (MAE): 1.1285, validation MSE: 1.2793\n",
      "2025-06-24 00:55:42 [INFO]: Epoch 004 - training loss (MAE): 1.0443, validation MSE: 1.1836\n",
      "2025-06-24 00:56:03 [INFO]: Epoch 005 - training loss (MAE): 0.9569, validation MSE: 1.0768\n",
      "2025-06-24 00:56:24 [INFO]: Epoch 006 - training loss (MAE): 0.9189, validation MSE: 0.9802\n",
      "2025-06-24 00:56:45 [INFO]: Epoch 007 - training loss (MAE): 0.8286, validation MSE: 0.9064\n",
      "2025-06-24 00:57:06 [INFO]: Epoch 008 - training loss (MAE): 0.7790, validation MSE: 0.8553\n",
      "2025-06-24 00:57:28 [INFO]: Epoch 009 - training loss (MAE): 0.7163, validation MSE: 0.7978\n",
      "2025-06-24 00:57:47 [INFO]: Epoch 010 - training loss (MAE): 0.6685, validation MSE: 0.7286\n",
      "2025-06-24 00:58:07 [INFO]: Epoch 011 - training loss (MAE): 0.6239, validation MSE: 0.6736\n",
      "2025-06-24 00:58:28 [INFO]: Epoch 012 - training loss (MAE): 0.5820, validation MSE: 0.6310\n",
      "2025-06-24 00:58:49 [INFO]: Epoch 013 - training loss (MAE): 0.5381, validation MSE: 0.5942\n",
      "2025-06-24 00:59:09 [INFO]: Epoch 014 - training loss (MAE): 0.5095, validation MSE: 0.5681\n",
      "2025-06-24 00:59:30 [INFO]: Epoch 015 - training loss (MAE): 0.4939, validation MSE: 0.5513\n",
      "2025-06-24 00:59:50 [INFO]: Epoch 016 - training loss (MAE): 0.4593, validation MSE: 0.5418\n",
      "2025-06-24 01:00:10 [INFO]: Epoch 017 - training loss (MAE): 0.4391, validation MSE: 0.5208\n",
      "2025-06-24 01:00:30 [INFO]: Epoch 018 - training loss (MAE): 0.4185, validation MSE: 0.4998\n",
      "2025-06-24 01:00:51 [INFO]: Epoch 019 - training loss (MAE): 0.4109, validation MSE: 0.4873\n",
      "2025-06-24 01:01:12 [INFO]: Epoch 020 - training loss (MAE): 0.3876, validation MSE: 0.4743\n",
      "2025-06-24 01:01:33 [INFO]: Epoch 021 - training loss (MAE): 0.3785, validation MSE: 0.4588\n",
      "2025-06-24 01:01:54 [INFO]: Epoch 022 - training loss (MAE): 0.3620, validation MSE: 0.4438\n",
      "2025-06-24 01:02:16 [INFO]: Epoch 023 - training loss (MAE): 0.3551, validation MSE: 0.4313\n",
      "2025-06-24 01:02:37 [INFO]: Epoch 024 - training loss (MAE): 0.3400, validation MSE: 0.4221\n",
      "2025-06-24 01:02:58 [INFO]: Epoch 025 - training loss (MAE): 0.3246, validation MSE: 0.4074\n",
      "2025-06-24 01:02:58 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 01:02:58 [INFO]: Saved the model to ./brits_model\\20250624_T005450\\BRITS.pypots\n",
      "2025-06-24 01:02:58 [INFO]: Using the given device: cpu\n",
      "2025-06-24 01:02:58 [INFO]: Model files will be saved to ./brits_model\\20250624_T010258\n",
      "2025-06-24 01:02:58 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T010258\\tensorboard\n",
      "2025-06-24 01:02:58 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 01:02:58 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 01:02:58 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 31,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 01:03:28 [INFO]: Epoch 001 - training loss (MAE): 1.2397, validation MSE: 1.5055\n",
      "2025-06-24 01:03:51 [INFO]: Epoch 002 - training loss (MAE): 1.1589, validation MSE: 1.4352\n",
      "2025-06-24 01:04:38 [INFO]: Epoch 003 - training loss (MAE): 1.0793, validation MSE: 1.3667\n",
      "2025-06-24 01:05:27 [INFO]: Epoch 004 - training loss (MAE): 0.9977, validation MSE: 1.2985\n",
      "2025-06-24 01:05:52 [INFO]: Epoch 005 - training loss (MAE): 0.9447, validation MSE: 1.2192\n",
      "2025-06-24 01:06:07 [INFO]: Epoch 006 - training loss (MAE): 0.8582, validation MSE: 1.1378\n",
      "2025-06-24 01:06:25 [INFO]: Epoch 007 - training loss (MAE): 0.8010, validation MSE: 1.0615\n",
      "2025-06-24 01:06:40 [INFO]: Epoch 008 - training loss (MAE): 0.7680, validation MSE: 0.9965\n",
      "2025-06-24 01:06:54 [INFO]: Epoch 009 - training loss (MAE): 0.6978, validation MSE: 0.9411\n",
      "2025-06-24 01:07:09 [INFO]: Epoch 010 - training loss (MAE): 0.6875, validation MSE: 0.8870\n",
      "2025-06-24 01:07:23 [INFO]: Epoch 011 - training loss (MAE): 0.6111, validation MSE: 0.8338\n",
      "2025-06-24 01:07:38 [INFO]: Epoch 012 - training loss (MAE): 0.5735, validation MSE: 0.7917\n",
      "2025-06-24 01:07:52 [INFO]: Epoch 013 - training loss (MAE): 0.5277, validation MSE: 0.7472\n",
      "2025-06-24 01:08:35 [INFO]: Epoch 014 - training loss (MAE): 0.4971, validation MSE: 0.7275\n",
      "2025-06-24 01:09:08 [INFO]: Epoch 015 - training loss (MAE): 0.4585, validation MSE: 0.6831\n",
      "2025-06-24 01:10:04 [INFO]: Epoch 016 - training loss (MAE): 0.4539, validation MSE: 0.6701\n",
      "2025-06-24 01:10:49 [INFO]: Epoch 017 - training loss (MAE): 0.4158, validation MSE: 0.6417\n",
      "2025-06-24 01:11:35 [INFO]: Epoch 018 - training loss (MAE): 0.3954, validation MSE: 0.6357\n",
      "2025-06-24 01:12:21 [INFO]: Epoch 019 - training loss (MAE): 0.3904, validation MSE: 0.6201\n",
      "2025-06-24 01:12:56 [INFO]: Epoch 020 - training loss (MAE): 0.3611, validation MSE: 0.6022\n",
      "2025-06-24 01:13:41 [INFO]: Epoch 021 - training loss (MAE): 0.3504, validation MSE: 0.5931\n",
      "2025-06-24 01:14:27 [INFO]: Epoch 022 - training loss (MAE): 0.3405, validation MSE: 0.5795\n",
      "2025-06-24 01:15:12 [INFO]: Epoch 023 - training loss (MAE): 0.3223, validation MSE: 0.5618\n",
      "2025-06-24 01:15:59 [INFO]: Epoch 024 - training loss (MAE): 0.3104, validation MSE: 0.5420\n",
      "2025-06-24 01:16:43 [INFO]: Epoch 025 - training loss (MAE): 0.3011, validation MSE: 0.5328\n",
      "2025-06-24 01:16:43 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 01:16:44 [INFO]: Saved the model to ./brits_model\\20250624_T010258\\BRITS.pypots\n",
      "2025-06-24 01:16:44 [INFO]: Using the given device: cpu\n",
      "2025-06-24 01:16:44 [INFO]: Model files will be saved to ./brits_model\\20250624_T011644\n",
      "2025-06-24 01:16:44 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T011644\\tensorboard\n",
      "2025-06-24 01:16:44 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 01:16:44 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 01:16:44 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 31,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.9 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 01:17:18 [INFO]: Epoch 001 - training loss (MAE): 1.3339, validation MSE: 1.1836\n",
      "2025-06-24 01:17:33 [INFO]: Epoch 002 - training loss (MAE): 1.2723, validation MSE: 1.1421\n",
      "2025-06-24 01:17:48 [INFO]: Epoch 003 - training loss (MAE): 1.2223, validation MSE: 1.1034\n",
      "2025-06-24 01:18:24 [INFO]: Epoch 004 - training loss (MAE): 1.1352, validation MSE: 1.0741\n",
      "2025-06-24 01:18:45 [INFO]: Epoch 005 - training loss (MAE): 1.0612, validation MSE: 1.0431\n",
      "2025-06-24 01:19:32 [INFO]: Epoch 006 - training loss (MAE): 1.0242, validation MSE: 1.0035\n",
      "2025-06-24 01:20:18 [INFO]: Epoch 007 - training loss (MAE): 0.9265, validation MSE: 0.9525\n",
      "2025-06-24 01:21:05 [INFO]: Epoch 008 - training loss (MAE): 0.8922, validation MSE: 0.9031\n",
      "2025-06-24 01:21:51 [INFO]: Epoch 009 - training loss (MAE): 0.8113, validation MSE: 0.8475\n",
      "2025-06-24 01:22:37 [INFO]: Epoch 010 - training loss (MAE): 0.7517, validation MSE: 0.7977\n",
      "2025-06-24 01:23:23 [INFO]: Epoch 011 - training loss (MAE): 0.6926, validation MSE: 0.7601\n",
      "2025-06-24 01:24:09 [INFO]: Epoch 012 - training loss (MAE): 0.6249, validation MSE: 0.7296\n",
      "2025-06-24 01:24:54 [INFO]: Epoch 013 - training loss (MAE): 0.6050, validation MSE: 0.7019\n",
      "2025-06-24 01:25:12 [INFO]: Epoch 014 - training loss (MAE): 0.5474, validation MSE: 0.6833\n",
      "2025-06-24 01:25:27 [INFO]: Epoch 015 - training loss (MAE): 0.5195, validation MSE: 0.6579\n",
      "2025-06-24 01:25:43 [INFO]: Epoch 016 - training loss (MAE): 0.4794, validation MSE: 0.6317\n",
      "2025-06-24 01:25:59 [INFO]: Epoch 017 - training loss (MAE): 0.4437, validation MSE: 0.6060\n",
      "2025-06-24 01:26:17 [INFO]: Epoch 018 - training loss (MAE): 0.4194, validation MSE: 0.5841\n",
      "2025-06-24 01:26:34 [INFO]: Epoch 019 - training loss (MAE): 0.3940, validation MSE: 0.5634\n",
      "2025-06-24 01:26:49 [INFO]: Epoch 020 - training loss (MAE): 0.3770, validation MSE: 0.5511\n",
      "2025-06-24 01:27:05 [INFO]: Epoch 021 - training loss (MAE): 0.3464, validation MSE: 0.5298\n",
      "2025-06-24 01:27:20 [INFO]: Epoch 022 - training loss (MAE): 0.3306, validation MSE: 0.5281\n",
      "2025-06-24 01:27:35 [INFO]: Epoch 023 - training loss (MAE): 0.3110, validation MSE: 0.5133\n",
      "2025-06-24 01:27:51 [INFO]: Epoch 024 - training loss (MAE): 0.3100, validation MSE: 0.5113\n",
      "2025-06-24 01:28:06 [INFO]: Epoch 025 - training loss (MAE): 0.2937, validation MSE: 0.4972\n",
      "2025-06-24 01:28:06 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 01:28:06 [INFO]: Saved the model to ./brits_model\\20250624_T011644\\BRITS.pypots\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "rnn_hidden = 0\n",
    "# Initialize and fit BRITS models for each missing rate\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    print(f\"Training BRITS models for cluster {cluster_id}...\")\n",
    "    models[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        print(f\"Training model for missing rate {rate} in cluster {cluster_id}...\")\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        _, n_steps, n_features = train_data[cluster_id][key][\"X\"].shape\n",
    "        \n",
    "        # Reduce complexity of model for less features\n",
    "        if cluster_id != len(clusters) - 1:\n",
    "            rnn_hidden = 16\n",
    "        else:\n",
    "            rnn_hidden = 32\n",
    "        \n",
    "        models[cluster_id][key] = intialize_BRITS(n_steps, n_features, rnn_hidden)\n",
    "        models[cluster_id][key].fit(train_data[cluster_id][key], val_set=val_data[cluster_id][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b09f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluation, since BRITS does not have passed ground truth without missing values.\n",
    "\n",
    "imputed = {}\n",
    "\n",
    "# Impute missing values using the trained models\n",
    "for cluster_id in range(len(clusters)):\n",
    "    imputed[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        imputed[cluster_id][key] = models[cluster_id][key].impute(val_data[cluster_id][key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d55299",
   "metadata": {},
   "source": [
    "### Unscale data before evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab456f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_group_feature_indices(columns):\n",
    "    group_feature_indices = {\n",
    "        'temp': [columns.index(col) for col in temp_cols if col in columns],\n",
    "        'humidity': [columns.index(col) for col in humidity_cols if col in columns],\n",
    "        'water_flow': [columns.index(col) for col in water_flow_cols if col in columns],\n",
    "        'air_flow': [columns.index(col) for col in air_flow_cols if col in columns],\n",
    "        'power': [columns.index(col) for col in power_cols if col in columns],\n",
    "        'speed': [columns.index(col) for col in speed_cols if col in columns],\n",
    "        # Binary skipped\n",
    "    }\n",
    "    return group_feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca1113ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "def unscale_imputed_by_group(imputed_data, cluster_id, group_feature_indices):\n",
    "    n_samples, n_steps, _ = imputed_data.shape\n",
    "    unscaled = np.zeros_like(imputed_data)\n",
    "\n",
    "    # Unscale for each group inside each cluster\n",
    "    for group_name, indices in group_feature_indices.items():\n",
    "        if not indices:\n",
    "            continue  # Skip if no features in this group\n",
    "\n",
    "        scaler_path = f\"{group_name}_scaler_{cluster_id}.pkl\"\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        \n",
    "        # Extract and reshape group data\n",
    "        group_data = imputed_data[:, :, indices].reshape(-1, len(indices))\n",
    "\n",
    "        # Inverse transform\n",
    "        group_data_unscaled = scaler.inverse_transform(group_data)\n",
    "\n",
    "        # Reshape back to original\n",
    "        group_data_unscaled = group_data_unscaled.reshape(n_samples, n_steps, len(indices))\n",
    "\n",
    "        # Insert into final tensor\n",
    "        for i, f_idx in enumerate(indices):\n",
    "            unscaled[:, :, f_idx] = group_data_unscaled[:, :, i]\n",
    "\n",
    "    return unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a8df37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_unscaled = {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    imputed_unscaled[cluster_id] = {}\n",
    "\n",
    "    # Extract column names of the cluster to recompute group_feature_indices\n",
    "    cluster_columns = list(clusters[cluster_id].columns)\n",
    "    group_feature_indices = build_group_feature_indices(cluster_columns)\n",
    "\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        imputed_unscaled[cluster_id][key] = unscale_imputed_by_group(\n",
    "            imputed_data=imputed[cluster_id][key],\n",
    "            cluster_id=cluster_id,\n",
    "            group_feature_indices=group_feature_indices\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dde7bf3",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c85268f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Cluster 0 Rate 5%: -0.771\n",
      "R² Cluster 0 Rate 20%: 0.280\n",
      "R² Cluster 0 Rate 60%: -0.424\n",
      "R² Cluster 0 Rate 90%: -0.379\n",
      "R² Cluster 1 Rate 5%: -1.512\n",
      "R² Cluster 1 Rate 20%: -8.735\n",
      "R² Cluster 1 Rate 60%: -1.278\n",
      "R² Cluster 1 Rate 90%: -3.744\n",
      "R² Cluster 2 Rate 5%: 0.366\n",
      "R² Cluster 2 Rate 20%: 0.874\n",
      "R² Cluster 2 Rate 60%: 0.682\n",
      "R² Cluster 2 Rate 90%: -0.075\n",
      "R² Cluster 3 Rate 5%: 0.749\n",
      "R² Cluster 3 Rate 20%: 0.493\n",
      "R² Cluster 3 Rate 60%: 0.623\n",
      "R² Cluster 3 Rate 90%: -0.605\n",
      "R² Cluster 4 Rate 5%: -1.636\n",
      "R² Cluster 4 Rate 20%: 0.654\n",
      "R² Cluster 4 Rate 60%: -0.704\n",
      "R² Cluster 4 Rate 90%: 0.226\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_scores = {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    r2_scores[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        imputed = imputed_unscaled[cluster_id][key]\n",
    "        original = X_val_full_unscaled_seq_tensor[cluster_id]\n",
    "        mask = val_masks_seq[cluster_id][key]\n",
    "\n",
    "        # Initialize list for per-feature R²\n",
    "        feature_r2 = []\n",
    "\n",
    "        for f in range(original.shape[2]):  # loop over features\n",
    "            f_mask = mask[:, :, f]\n",
    "            if not np.any(f_mask):\n",
    "                continue  # skip if no missing values for this feature\n",
    "\n",
    "            y_true = original[:, :, f][f_mask]\n",
    "            y_pred = imputed[:, :, f][f_mask]\n",
    "\n",
    "            if len(y_true) < 2:\n",
    "                continue  # not enough points to compute R²\n",
    "\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            feature_r2.append(r2)\n",
    "\n",
    "        if feature_r2:\n",
    "            r2_scores[cluster_id][key] = np.mean(feature_r2)\n",
    "        else:\n",
    "            r2_scores[cluster_id][key] = np.nan  # or 0 or another fallback\n",
    "\n",
    "        print(f\"R² Cluster {cluster_id} Rate {rate*100:.0f}%: {r2_scores[cluster_id][key]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f359216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE Cluster 0 Rate 5.0%: 77.05%\n",
      "SMAPE Cluster 0 Rate 20.0%: 16.34%\n",
      "SMAPE Cluster 0 Rate 60.0%: 129.09%\n",
      "SMAPE Cluster 0 Rate 90.0%: 127.69%\n",
      "SMAPE Cluster 1 Rate 5.0%: 54.54%\n",
      "SMAPE Cluster 1 Rate 20.0%: 47.10%\n",
      "SMAPE Cluster 1 Rate 60.0%: 36.97%\n",
      "SMAPE Cluster 1 Rate 90.0%: 84.86%\n",
      "SMAPE Cluster 2 Rate 5.0%: 63.56%\n",
      "SMAPE Cluster 2 Rate 20.0%: 184.10%\n",
      "SMAPE Cluster 2 Rate 60.0%: 170.21%\n",
      "SMAPE Cluster 2 Rate 90.0%: 168.36%\n",
      "SMAPE Cluster 3 Rate 5.0%: 1.90%\n",
      "SMAPE Cluster 3 Rate 20.0%: 2.08%\n",
      "SMAPE Cluster 3 Rate 60.0%: 5.00%\n",
      "SMAPE Cluster 3 Rate 90.0%: 6.75%\n",
      "SMAPE Cluster 4 Rate 5.0%: 47.02%\n",
      "SMAPE Cluster 4 Rate 20.0%: 22.89%\n",
      "SMAPE Cluster 4 Rate 60.0%: 57.66%\n",
      "SMAPE Cluster 4 Rate 90.0%: 52.80%\n"
     ]
    }
   ],
   "source": [
    "smape = {}\n",
    "for cluster_id in range(len(clusters)):\n",
    "    smape[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        imputed = imputed_unscaled[cluster_id][key]  # shape (n_samples, n_steps, n_features)\n",
    "        original = X_val_full_unscaled_seq_tensor[cluster_id]  # same shape\n",
    "        mask = val_masks_seq[cluster_id][key]  # same shape (bool mask)\n",
    "\n",
    "        n_samples, n_steps, n_features = original.shape\n",
    "\n",
    "        feature_smapes = []\n",
    "        for f in range(n_features):\n",
    "            # Select the mask and data for feature f\n",
    "            f_mask = mask[:, :, f]\n",
    "            if not np.any(f_mask):\n",
    "                continue  # skip if no missing values for this feature\n",
    "\n",
    "            numerator = np.abs(imputed[:, :, f][f_mask] - original[:, :, f][f_mask])\n",
    "            denominator = np.abs(imputed[:, :, f][f_mask]) + np.abs(original[:, :, f][f_mask]) + 1e-8\n",
    "            smape_f = 100 * np.mean(2 * numerator / denominator)\n",
    "            feature_smapes.append(smape_f)\n",
    "\n",
    "        smape[cluster_id][key] = np.mean(feature_smapes) if feature_smapes else np.nan\n",
    "        print(f\"SMAPE Cluster {cluster_id} Rate {rate*100}%: {smape[cluster_id][key]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b0397",
   "metadata": {},
   "source": [
    "### Average errors per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70d1b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_per_cluster = {i: X_val_full_unscaled_seq_tensor[i].shape[-1] for i in range(len(clusters))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbf477b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4, 1: 11, 2: 2, 3: 3, 4: 26}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cace70fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average NRMSE for rate 5.0%: -0.84%\n",
      "NRMSE for full at rate 5.0%: -1.64%\n",
      "Weighted Average NRMSE for rate 20.0%: -4.59%\n",
      "NRMSE for full at rate 20.0%: 0.65%\n",
      "Weighted Average NRMSE for rate 60.0%: -0.63%\n",
      "NRMSE for full at rate 60.0%: -0.70%\n",
      "Weighted Average NRMSE for rate 90.0%: -2.23%\n",
      "NRMSE for full at rate 90.0%: 0.23%\n"
     ]
    }
   ],
   "source": [
    "n_clusters = len(clusters) - 1  # number of actual clusters\n",
    "flow_all_id = len(clusters) - 1  # index of the full dataset\n",
    "\n",
    "avg_r2_cluster = {}\n",
    "r2_all = {}\n",
    "\n",
    "for rate in missing_rates:\n",
    "    key = int(rate * 100)\n",
    "\n",
    "    # Gather NRMSE and weights (number of features per cluster)\n",
    "    r2_values = np.array([r2_scores[cluster_id][key] for cluster_id in range(n_clusters)])\n",
    "    feature_counts = np.array([features_per_cluster[cluster_id] for cluster_id in range(n_clusters)])\n",
    "\n",
    "    # Compute weighted average\n",
    "    weighted_avg = np.average(r2_values, weights=feature_counts)\n",
    "    \n",
    "    avg_r2_cluster[key] = weighted_avg\n",
    "    r2_all[key] = r2_scores[flow_all_id][key]  # for full feature set\n",
    "\n",
    "    print(f\"Weighted Average NRMSE for rate {rate*100}%: {avg_r2_cluster[key]:.2f}%\")\n",
    "    print(f\"NRMSE for full at rate {rate*100}%: {r2_all[key]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4bb9d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average SMAPE for rate 5.0%: 52.05%\n",
      "SMAPE for full at rate 5.0%: 47.02%\n",
      "Weighted Average SMAPE for rate 20.0%: 47.89%\n",
      "SMAPE for full at rate 20.0%: 22.89%\n",
      "Weighted Average SMAPE for rate 60.0%: 63.92%\n",
      "SMAPE for full at rate 60.0%: 57.66%\n",
      "Weighted Average SMAPE for rate 90.0%: 90.06%\n",
      "SMAPE for full at rate 90.0%: 52.80%\n"
     ]
    }
   ],
   "source": [
    "avg_smape_cluster = {}\n",
    "smape_all = {}\n",
    "\n",
    "for rate in missing_rates:\n",
    "    key = int(rate * 100)\n",
    "    \n",
    "    # Gather SMAPE and weights (number of features per cluster)\n",
    "    smape_values = np.array([smape[cluster_id][key] for cluster_id in range(n_clusters)])\n",
    "    feature_counts = np.array([features_per_cluster[cluster_id] for cluster_id in range(n_clusters)])\n",
    "    \n",
    "    # Compute weighted average\n",
    "    weighted_avg = np.average(smape_values, weights=feature_counts)\n",
    "    \n",
    "    avg_smape_cluster[key] = weighted_avg\n",
    "    smape_all[key] = smape[flow_all_id][key]  # for full feature set\n",
    "    \n",
    "    print(f\"Weighted Average SMAPE for rate {rate*100}%: {avg_smape_cluster[key]:.2f}%\")\n",
    "    print(f\"SMAPE for full at rate {rate*100}%: {smape_all[key]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "533c079a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_missing_vs_observed(data, mask, feature_name=\"flow\"):\n",
    "    \"\"\"\n",
    "    data: 1D array of original values\n",
    "    mask: 1D boolean array, True if missing\n",
    "    feature_name: for labeling\n",
    "    \"\"\"\n",
    "    data_missing = data[mask]\n",
    "    data_observed = data[~mask]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(data_observed, color='blue', label='Observed', kde=True, stat=\"density\", bins=30)\n",
    "    sns.histplot(data_missing, color='red', label='Missing', kde=True, stat=\"density\", bins=30)\n",
    "    plt.title(f\"Distribution of {feature_name} - Observed vs Missing\")\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_missing_vs_observed(X_val_full_unscaled_seq_tensor[1].flatten(), val_masks_seq[1][20].flatten(), feature_name=\"Flow at 20% missingness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37e8d714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example error values (replace with your real variables)\n",
    "missing_levels = ['20%', '40%', '60%', '90%']\n",
    "\n",
    "# Bar chart setup\n",
    "x = np.arange(len(missing_levels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# --- MAE plot ---\n",
    "ax[0].bar(x - width/2, r2_all.values(), width, label='Without Semantics', color='tab:blue')\n",
    "ax[0].bar(x + width/2, avg_r2_cluster.values(), width, label='With Semantics', color='tab:orange')\n",
    "ax[0].set_ylabel('MAE')\n",
    "ax[0].set_title('MAE by Missingness Level')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# --- SMAPE plot ---\n",
    "ax[1].bar(x - width/2, smape_all.values(), width, label='Without Semantics', color='tab:blue')\n",
    "ax[1].bar(x + width/2, avg_smape_cluster.values(), width, label='With Semantics', color='tab:orange')\n",
    "ax[1].set_ylabel('SMAPE (%)')\n",
    "ax[1].set_title('SMAPE by Missingness Level')\n",
    "ax[1].set_xticks(x)\n",
    "ax[1].set_xticklabels(missing_levels)\n",
    "ax[1].legend()\n",
    "ax[1].grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
