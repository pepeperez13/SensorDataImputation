{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49cabb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc4a17",
   "metadata": {},
   "source": [
    "## Get measurements from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06053be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_readings = pd.read_csv(\"D:\\Master\\Thesis\\Code\\LeakDB\\LeakDB-master\\measurements\\measurements_1_LeakDB.csv\")\n",
    "\n",
    "sensor_readings['Timestamp'] = pd.to_datetime(sensor_readings['Timestamp'])\n",
    "\n",
    "# Extract entity ID and type\n",
    "sensor_readings['entity_id'] = sensor_readings['sensor_id'].apply(lambda x: \"_\".join(x.split(\"_\")[:2]))  # e.g., Node_1 or Pipe_12\n",
    "sensor_readings['measurement_type'] = sensor_readings['sensor_type']  # demand, pressure, flow\n",
    "sensor_readings['entity_type'] = sensor_readings['entity_id'].apply(lambda x: x.split(\"_\")[0])  # Node or Pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0005913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes → pressure & demand\n",
    "node_df = sensor_readings[sensor_readings['entity_type'] == 'Node']\n",
    "node_pivot = node_df.pivot_table(index='Timestamp', columns=['entity_id', 'measurement_type'], values='measurement')\n",
    "\n",
    "# Pipes → flow\n",
    "pipe_df = sensor_readings[sensor_readings['entity_type'] == 'Link']\n",
    "pipe_pivot = pipe_df.pivot_table(index='Timestamp', columns=['entity_id', 'measurement_type'], values='measurement')\n",
    "\n",
    "# Rewrite column names\n",
    "node_pivot.columns = ['_'.join(col).strip() for col in node_pivot.columns.values]\n",
    "pipe_pivot.columns = ['_'.join(col).strip() for col in pipe_pivot.columns.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c18916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link_1_flow</th>\n",
       "      <th>Link_10_flow</th>\n",
       "      <th>Link_11_flow</th>\n",
       "      <th>Link_12_flow</th>\n",
       "      <th>Link_13_flow</th>\n",
       "      <th>Link_14_flow</th>\n",
       "      <th>Link_15_flow</th>\n",
       "      <th>Link_16_flow</th>\n",
       "      <th>Link_17_flow</th>\n",
       "      <th>Link_18_flow</th>\n",
       "      <th>...</th>\n",
       "      <th>Link_31_flow</th>\n",
       "      <th>Link_32_flow</th>\n",
       "      <th>Link_33_flow</th>\n",
       "      <th>Link_34_flow</th>\n",
       "      <th>Link_4_flow</th>\n",
       "      <th>Link_5_flow</th>\n",
       "      <th>Link_6_flow</th>\n",
       "      <th>Link_7_flow</th>\n",
       "      <th>Link_8_flow</th>\n",
       "      <th>Link_9_flow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>3405.6</td>\n",
       "      <td>352.8</td>\n",
       "      <td>270.0</td>\n",
       "      <td>172.8</td>\n",
       "      <td>190.8</td>\n",
       "      <td>82.8</td>\n",
       "      <td>39.6</td>\n",
       "      <td>68.4</td>\n",
       "      <td>-212.4</td>\n",
       "      <td>-489.6</td>\n",
       "      <td>...</td>\n",
       "      <td>25.2</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1378.8</td>\n",
       "      <td>1234.8</td>\n",
       "      <td>1040.4</td>\n",
       "      <td>824.4</td>\n",
       "      <td>716.4</td>\n",
       "      <td>630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:30:00</th>\n",
       "      <td>2970.0</td>\n",
       "      <td>295.2</td>\n",
       "      <td>230.4</td>\n",
       "      <td>144.0</td>\n",
       "      <td>172.8</td>\n",
       "      <td>75.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>57.6</td>\n",
       "      <td>-194.4</td>\n",
       "      <td>-428.4</td>\n",
       "      <td>...</td>\n",
       "      <td>21.6</td>\n",
       "      <td>-32.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>169.2</td>\n",
       "      <td>1166.4</td>\n",
       "      <td>1054.8</td>\n",
       "      <td>900.0</td>\n",
       "      <td>723.6</td>\n",
       "      <td>615.6</td>\n",
       "      <td>543.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>2656.8</td>\n",
       "      <td>273.6</td>\n",
       "      <td>208.8</td>\n",
       "      <td>126.0</td>\n",
       "      <td>151.2</td>\n",
       "      <td>64.8</td>\n",
       "      <td>32.4</td>\n",
       "      <td>50.4</td>\n",
       "      <td>-172.8</td>\n",
       "      <td>-388.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-21.6</td>\n",
       "      <td>32.4</td>\n",
       "      <td>158.4</td>\n",
       "      <td>1054.8</td>\n",
       "      <td>957.6</td>\n",
       "      <td>802.8</td>\n",
       "      <td>640.8</td>\n",
       "      <td>561.6</td>\n",
       "      <td>493.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:30:00</th>\n",
       "      <td>2401.2</td>\n",
       "      <td>241.2</td>\n",
       "      <td>183.6</td>\n",
       "      <td>108.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>57.6</td>\n",
       "      <td>28.8</td>\n",
       "      <td>43.2</td>\n",
       "      <td>-154.8</td>\n",
       "      <td>-363.6</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-25.2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>946.8</td>\n",
       "      <td>860.4</td>\n",
       "      <td>734.4</td>\n",
       "      <td>583.2</td>\n",
       "      <td>507.6</td>\n",
       "      <td>442.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>2199.6</td>\n",
       "      <td>219.6</td>\n",
       "      <td>165.6</td>\n",
       "      <td>100.8</td>\n",
       "      <td>133.2</td>\n",
       "      <td>57.6</td>\n",
       "      <td>28.8</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-147.6</td>\n",
       "      <td>-338.4</td>\n",
       "      <td>...</td>\n",
       "      <td>14.4</td>\n",
       "      <td>-21.6</td>\n",
       "      <td>32.4</td>\n",
       "      <td>133.2</td>\n",
       "      <td>856.8</td>\n",
       "      <td>774.0</td>\n",
       "      <td>658.8</td>\n",
       "      <td>532.8</td>\n",
       "      <td>457.2</td>\n",
       "      <td>403.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 21:30:00</th>\n",
       "      <td>5652.0</td>\n",
       "      <td>579.6</td>\n",
       "      <td>439.2</td>\n",
       "      <td>273.6</td>\n",
       "      <td>313.2</td>\n",
       "      <td>129.6</td>\n",
       "      <td>61.2</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-352.8</td>\n",
       "      <td>-752.4</td>\n",
       "      <td>...</td>\n",
       "      <td>46.8</td>\n",
       "      <td>-64.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>2293.2</td>\n",
       "      <td>2055.6</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>1353.6</td>\n",
       "      <td>1191.6</td>\n",
       "      <td>1047.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 22:00:00</th>\n",
       "      <td>5360.4</td>\n",
       "      <td>554.4</td>\n",
       "      <td>421.2</td>\n",
       "      <td>273.6</td>\n",
       "      <td>298.8</td>\n",
       "      <td>129.6</td>\n",
       "      <td>68.4</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-331.2</td>\n",
       "      <td>-687.6</td>\n",
       "      <td>...</td>\n",
       "      <td>39.6</td>\n",
       "      <td>-64.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>331.2</td>\n",
       "      <td>2145.6</td>\n",
       "      <td>1940.4</td>\n",
       "      <td>1641.6</td>\n",
       "      <td>1285.2</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 22:30:00</th>\n",
       "      <td>4935.6</td>\n",
       "      <td>518.4</td>\n",
       "      <td>399.6</td>\n",
       "      <td>255.6</td>\n",
       "      <td>270.0</td>\n",
       "      <td>111.6</td>\n",
       "      <td>54.0</td>\n",
       "      <td>115.2</td>\n",
       "      <td>-309.6</td>\n",
       "      <td>-630.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.4</td>\n",
       "      <td>-57.6</td>\n",
       "      <td>82.8</td>\n",
       "      <td>284.4</td>\n",
       "      <td>2026.8</td>\n",
       "      <td>1814.4</td>\n",
       "      <td>1526.4</td>\n",
       "      <td>1216.8</td>\n",
       "      <td>1054.8</td>\n",
       "      <td>932.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:00:00</th>\n",
       "      <td>4608.0</td>\n",
       "      <td>453.6</td>\n",
       "      <td>349.2</td>\n",
       "      <td>208.8</td>\n",
       "      <td>255.6</td>\n",
       "      <td>115.2</td>\n",
       "      <td>61.2</td>\n",
       "      <td>97.2</td>\n",
       "      <td>-288.0</td>\n",
       "      <td>-633.6</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-46.8</td>\n",
       "      <td>68.4</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1814.4</td>\n",
       "      <td>1648.8</td>\n",
       "      <td>1389.6</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>957.6</td>\n",
       "      <td>838.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:30:00</th>\n",
       "      <td>4093.2</td>\n",
       "      <td>421.2</td>\n",
       "      <td>324.0</td>\n",
       "      <td>205.2</td>\n",
       "      <td>226.8</td>\n",
       "      <td>97.2</td>\n",
       "      <td>46.8</td>\n",
       "      <td>86.4</td>\n",
       "      <td>-248.4</td>\n",
       "      <td>-576.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.8</td>\n",
       "      <td>-46.8</td>\n",
       "      <td>68.4</td>\n",
       "      <td>255.6</td>\n",
       "      <td>1630.8</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>986.4</td>\n",
       "      <td>853.2</td>\n",
       "      <td>756.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17520 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Link_1_flow  Link_10_flow  Link_11_flow  Link_12_flow  \\\n",
       "Timestamp                                                                    \n",
       "2017-01-01 00:00:00       3405.6         352.8         270.0         172.8   \n",
       "2017-01-01 00:30:00       2970.0         295.2         230.4         144.0   \n",
       "2017-01-01 01:00:00       2656.8         273.6         208.8         126.0   \n",
       "2017-01-01 01:30:00       2401.2         241.2         183.6         108.0   \n",
       "2017-01-01 02:00:00       2199.6         219.6         165.6         100.8   \n",
       "...                          ...           ...           ...           ...   \n",
       "2017-12-31 21:30:00       5652.0         579.6         439.2         273.6   \n",
       "2017-12-31 22:00:00       5360.4         554.4         421.2         273.6   \n",
       "2017-12-31 22:30:00       4935.6         518.4         399.6         255.6   \n",
       "2017-12-31 23:00:00       4608.0         453.6         349.2         208.8   \n",
       "2017-12-31 23:30:00       4093.2         421.2         324.0         205.2   \n",
       "\n",
       "                     Link_13_flow  Link_14_flow  Link_15_flow  Link_16_flow  \\\n",
       "Timestamp                                                                     \n",
       "2017-01-01 00:00:00         190.8          82.8          39.6          68.4   \n",
       "2017-01-01 00:30:00         172.8          75.6          36.0          57.6   \n",
       "2017-01-01 01:00:00         151.2          64.8          32.4          50.4   \n",
       "2017-01-01 01:30:00         144.0          57.6          28.8          43.2   \n",
       "2017-01-01 02:00:00         133.2          57.6          28.8          36.0   \n",
       "...                           ...           ...           ...           ...   \n",
       "2017-12-31 21:30:00         313.2         129.6          61.2         126.0   \n",
       "2017-12-31 22:00:00         298.8         129.6          68.4         126.0   \n",
       "2017-12-31 22:30:00         270.0         111.6          54.0         115.2   \n",
       "2017-12-31 23:00:00         255.6         115.2          61.2          97.2   \n",
       "2017-12-31 23:30:00         226.8          97.2          46.8          86.4   \n",
       "\n",
       "                     Link_17_flow  Link_18_flow  ...  Link_31_flow  \\\n",
       "Timestamp                                        ...                 \n",
       "2017-01-01 00:00:00        -212.4        -489.6  ...          25.2   \n",
       "2017-01-01 00:30:00        -194.4        -428.4  ...          21.6   \n",
       "2017-01-01 01:00:00        -172.8        -388.8  ...          18.0   \n",
       "2017-01-01 01:30:00        -154.8        -363.6  ...          18.0   \n",
       "2017-01-01 02:00:00        -147.6        -338.4  ...          14.4   \n",
       "...                           ...           ...  ...           ...   \n",
       "2017-12-31 21:30:00        -352.8        -752.4  ...          46.8   \n",
       "2017-12-31 22:00:00        -331.2        -687.6  ...          39.6   \n",
       "2017-12-31 22:30:00        -309.6        -630.0  ...          32.4   \n",
       "2017-12-31 23:00:00        -288.0        -633.6  ...          36.0   \n",
       "2017-12-31 23:30:00        -248.4        -576.0  ...          28.8   \n",
       "\n",
       "                     Link_32_flow  Link_33_flow  Link_34_flow  Link_4_flow  \\\n",
       "Timestamp                                                                    \n",
       "2017-01-01 00:00:00         -36.0          54.0         198.0       1378.8   \n",
       "2017-01-01 00:30:00         -32.4          46.8         169.2       1166.4   \n",
       "2017-01-01 01:00:00         -21.6          32.4         158.4       1054.8   \n",
       "2017-01-01 01:30:00         -25.2          36.0         144.0        946.8   \n",
       "2017-01-01 02:00:00         -21.6          32.4         133.2        856.8   \n",
       "...                           ...           ...           ...          ...   \n",
       "2017-12-31 21:30:00         -64.8          90.0         342.0       2293.2   \n",
       "2017-12-31 22:00:00         -64.8          90.0         331.2       2145.6   \n",
       "2017-12-31 22:30:00         -57.6          82.8         284.4       2026.8   \n",
       "2017-12-31 23:00:00         -46.8          68.4         270.0       1814.4   \n",
       "2017-12-31 23:30:00         -46.8          68.4         255.6       1630.8   \n",
       "\n",
       "                     Link_5_flow  Link_6_flow  Link_7_flow  Link_8_flow  \\\n",
       "Timestamp                                                                 \n",
       "2017-01-01 00:00:00       1234.8       1040.4        824.4        716.4   \n",
       "2017-01-01 00:30:00       1054.8        900.0        723.6        615.6   \n",
       "2017-01-01 01:00:00        957.6        802.8        640.8        561.6   \n",
       "2017-01-01 01:30:00        860.4        734.4        583.2        507.6   \n",
       "2017-01-01 02:00:00        774.0        658.8        532.8        457.2   \n",
       "...                          ...          ...          ...          ...   \n",
       "2017-12-31 21:30:00       2055.6       1746.0       1353.6       1191.6   \n",
       "2017-12-31 22:00:00       1940.4       1641.6       1285.2       1116.0   \n",
       "2017-12-31 22:30:00       1814.4       1526.4       1216.8       1054.8   \n",
       "2017-12-31 23:00:00       1648.8       1389.6       1098.0        957.6   \n",
       "2017-12-31 23:30:00       1476.0       1242.0        986.4        853.2   \n",
       "\n",
       "                     Link_9_flow  \n",
       "Timestamp                         \n",
       "2017-01-01 00:00:00        630.0  \n",
       "2017-01-01 00:30:00        543.6  \n",
       "2017-01-01 01:00:00        493.2  \n",
       "2017-01-01 01:30:00        442.8  \n",
       "2017-01-01 02:00:00        403.2  \n",
       "...                          ...  \n",
       "2017-12-31 21:30:00       1047.6  \n",
       "2017-12-31 22:00:00        990.0  \n",
       "2017-12-31 22:30:00        932.4  \n",
       "2017-12-31 23:00:00        838.8  \n",
       "2017-12-31 23:30:00        756.0  \n",
       "\n",
       "[17520 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf609795",
   "metadata": {},
   "source": [
    "### Separate data by feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbf31ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_cols = [col for col in node_pivot.columns if col.endswith(\"demand\")]\n",
    "pressure_cols = [col for col in node_pivot.columns if col.endswith(\"pressure\")]\n",
    "\n",
    "demand_df = node_pivot[demand_cols]\n",
    "pressure_df = node_pivot[pressure_cols]\n",
    "flow_df = pipe_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed9ba0",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68121c6",
   "metadata": {},
   "source": [
    "### Split train/val, and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d22de467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "import joblib\n",
    "\n",
    "def split_scale(measurements, feature, cluster):\n",
    "\n",
    "    # Step 1: Split the full data (X_seq or X_ori) into train and validation sets\n",
    "    X_train_full, X_val_full = train_test_split(measurements, test_size=0.2, shuffle = False, random_state=42)\n",
    "    # Include k cross fold validation (5 k at least)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform training data\n",
    "    X_train_full_scaled = X_train_full.copy()\n",
    "    X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
    "    X_train_full_scaled = pd.DataFrame(X_train_full_scaled, columns=X_train_full.columns, index=X_train_full.index)\n",
    "\n",
    "    # Save scaler with specific name for later rescaling\n",
    "    joblib.dump(scaler, f\"{feature}_scaler_{cluster}.pkl\")\n",
    "\n",
    "    # Now, apply ONLY transformation (not fitting) on val data\n",
    "    X_val_full_scaled = X_val_full.copy()\n",
    "    X_val_full_scaled = scaler.transform(X_val_full)\n",
    "    X_val_full_scaled = pd.DataFrame(X_val_full_scaled, columns=X_val_full.columns, index=X_val_full.index)\n",
    "\n",
    "    return X_train_full_scaled, X_val_full_scaled, X_train_full, X_val_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16492ceb",
   "metadata": {},
   "source": [
    "### Select semantically relevant pipes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29282b6",
   "metadata": {},
   "source": [
    "Cluster 0: Pipe_13, Pipe_14, Pipe_15, Pipe_17, Pipe_19, Pipe_26, Pipe_27, Pipe_28, Pipe_29, Pipe_32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf86b0d",
   "metadata": {},
   "source": [
    "Cluster 1: Pipe_1, Pipe_11, Pipe_24, Pipe_3, Pipe_4, Pipe_5, Pipe_6, Pipe_7, Pipe_8, Pipe_9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b18e9c",
   "metadata": {},
   "source": [
    "Cluster 3: Pipe_10, Pipe_18, Pipe_2, Pipe_21, Pipe_22, Pipe_25, Pipe_30, Pipe_31, Pipe_33, Pipe_34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda274ac",
   "metadata": {},
   "source": [
    "Cluster 2: Pipe_12, Pipe_16, Pipe_20, Pipe_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76764de",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_c1 = flow_df[[\"Link_1_flow\", \"Link_11_flow\", \"Link_24_flow\", \"Link_3_flow\", \"Link_4_flow\", \"Link_5_flow\", \"Link_6_flow\", \"Link_7_flow\", \"Link_8_flow\", \"Link_9_flow\"]]\n",
    "flow_c0 = flow_df[[\"Link_13_flow\", \"Link_14_flow\", \"Link_15_flow\", \"Link_17_flow\", \"Link_19_flow\", \"Link_26_flow\", \"Link_27_flow\", \"Link_28_flow\", \"Link_29_flow\", \"Link_32_flow\"]]\n",
    "flow_c3 = flow_df[[\"Link_10_flow\", \"Link_18_flow\", \"Link_2_flow\", \"Link_21_flow\", \"Link_22_flow\", \"Link_25_flow\", \"Link_30_flow\", \"Link_31_flow\", \"Link_33_flow\", \"Link_34_flow\"]]\n",
    "flow_c2 = flow_df[[\"Link_12_flow\", \"Link_16_flow\", \"Link_20_flow\", \"Link_23_flow\"]]\n",
    "flow_all = flow_df\n",
    "\n",
    "# Initialize the containers\n",
    "X_train_full_scaled = {}\n",
    "X_val_full_scaled = {}\n",
    "X_train_full_unscaled = {}\n",
    "X_val_full_unscaled = {}\n",
    "clusters = [flow_c0, flow_c1, flow_c2, flow_c3, flow_all]\n",
    "\n",
    "# Iterate over the clusters\n",
    "for i, flow_cluster in enumerate(clusters):\n",
    "    X_train_full_scaled[i], X_val_full_scaled[i], X_train_full_unscaled[i], X_val_full_unscaled[i] = split_scale(flow_cluster, \"flow\", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca466441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link_1_flow</th>\n",
       "      <th>Link_11_flow</th>\n",
       "      <th>Link_24_flow</th>\n",
       "      <th>Link_3_flow</th>\n",
       "      <th>Link_4_flow</th>\n",
       "      <th>Link_5_flow</th>\n",
       "      <th>Link_6_flow</th>\n",
       "      <th>Link_7_flow</th>\n",
       "      <th>Link_8_flow</th>\n",
       "      <th>Link_9_flow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>3405.6</td>\n",
       "      <td>270.0</td>\n",
       "      <td>561.6</td>\n",
       "      <td>1396.8</td>\n",
       "      <td>1378.8</td>\n",
       "      <td>1234.8</td>\n",
       "      <td>1040.4</td>\n",
       "      <td>824.4</td>\n",
       "      <td>716.4</td>\n",
       "      <td>630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:30:00</th>\n",
       "      <td>2970.0</td>\n",
       "      <td>230.4</td>\n",
       "      <td>482.4</td>\n",
       "      <td>1180.8</td>\n",
       "      <td>1166.4</td>\n",
       "      <td>1054.8</td>\n",
       "      <td>900.0</td>\n",
       "      <td>723.6</td>\n",
       "      <td>615.6</td>\n",
       "      <td>543.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>2656.8</td>\n",
       "      <td>208.8</td>\n",
       "      <td>435.6</td>\n",
       "      <td>1069.2</td>\n",
       "      <td>1054.8</td>\n",
       "      <td>957.6</td>\n",
       "      <td>802.8</td>\n",
       "      <td>640.8</td>\n",
       "      <td>561.6</td>\n",
       "      <td>493.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:30:00</th>\n",
       "      <td>2401.2</td>\n",
       "      <td>183.6</td>\n",
       "      <td>385.2</td>\n",
       "      <td>957.6</td>\n",
       "      <td>946.8</td>\n",
       "      <td>860.4</td>\n",
       "      <td>734.4</td>\n",
       "      <td>583.2</td>\n",
       "      <td>507.6</td>\n",
       "      <td>442.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>2199.6</td>\n",
       "      <td>165.6</td>\n",
       "      <td>363.6</td>\n",
       "      <td>867.6</td>\n",
       "      <td>856.8</td>\n",
       "      <td>774.0</td>\n",
       "      <td>658.8</td>\n",
       "      <td>532.8</td>\n",
       "      <td>457.2</td>\n",
       "      <td>403.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-19 21:30:00</th>\n",
       "      <td>5464.8</td>\n",
       "      <td>406.8</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2152.8</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>1904.4</td>\n",
       "      <td>1627.2</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>1137.6</td>\n",
       "      <td>1000.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-19 22:00:00</th>\n",
       "      <td>5151.6</td>\n",
       "      <td>414.0</td>\n",
       "      <td>853.2</td>\n",
       "      <td>2077.2</td>\n",
       "      <td>2044.8</td>\n",
       "      <td>1850.4</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1090.8</td>\n",
       "      <td>968.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-19 22:30:00</th>\n",
       "      <td>4870.8</td>\n",
       "      <td>396.0</td>\n",
       "      <td>795.6</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1969.2</td>\n",
       "      <td>1771.2</td>\n",
       "      <td>1501.2</td>\n",
       "      <td>1202.4</td>\n",
       "      <td>1047.6</td>\n",
       "      <td>914.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-19 23:00:00</th>\n",
       "      <td>4644.0</td>\n",
       "      <td>381.6</td>\n",
       "      <td>730.8</td>\n",
       "      <td>1922.4</td>\n",
       "      <td>1897.2</td>\n",
       "      <td>1702.8</td>\n",
       "      <td>1425.6</td>\n",
       "      <td>1126.8</td>\n",
       "      <td>979.2</td>\n",
       "      <td>867.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-19 23:30:00</th>\n",
       "      <td>4316.4</td>\n",
       "      <td>338.4</td>\n",
       "      <td>676.8</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>1717.2</td>\n",
       "      <td>1551.6</td>\n",
       "      <td>1303.2</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>892.8</td>\n",
       "      <td>788.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14016 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Link_1_flow  Link_11_flow  Link_24_flow  Link_3_flow  \\\n",
       "Timestamp                                                                   \n",
       "2017-01-01 00:00:00       3405.6         270.0         561.6       1396.8   \n",
       "2017-01-01 00:30:00       2970.0         230.4         482.4       1180.8   \n",
       "2017-01-01 01:00:00       2656.8         208.8         435.6       1069.2   \n",
       "2017-01-01 01:30:00       2401.2         183.6         385.2        957.6   \n",
       "2017-01-01 02:00:00       2199.6         165.6         363.6        867.6   \n",
       "...                          ...           ...           ...          ...   \n",
       "2017-10-19 21:30:00       5464.8         406.8         900.0       2152.8   \n",
       "2017-10-19 22:00:00       5151.6         414.0         853.2       2077.2   \n",
       "2017-10-19 22:30:00       4870.8         396.0         795.6       1998.0   \n",
       "2017-10-19 23:00:00       4644.0         381.6         730.8       1922.4   \n",
       "2017-10-19 23:30:00       4316.4         338.4         676.8       1746.0   \n",
       "\n",
       "                     Link_4_flow  Link_5_flow  Link_6_flow  Link_7_flow  \\\n",
       "Timestamp                                                                 \n",
       "2017-01-01 00:00:00       1378.8       1234.8       1040.4        824.4   \n",
       "2017-01-01 00:30:00       1166.4       1054.8        900.0        723.6   \n",
       "2017-01-01 01:00:00       1054.8        957.6        802.8        640.8   \n",
       "2017-01-01 01:30:00        946.8        860.4        734.4        583.2   \n",
       "2017-01-01 02:00:00        856.8        774.0        658.8        532.8   \n",
       "...                          ...          ...          ...          ...   \n",
       "2017-10-19 21:30:00       2124.0       1904.4       1627.2       1296.0   \n",
       "2017-10-19 22:00:00       2044.8       1850.4       1566.0       1260.0   \n",
       "2017-10-19 22:30:00       1969.2       1771.2       1501.2       1202.4   \n",
       "2017-10-19 23:00:00       1897.2       1702.8       1425.6       1126.8   \n",
       "2017-10-19 23:30:00       1717.2       1551.6       1303.2       1026.0   \n",
       "\n",
       "                     Link_8_flow  Link_9_flow  \n",
       "Timestamp                                      \n",
       "2017-01-01 00:00:00        716.4        630.0  \n",
       "2017-01-01 00:30:00        615.6        543.6  \n",
       "2017-01-01 01:00:00        561.6        493.2  \n",
       "2017-01-01 01:30:00        507.6        442.8  \n",
       "2017-01-01 02:00:00        457.2        403.2  \n",
       "...                          ...          ...  \n",
       "2017-10-19 21:30:00       1137.6       1000.8  \n",
       "2017-10-19 22:00:00       1090.8        968.4  \n",
       "2017-10-19 22:30:00       1047.6        914.4  \n",
       "2017-10-19 23:00:00        979.2        867.6  \n",
       "2017-10-19 23:30:00        892.8        788.4  \n",
       "\n",
       "[14016 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full_unscaled[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78bbd500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_3d(data, window_size, stride):\n",
    "    \"\"\"\n",
    "    Converts a long time series [1, T, F] into [N, window_size, F]\n",
    "    \"\"\"\n",
    "    data = data.squeeze(0)  # [T, F]\n",
    "    total_steps, n_features = data.shape\n",
    "    windows = []\n",
    "\n",
    "    for i in range(0, total_steps - window_size + 1, stride):\n",
    "        window = data[i:i+window_size]\n",
    "        windows.append(window)\n",
    "\n",
    "    return np.stack(windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2efcd",
   "metadata": {},
   "source": [
    "### Introduce MAR Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afa26827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing 5.0% missingness for cluster 0 with key 5\n",
      "Actual missing rate: 2.98%\n",
      "Introducing 40.0% missingness for cluster 0 with key 40\n",
      "Actual missing rate: 24.27%\n",
      "Introducing 60.0% missingness for cluster 0 with key 60\n",
      "Actual missing rate: 35.95%\n",
      "Introducing 99.0% missingness for cluster 0 with key 99\n",
      "Actual missing rate: 59.41%\n",
      "Introducing 5.0% missingness for cluster 1 with key 5\n",
      "Actual missing rate: 2.96%\n",
      "Introducing 40.0% missingness for cluster 1 with key 40\n",
      "Actual missing rate: 24.00%\n",
      "Introducing 60.0% missingness for cluster 1 with key 60\n",
      "Actual missing rate: 35.84%\n",
      "Introducing 99.0% missingness for cluster 1 with key 99\n",
      "Actual missing rate: 59.40%\n",
      "Introducing 5.0% missingness for cluster 2 with key 5\n",
      "Actual missing rate: 3.64%\n",
      "Introducing 40.0% missingness for cluster 2 with key 40\n",
      "Actual missing rate: 29.83%\n",
      "Introducing 60.0% missingness for cluster 2 with key 60\n",
      "Actual missing rate: 44.92%\n",
      "Introducing 99.0% missingness for cluster 2 with key 99\n",
      "Actual missing rate: 74.27%\n",
      "Introducing 5.0% missingness for cluster 3 with key 5\n",
      "Actual missing rate: 3.03%\n",
      "Introducing 40.0% missingness for cluster 3 with key 40\n",
      "Actual missing rate: 24.02%\n",
      "Introducing 60.0% missingness for cluster 3 with key 60\n",
      "Actual missing rate: 35.93%\n",
      "Introducing 99.0% missingness for cluster 3 with key 99\n",
      "Actual missing rate: 59.41%\n",
      "Introducing 5.0% missingness for cluster 4 with key 5\n",
      "Actual missing rate: 3.13%\n",
      "Introducing 40.0% missingness for cluster 4 with key 40\n",
      "Actual missing rate: 24.69%\n",
      "Introducing 60.0% missingness for cluster 4 with key 60\n",
      "Actual missing rate: 37.12%\n",
      "Introducing 99.0% missingness for cluster 4 with key 99\n",
      "Actual missing rate: 61.14%\n"
     ]
    }
   ],
   "source": [
    "from pygrinder import mar_logistic\n",
    "\n",
    "missing_rates = [0.05, 0.4, 0.6, 0.99]\n",
    "\n",
    "# Training and validation sets for each cluster\n",
    "X_train_incomplete = {}\n",
    "X_val_incomplete = {}\n",
    "train_masks = {}\n",
    "val_masks = {}\n",
    "X_train_seq = {}\n",
    "X_val_seq = {}\n",
    "train_masks_seq = {}\n",
    "val_masks_seq = {}\n",
    "\n",
    "# Full tensors for each cluster\n",
    "X_train_full_tensor = {}\n",
    "X_val_full_tensor = {}\n",
    "X_val_full_seq = {}\n",
    "X_train_full_seq = {}\n",
    "X_train_full_unscaled_seq_tensor = {}\n",
    "X_val_full_unscaled_seq_tensor = {}\n",
    "\n",
    "\n",
    "n_steps = 168 # 3.5 days each window\n",
    "stride = 48 # 1 day stride\n",
    "\n",
    "for cluster_id, flow_cluster in enumerate(clusters):\n",
    "    X_train_incomplete[cluster_id] = {}\n",
    "    X_val_incomplete[cluster_id] = {}\n",
    "    train_masks[cluster_id] = {}\n",
    "    val_masks[cluster_id] = {}\n",
    "    X_train_seq[cluster_id] = {}\n",
    "    X_val_seq[cluster_id] = {}\n",
    "    train_masks_seq[cluster_id] = {}\n",
    "    val_masks_seq[cluster_id] = {}\n",
    "\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        # Introduce missingness per cluster & rate\n",
    "        print(f\"Introducing {rate*100}% missingness for cluster {cluster_id} with key {key}\")\n",
    "\n",
    "        # Apply MNAR-x missingness\n",
    "        X_train_incomplete[cluster_id][key] = mar_logistic(X_train_full_scaled[cluster_id].values, obs_rate=0.4, missing_rate=rate)\n",
    "        X_val_incomplete[cluster_id][key] = mar_logistic(X_val_full_scaled[cluster_id].values, obs_rate=0.4, missing_rate=rate)\n",
    "\n",
    "        # Masks for missingness\n",
    "        train_masks[cluster_id][key] = np.isnan(X_train_incomplete[cluster_id][key])\n",
    "        val_masks[cluster_id][key] = np.isnan(X_val_incomplete[cluster_id][key])\n",
    "\n",
    "        actual_missing_rate = train_masks[cluster_id][key].mean()\n",
    "        print(f\"Actual missing rate: {actual_missing_rate:.2%}\")\n",
    "        \n",
    "        # Expand dims for batch axis (needed for sliding window)\n",
    "        X_train_tensor = np.expand_dims(X_train_incomplete[cluster_id][key], axis=0)\n",
    "        X_val_tensor = np.expand_dims(X_val_incomplete[cluster_id][key], axis=0)\n",
    "        train_mask_tensor = np.expand_dims(train_masks[cluster_id][key], axis=0)\n",
    "        val_mask_tensor = np.expand_dims(val_masks[cluster_id][key], axis=0)\n",
    "\n",
    "        # Sliding window on data\n",
    "        X_train_seq[cluster_id][key] = sliding_window_3d(X_train_tensor, window_size=n_steps, stride=stride)\n",
    "        X_val_seq[cluster_id][key] = sliding_window_3d(X_val_tensor, window_size=n_steps, stride=stride)\n",
    "\n",
    "        # Sliding window on masks\n",
    "        train_masks_seq[cluster_id][key] = sliding_window_3d(train_mask_tensor, window_size=n_steps, stride=stride)\n",
    "        val_masks_seq[cluster_id][key] = sliding_window_3d(val_mask_tensor, window_size=n_steps, stride=stride)\n",
    "\n",
    "\n",
    "    # Expand full training tensors\n",
    "    X_train_full_tensor[cluster_id] = np.expand_dims(X_train_full_scaled[cluster_id].values, axis = 0)\n",
    "\n",
    "    # Expand full validation tensors\n",
    "    X_val_full_tensor[cluster_id] = np.expand_dims(X_val_full_scaled[cluster_id].values, axis = 0)\n",
    "\n",
    "    # Convert scaled data to tensor\n",
    "    X_val_full_seq[cluster_id] = sliding_window_3d(X_val_full_tensor[cluster_id], window_size=n_steps, stride=stride)\n",
    "    X_train_full_seq[cluster_id] = sliding_window_3d(X_train_full_tensor[cluster_id], window_size=n_steps, stride=stride)\n",
    "\n",
    "    # Convert unscaled data to tensor\n",
    "    X_train_full_unscaled_values = np.expand_dims(X_train_full_unscaled[cluster_id].values, axis=0)\n",
    "    X_train_full_unscaled_seq_tensor[cluster_id] = sliding_window_3d(X_train_full_unscaled_values, window_size=n_steps, stride=stride)\n",
    "\n",
    "    X_val_full_unscaled_values = np.expand_dims(X_val_full_unscaled[cluster_id].values, axis=0)\n",
    "    X_val_full_unscaled_seq_tensor[cluster_id] = sliding_window_3d(X_val_full_unscaled_values, window_size=n_steps, stride=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64f7d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare the final datasets with 'X' (incomplete) and 'X_ori' (full data)\n",
    "\n",
    "# 20 percent missing\n",
    "train_data, val_data = {}, {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    train_data[cluster_id] = {}\n",
    "    val_data[cluster_id] = {}\n",
    "    \n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        \n",
    "        # Prepare the train and validation data dictionaries for each missing rate\n",
    "        train_data[cluster_id][key] = {\"X\": X_train_seq[cluster_id][key]}\n",
    "        val_data[cluster_id][key] = {\"X\": X_val_seq[cluster_id][key], \"X_ori\": X_val_full_seq[cluster_id]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5463906",
   "metadata": {},
   "source": [
    "### Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef69c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_impute(X_incomplete):\n",
    "    \"\"\"\n",
    "    Impute missing values using feature-wise mean over the entire dataset.\n",
    "    Assumes input shape is [n_samples, n_steps, n_features].\n",
    "    \"\"\"\n",
    "    X_imputed = X_incomplete.copy()\n",
    "    n_features = X_imputed.shape[2]\n",
    "\n",
    "    for f in range(n_features):\n",
    "        feature_data = X_imputed[:, :, f]\n",
    "        mean_val = np.nanmean(feature_data)\n",
    "        feature_data[np.isnan(feature_data)] = mean_val\n",
    "        X_imputed[:, :, f] = feature_data\n",
    "\n",
    "    return X_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a43f5420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold results\n",
    "mean_imputed_results = {}\n",
    "missing_masks = {}\n",
    "\n",
    "for cluster_idx, cluster_data in enumerate(X_val_seq):\n",
    "    mean_imputed_results[cluster_idx] = {}\n",
    "    missing_masks[cluster_idx] = {}\n",
    "    \n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        X_missing = X_val_seq[cluster_idx][key]\n",
    "        \n",
    "        # Impute using mean\n",
    "        X_imputed = mean_impute(X_missing)\n",
    "        mean_imputed_results[cluster_idx][key] = X_imputed\n",
    "\n",
    "        # Create missing mask\n",
    "        missing_mask = np.isnan(X_missing)\n",
    "        missing_masks[cluster_idx][key] = missing_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c41cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "imputed_unscaled_mean = {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    imputed_unscaled_mean[cluster_id] = {}\n",
    "    \n",
    "    scaler = joblib.load(f\"flow_scaler_{cluster_id}.pkl\")\n",
    "    \n",
    "# Unscale the imputed values for each cluster and missing rate\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        n_samples, n_steps, n_features = mean_imputed_results[cluster_id][key].shape\n",
    "        tensor_2d = mean_imputed_results[cluster_id][key].reshape(-1, n_features)  # Flatten time dimension\n",
    "        tensor_2d_unscaled = scaler.inverse_transform(tensor_2d)\n",
    "        imputed_unscaled_mean[cluster_id][key] = tensor_2d_unscaled.reshape(n_samples, n_steps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3932cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Cluster 0 Rate 5.0% (MAE): 81.42315184104845\n",
      "MAE Cluster 0 Rate 40.0% (MAE): 87.13127596943515\n",
      "MAE Cluster 0 Rate 60.0% (MAE): 73.10090039452936\n",
      "MAE Cluster 0 Rate 99.0% (MAE): 85.48743541962585\n",
      "MAE Cluster 1 Rate 5.0% (MAE): 707.7912504084583\n",
      "MAE Cluster 1 Rate 40.0% (MAE): 565.6162554813036\n",
      "MAE Cluster 1 Rate 60.0% (MAE): 689.7286682186259\n",
      "MAE Cluster 1 Rate 99.0% (MAE): 691.1713973392746\n",
      "MAE Cluster 2 Rate 5.0% (MAE): 176.82281104347925\n",
      "MAE Cluster 2 Rate 40.0% (MAE): 190.8460027593263\n",
      "MAE Cluster 2 Rate 60.0% (MAE): 248.82809587549121\n",
      "MAE Cluster 2 Rate 99.0% (MAE): 186.62160267195807\n",
      "MAE Cluster 3 Rate 5.0% (MAE): 397.126233579805\n",
      "MAE Cluster 3 Rate 40.0% (MAE): 309.0796120508572\n",
      "MAE Cluster 3 Rate 60.0% (MAE): 108.99562330549843\n",
      "MAE Cluster 3 Rate 99.0% (MAE): 68.81730171472758\n",
      "MAE Cluster 4 Rate 5.0% (MAE): 267.33689918535816\n",
      "MAE Cluster 4 Rate 40.0% (MAE): 185.70176583754392\n",
      "MAE Cluster 4 Rate 60.0% (MAE): 280.8000989880321\n",
      "MAE Cluster 4 Rate 99.0% (MAE): 275.5950237009221\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE for imputation evaluation\n",
    "\n",
    "# Calculate MAE for imputation evaluation\n",
    "\n",
    "mae_mean = {}\n",
    "for cluster_id in range(len(clusters)):\n",
    "    mae_mean[cluster_id] = {}\n",
    "\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        mae_mean[cluster_id][key] = np.mean(np.abs(imputed_unscaled_mean[cluster_id][key][val_masks_seq[cluster_id][key]] - X_val_full_unscaled_seq_tensor[cluster_id][val_masks_seq[cluster_id][key]]))\n",
    "        print(f\"MAE Cluster {cluster_id} Rate {rate*100}% (MAE): {mae_mean[cluster_id][key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "368b57e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE Cluster 0 Rate 5.0%: 42.75%\n",
      "SMAPE Cluster 0 Rate 40.0%: 29.77%\n",
      "SMAPE Cluster 0 Rate 60.0%: 46.54%\n",
      "SMAPE Cluster 0 Rate 99.0%: 45.02%\n",
      "SMAPE Cluster 1 Rate 5.0%: 32.98%\n",
      "SMAPE Cluster 1 Rate 40.0%: 34.26%\n",
      "SMAPE Cluster 1 Rate 60.0%: 36.23%\n",
      "SMAPE Cluster 1 Rate 99.0%: 41.50%\n",
      "SMAPE Cluster 2 Rate 5.0%: 33.71%\n",
      "SMAPE Cluster 2 Rate 40.0%: 40.48%\n",
      "SMAPE Cluster 2 Rate 60.0%: 39.73%\n",
      "SMAPE Cluster 2 Rate 99.0%: 36.37%\n",
      "SMAPE Cluster 3 Rate 5.0%: 38.23%\n",
      "SMAPE Cluster 3 Rate 40.0%: 34.54%\n",
      "SMAPE Cluster 3 Rate 60.0%: 35.62%\n",
      "SMAPE Cluster 3 Rate 99.0%: 36.73%\n",
      "SMAPE Cluster 4 Rate 5.0%: 36.98%\n",
      "SMAPE Cluster 4 Rate 40.0%: 37.08%\n",
      "SMAPE Cluster 4 Rate 60.0%: 38.98%\n",
      "SMAPE Cluster 4 Rate 99.0%: 37.40%\n"
     ]
    }
   ],
   "source": [
    "#SMAPE for each percentage of missingness\n",
    "smape = {}\n",
    "for cluster_id in range(len(clusters)):\n",
    "    smape[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        numerator = np.abs((imputed_unscaled_mean[cluster_id][key][val_masks_seq[cluster_id][key]] - X_val_full_unscaled_seq_tensor[cluster_id][val_masks_seq[cluster_id][key]]))\n",
    "        denominator = np.abs(imputed_unscaled_mean[cluster_id][key][val_masks_seq[cluster_id][key]]) + np.abs(X_val_full_unscaled_seq_tensor[cluster_id][val_masks_seq[cluster_id][key]]) + 1e-8\n",
    "        smape[cluster_id][key] = 100 * np.mean(2 * numerator / denominator)\n",
    "        print(f\"SMAPE Cluster {cluster_id} Rate {rate*100}%: {smape[cluster_id][key]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbdac0c",
   "metadata": {},
   "source": [
    "### BRITS Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe8d91f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pypots.imputation import BRITS\n",
    "from pypots.nn.modules.loss import MAE, MSE\n",
    "from pypots.optim.adam import Adam\n",
    "import torch\n",
    "\n",
    "def intialize_BRITS(n_steps, num_features, rnn_hidden_size):\n",
    "\n",
    "    # Basic configuration\n",
    "    model = BRITS(\n",
    "        n_steps=n_steps,\n",
    "        n_features=num_features,\n",
    "        rnn_hidden_size=rnn_hidden_size,               # Reasonable hidden size\n",
    "        batch_size=32,                    # Standard for most datasets\n",
    "        epochs=25,                       # Higher epochs for better convergence\n",
    "        patience=5,                      # Early stopping if no improvement\n",
    "        training_loss=MAE,                # MAE often performs well for imputation\n",
    "        validation_metric=MSE,           # Use MSE for validation comparison\n",
    "        optimizer=Adam,                   # Adam optimizer (default)\n",
    "        num_workers=0,                    # Adjust if using DataLoader with multiprocessing\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # Use GPU if available\n",
    "        saving_path=\"./brits_model\",     # Directory to save model checkpoints\n",
    "        model_saving_strategy=\"best\",    # Save best model only\n",
    "        verbose=True                      # Print training progress\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d4a0b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:36:03 [INFO]: Using the given device: cpu\n",
      "2025-06-26 22:36:03 [INFO]: Model files will be saved to ./brits_model\\20250626_T223603\n",
      "2025-06-26 22:36:03 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T223603\\tensorboard\n",
      "2025-06-26 22:36:03 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 22:36:03 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 22:36:03 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 0...\n",
      "Training model for missing rate 0.05 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:36:12 [INFO]: Epoch 001 - training loss (MAE): 1.8158, validation MSE: 1.8436\n",
      "2025-06-26 22:36:17 [INFO]: Epoch 002 - training loss (MAE): 1.7498, validation MSE: 1.5725\n",
      "2025-06-26 22:36:22 [INFO]: Epoch 003 - training loss (MAE): 1.5871, validation MSE: 1.3060\n",
      "2025-06-26 22:36:27 [INFO]: Epoch 004 - training loss (MAE): 1.4474, validation MSE: 1.0460\n",
      "2025-06-26 22:36:33 [INFO]: Epoch 005 - training loss (MAE): 1.3245, validation MSE: 0.8135\n",
      "2025-06-26 22:36:38 [INFO]: Epoch 006 - training loss (MAE): 1.1917, validation MSE: 0.6145\n",
      "2025-06-26 22:36:43 [INFO]: Epoch 007 - training loss (MAE): 1.0664, validation MSE: 0.4454\n",
      "2025-06-26 22:36:47 [INFO]: Epoch 008 - training loss (MAE): 0.9711, validation MSE: 0.3132\n",
      "2025-06-26 22:36:52 [INFO]: Epoch 009 - training loss (MAE): 0.8495, validation MSE: 0.2179\n",
      "2025-06-26 22:36:57 [INFO]: Epoch 010 - training loss (MAE): 0.7669, validation MSE: 0.1518\n",
      "2025-06-26 22:37:02 [INFO]: Epoch 011 - training loss (MAE): 0.7087, validation MSE: 0.1085\n",
      "2025-06-26 22:37:07 [INFO]: Epoch 012 - training loss (MAE): 0.6387, validation MSE: 0.0819\n",
      "2025-06-26 22:37:11 [INFO]: Epoch 013 - training loss (MAE): 0.5905, validation MSE: 0.0645\n",
      "2025-06-26 22:37:16 [INFO]: Epoch 014 - training loss (MAE): 0.5527, validation MSE: 0.0521\n",
      "2025-06-26 22:37:21 [INFO]: Epoch 015 - training loss (MAE): 0.5210, validation MSE: 0.0429\n",
      "2025-06-26 22:37:26 [INFO]: Epoch 016 - training loss (MAE): 0.5029, validation MSE: 0.0360\n",
      "2025-06-26 22:37:31 [INFO]: Epoch 017 - training loss (MAE): 0.4699, validation MSE: 0.0307\n",
      "2025-06-26 22:37:36 [INFO]: Epoch 018 - training loss (MAE): 0.4519, validation MSE: 0.0269\n",
      "2025-06-26 22:37:41 [INFO]: Epoch 019 - training loss (MAE): 0.4347, validation MSE: 0.0236\n",
      "2025-06-26 22:37:45 [INFO]: Epoch 020 - training loss (MAE): 0.4220, validation MSE: 0.0215\n",
      "2025-06-26 22:37:50 [INFO]: Epoch 021 - training loss (MAE): 0.4095, validation MSE: 0.0200\n",
      "2025-06-26 22:37:55 [INFO]: Epoch 022 - training loss (MAE): 0.4053, validation MSE: 0.0191\n",
      "2025-06-26 22:37:59 [INFO]: Epoch 023 - training loss (MAE): 0.3962, validation MSE: 0.0186\n",
      "2025-06-26 22:38:04 [INFO]: Epoch 024 - training loss (MAE): 0.3899, validation MSE: 0.0179\n",
      "2025-06-26 22:38:10 [INFO]: Epoch 025 - training loss (MAE): 0.3853, validation MSE: 0.0174\n",
      "2025-06-26 22:38:10 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 22:38:10 [INFO]: Saved the model to ./brits_model\\20250626_T223603\\BRITS.pypots\n",
      "2025-06-26 22:38:10 [INFO]: Using the given device: cpu\n",
      "2025-06-26 22:38:10 [INFO]: Model files will be saved to ./brits_model\\20250626_T223810\n",
      "2025-06-26 22:38:10 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T223810\\tensorboard\n",
      "2025-06-26 22:38:10 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 22:38:10 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 22:38:10 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.4 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:38:18 [INFO]: Epoch 001 - training loss (MAE): 1.9258, validation MSE: 0.9209\n",
      "2025-06-26 22:38:23 [INFO]: Epoch 002 - training loss (MAE): 1.8178, validation MSE: 0.8205\n",
      "2025-06-26 22:38:28 [INFO]: Epoch 003 - training loss (MAE): 1.7085, validation MSE: 0.7131\n",
      "2025-06-26 22:38:34 [INFO]: Epoch 004 - training loss (MAE): 1.5854, validation MSE: 0.5986\n",
      "2025-06-26 22:38:39 [INFO]: Epoch 005 - training loss (MAE): 1.4702, validation MSE: 0.4784\n",
      "2025-06-26 22:38:45 [INFO]: Epoch 006 - training loss (MAE): 1.3205, validation MSE: 0.3686\n",
      "2025-06-26 22:38:50 [INFO]: Epoch 007 - training loss (MAE): 1.1883, validation MSE: 0.2708\n",
      "2025-06-26 22:38:55 [INFO]: Epoch 008 - training loss (MAE): 1.0474, validation MSE: 0.1895\n",
      "2025-06-26 22:39:01 [INFO]: Epoch 009 - training loss (MAE): 0.9181, validation MSE: 0.1278\n",
      "2025-06-26 22:39:06 [INFO]: Epoch 010 - training loss (MAE): 0.8063, validation MSE: 0.0887\n",
      "2025-06-26 22:39:11 [INFO]: Epoch 011 - training loss (MAE): 0.7214, validation MSE: 0.0676\n",
      "2025-06-26 22:39:17 [INFO]: Epoch 012 - training loss (MAE): 0.6501, validation MSE: 0.0525\n",
      "2025-06-26 22:39:22 [INFO]: Epoch 013 - training loss (MAE): 0.5740, validation MSE: 0.0430\n",
      "2025-06-26 22:39:26 [INFO]: Epoch 014 - training loss (MAE): 0.5289, validation MSE: 0.0359\n",
      "2025-06-26 22:39:31 [INFO]: Epoch 015 - training loss (MAE): 0.4890, validation MSE: 0.0323\n",
      "2025-06-26 22:39:36 [INFO]: Epoch 016 - training loss (MAE): 0.4739, validation MSE: 0.0301\n",
      "2025-06-26 22:39:41 [INFO]: Epoch 017 - training loss (MAE): 0.4428, validation MSE: 0.0290\n",
      "2025-06-26 22:39:45 [INFO]: Epoch 018 - training loss (MAE): 0.4300, validation MSE: 0.0267\n",
      "2025-06-26 22:39:50 [INFO]: Epoch 019 - training loss (MAE): 0.4066, validation MSE: 0.0253\n",
      "2025-06-26 22:39:55 [INFO]: Epoch 020 - training loss (MAE): 0.4010, validation MSE: 0.0241\n",
      "2025-06-26 22:40:01 [INFO]: Epoch 021 - training loss (MAE): 0.4055, validation MSE: 0.0230\n",
      "2025-06-26 22:40:06 [INFO]: Epoch 022 - training loss (MAE): 0.3889, validation MSE: 0.0234\n",
      "2025-06-26 22:40:12 [INFO]: Epoch 023 - training loss (MAE): 0.3822, validation MSE: 0.0226\n",
      "2025-06-26 22:40:17 [INFO]: Epoch 024 - training loss (MAE): 0.3873, validation MSE: 0.0224\n",
      "2025-06-26 22:40:22 [INFO]: Epoch 025 - training loss (MAE): 0.3807, validation MSE: 0.0223\n",
      "2025-06-26 22:40:22 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 22:40:22 [INFO]: Saved the model to ./brits_model\\20250626_T223810\\BRITS.pypots\n",
      "2025-06-26 22:40:22 [INFO]: Using the given device: cpu\n",
      "2025-06-26 22:40:22 [INFO]: Model files will be saved to ./brits_model\\20250626_T224022\n",
      "2025-06-26 22:40:22 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T224022\\tensorboard\n",
      "2025-06-26 22:40:22 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 22:40:22 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 22:40:22 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:40:31 [INFO]: Epoch 001 - training loss (MAE): 1.7740, validation MSE: 0.9751\n",
      "2025-06-26 22:40:36 [INFO]: Epoch 002 - training loss (MAE): 1.6884, validation MSE: 0.8822\n",
      "2025-06-26 22:40:42 [INFO]: Epoch 003 - training loss (MAE): 1.6350, validation MSE: 0.7857\n",
      "2025-06-26 22:40:47 [INFO]: Epoch 004 - training loss (MAE): 1.5039, validation MSE: 0.6821\n",
      "2025-06-26 22:40:52 [INFO]: Epoch 005 - training loss (MAE): 1.3886, validation MSE: 0.5754\n",
      "2025-06-26 22:40:58 [INFO]: Epoch 006 - training loss (MAE): 1.2777, validation MSE: 0.4757\n",
      "2025-06-26 22:41:03 [INFO]: Epoch 007 - training loss (MAE): 1.1563, validation MSE: 0.3886\n",
      "2025-06-26 22:41:09 [INFO]: Epoch 008 - training loss (MAE): 1.0520, validation MSE: 0.3130\n",
      "2025-06-26 22:41:14 [INFO]: Epoch 009 - training loss (MAE): 0.9350, validation MSE: 0.2495\n",
      "2025-06-26 22:41:19 [INFO]: Epoch 010 - training loss (MAE): 0.8252, validation MSE: 0.2008\n",
      "2025-06-26 22:41:25 [INFO]: Epoch 011 - training loss (MAE): 0.7254, validation MSE: 0.1655\n",
      "2025-06-26 22:41:30 [INFO]: Epoch 012 - training loss (MAE): 0.6643, validation MSE: 0.1419\n",
      "2025-06-26 22:41:35 [INFO]: Epoch 013 - training loss (MAE): 0.6006, validation MSE: 0.1268\n",
      "2025-06-26 22:41:41 [INFO]: Epoch 014 - training loss (MAE): 0.5315, validation MSE: 0.1156\n",
      "2025-06-26 22:41:46 [INFO]: Epoch 015 - training loss (MAE): 0.5023, validation MSE: 0.1065\n",
      "2025-06-26 22:41:52 [INFO]: Epoch 016 - training loss (MAE): 0.4662, validation MSE: 0.1024\n",
      "2025-06-26 22:41:57 [INFO]: Epoch 017 - training loss (MAE): 0.4242, validation MSE: 0.0987\n",
      "2025-06-26 22:42:03 [INFO]: Epoch 018 - training loss (MAE): 0.4064, validation MSE: 0.0959\n",
      "2025-06-26 22:42:08 [INFO]: Epoch 019 - training loss (MAE): 0.3867, validation MSE: 0.0942\n",
      "2025-06-26 22:42:13 [INFO]: Epoch 020 - training loss (MAE): 0.3726, validation MSE: 0.0927\n",
      "2025-06-26 22:42:19 [INFO]: Epoch 021 - training loss (MAE): 0.3637, validation MSE: 0.0917\n",
      "2025-06-26 22:42:24 [INFO]: Epoch 022 - training loss (MAE): 0.3613, validation MSE: 0.0909\n",
      "2025-06-26 22:42:29 [INFO]: Epoch 023 - training loss (MAE): 0.3550, validation MSE: 0.0906\n",
      "2025-06-26 22:42:34 [INFO]: Epoch 024 - training loss (MAE): 0.3555, validation MSE: 0.0903\n",
      "2025-06-26 22:42:40 [INFO]: Epoch 025 - training loss (MAE): 0.3446, validation MSE: 0.0903\n",
      "2025-06-26 22:42:40 [INFO]: Finished training. The best model is from epoch#24.\n",
      "2025-06-26 22:42:40 [INFO]: Saved the model to ./brits_model\\20250626_T224022\\BRITS.pypots\n",
      "2025-06-26 22:42:40 [INFO]: Using the given device: cpu\n",
      "2025-06-26 22:42:40 [INFO]: Model files will be saved to ./brits_model\\20250626_T224240\n",
      "2025-06-26 22:42:40 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T224240\\tensorboard\n",
      "2025-06-26 22:42:40 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 22:42:40 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 22:42:40 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.99 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:42:48 [INFO]: Epoch 001 - training loss (MAE): 1.8029, validation MSE: 0.9341\n",
      "2025-06-26 22:42:53 [INFO]: Epoch 002 - training loss (MAE): 1.7065, validation MSE: 0.9159\n",
      "2025-06-26 22:42:58 [INFO]: Epoch 003 - training loss (MAE): 1.6493, validation MSE: 0.8994\n",
      "2025-06-26 22:43:04 [INFO]: Epoch 004 - training loss (MAE): 1.5444, validation MSE: 0.8831\n",
      "2025-06-26 22:43:09 [INFO]: Epoch 005 - training loss (MAE): 1.4194, validation MSE: 0.8662\n",
      "2025-06-26 22:43:15 [INFO]: Epoch 006 - training loss (MAE): 1.2920, validation MSE: 0.8432\n",
      "2025-06-26 22:43:20 [INFO]: Epoch 007 - training loss (MAE): 1.1514, validation MSE: 0.8108\n",
      "2025-06-26 22:43:25 [INFO]: Epoch 008 - training loss (MAE): 1.0015, validation MSE: 0.7793\n",
      "2025-06-26 22:43:31 [INFO]: Epoch 009 - training loss (MAE): 0.8541, validation MSE: 0.7574\n",
      "2025-06-26 22:43:36 [INFO]: Epoch 010 - training loss (MAE): 0.7149, validation MSE: 0.7354\n",
      "2025-06-26 22:43:41 [INFO]: Epoch 011 - training loss (MAE): 0.6103, validation MSE: 0.7023\n",
      "2025-06-26 22:43:47 [INFO]: Epoch 012 - training loss (MAE): 0.5407, validation MSE: 0.6711\n",
      "2025-06-26 22:43:52 [INFO]: Epoch 013 - training loss (MAE): 0.4974, validation MSE: 0.6403\n",
      "2025-06-26 22:43:58 [INFO]: Epoch 014 - training loss (MAE): 0.4662, validation MSE: 0.6098\n",
      "2025-06-26 22:44:03 [INFO]: Epoch 015 - training loss (MAE): 0.4316, validation MSE: 0.5729\n",
      "2025-06-26 22:44:08 [INFO]: Epoch 016 - training loss (MAE): 0.4212, validation MSE: 0.5399\n",
      "2025-06-26 22:44:14 [INFO]: Epoch 017 - training loss (MAE): 0.4060, validation MSE: 0.5100\n",
      "2025-06-26 22:44:19 [INFO]: Epoch 018 - training loss (MAE): 0.3995, validation MSE: 0.4882\n",
      "2025-06-26 22:44:25 [INFO]: Epoch 019 - training loss (MAE): 0.3885, validation MSE: 0.4679\n",
      "2025-06-26 22:44:30 [INFO]: Epoch 020 - training loss (MAE): 0.3864, validation MSE: 0.4590\n",
      "2025-06-26 22:44:35 [INFO]: Epoch 021 - training loss (MAE): 0.3770, validation MSE: 0.4530\n",
      "2025-06-26 22:44:40 [INFO]: Epoch 022 - training loss (MAE): 0.3778, validation MSE: 0.4546\n",
      "2025-06-26 22:44:45 [INFO]: Epoch 023 - training loss (MAE): 0.3685, validation MSE: 0.4474\n",
      "2025-06-26 22:44:51 [INFO]: Epoch 024 - training loss (MAE): 0.3667, validation MSE: 0.4431\n",
      "2025-06-26 22:44:56 [INFO]: Epoch 025 - training loss (MAE): 0.3621, validation MSE: 0.4387\n",
      "2025-06-26 22:44:56 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 22:44:56 [INFO]: Saved the model to ./brits_model\\20250626_T224240\\BRITS.pypots\n",
      "2025-06-26 22:44:56 [INFO]: Using the given device: cpu\n",
      "2025-06-26 22:44:56 [INFO]: Model files will be saved to ./brits_model\\20250626_T224456\n",
      "2025-06-26 22:44:56 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T224456\\tensorboard\n",
      "2025-06-26 22:44:56 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 22:44:56 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 22:44:56 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 1...\n",
      "Training model for missing rate 0.05 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:45:04 [INFO]: Epoch 001 - training loss (MAE): 1.7133, validation MSE: 0.8733\n",
      "2025-06-26 22:45:10 [INFO]: Epoch 002 - training loss (MAE): 1.5899, validation MSE: 0.7483\n",
      "2025-06-26 22:45:15 [INFO]: Epoch 003 - training loss (MAE): 1.4479, validation MSE: 0.6181\n",
      "2025-06-26 22:45:21 [INFO]: Epoch 004 - training loss (MAE): 1.3200, validation MSE: 0.4855\n",
      "2025-06-26 22:45:26 [INFO]: Epoch 005 - training loss (MAE): 1.1555, validation MSE: 0.3719\n",
      "2025-06-26 22:45:32 [INFO]: Epoch 006 - training loss (MAE): 1.0059, validation MSE: 0.2754\n",
      "2025-06-26 22:45:38 [INFO]: Epoch 007 - training loss (MAE): 0.8617, validation MSE: 0.1936\n",
      "2025-06-26 22:45:43 [INFO]: Epoch 008 - training loss (MAE): 0.7313, validation MSE: 0.1301\n",
      "2025-06-26 22:45:48 [INFO]: Epoch 009 - training loss (MAE): 0.6146, validation MSE: 0.0828\n",
      "2025-06-26 22:45:53 [INFO]: Epoch 010 - training loss (MAE): 0.5217, validation MSE: 0.0495\n",
      "2025-06-26 22:45:58 [INFO]: Epoch 011 - training loss (MAE): 0.4495, validation MSE: 0.0310\n",
      "2025-06-26 22:46:04 [INFO]: Epoch 012 - training loss (MAE): 0.3946, validation MSE: 0.0219\n",
      "2025-06-26 22:46:08 [INFO]: Epoch 013 - training loss (MAE): 0.3435, validation MSE: 0.0168\n",
      "2025-06-26 22:46:13 [INFO]: Epoch 014 - training loss (MAE): 0.3008, validation MSE: 0.0120\n",
      "2025-06-26 22:46:19 [INFO]: Epoch 015 - training loss (MAE): 0.2727, validation MSE: 0.0081\n",
      "2025-06-26 22:46:23 [INFO]: Epoch 016 - training loss (MAE): 0.2377, validation MSE: 0.0062\n",
      "2025-06-26 22:46:29 [INFO]: Epoch 017 - training loss (MAE): 0.2199, validation MSE: 0.0049\n",
      "2025-06-26 22:46:34 [INFO]: Epoch 018 - training loss (MAE): 0.1934, validation MSE: 0.0040\n",
      "2025-06-26 22:46:39 [INFO]: Epoch 019 - training loss (MAE): 0.1768, validation MSE: 0.0030\n",
      "2025-06-26 22:46:44 [INFO]: Epoch 020 - training loss (MAE): 0.1643, validation MSE: 0.0026\n",
      "2025-06-26 22:46:50 [INFO]: Epoch 021 - training loss (MAE): 0.1530, validation MSE: 0.0025\n",
      "2025-06-26 22:46:56 [INFO]: Epoch 022 - training loss (MAE): 0.1438, validation MSE: 0.0023\n",
      "2025-06-26 22:47:01 [INFO]: Epoch 023 - training loss (MAE): 0.1367, validation MSE: 0.0022\n",
      "2025-06-26 22:47:07 [INFO]: Epoch 024 - training loss (MAE): 0.1306, validation MSE: 0.0023\n",
      "2025-06-26 22:47:12 [INFO]: Epoch 025 - training loss (MAE): 0.1265, validation MSE: 0.0020\n",
      "2025-06-26 22:47:12 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 22:47:12 [INFO]: Saved the model to ./brits_model\\20250626_T224456\\BRITS.pypots\n",
      "2025-06-26 22:47:12 [INFO]: Using the given device: cpu\n",
      "2025-06-26 22:47:12 [INFO]: Model files will be saved to ./brits_model\\20250626_T224712\n",
      "2025-06-26 22:47:12 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T224712\\tensorboard\n",
      "2025-06-26 22:47:12 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 22:47:12 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 22:47:12 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.4 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:47:20 [INFO]: Epoch 001 - training loss (MAE): 1.6897, validation MSE: 0.6197\n",
      "2025-06-26 22:47:25 [INFO]: Epoch 002 - training loss (MAE): 1.5825, validation MSE: 0.5132\n",
      "2025-06-26 22:47:29 [INFO]: Epoch 003 - training loss (MAE): 1.4528, validation MSE: 0.4028\n",
      "2025-06-26 22:47:35 [INFO]: Epoch 004 - training loss (MAE): 1.3292, validation MSE: 0.2998\n",
      "2025-06-26 22:47:40 [INFO]: Epoch 005 - training loss (MAE): 1.1852, validation MSE: 0.2143\n",
      "2025-06-26 22:47:46 [INFO]: Epoch 006 - training loss (MAE): 1.0523, validation MSE: 0.1492\n",
      "2025-06-26 22:47:51 [INFO]: Epoch 007 - training loss (MAE): 0.9510, validation MSE: 0.1015\n",
      "2025-06-26 22:47:56 [INFO]: Epoch 008 - training loss (MAE): 0.8256, validation MSE: 0.0682\n",
      "2025-06-26 22:48:02 [INFO]: Epoch 009 - training loss (MAE): 0.7020, validation MSE: 0.0466\n",
      "2025-06-26 22:48:07 [INFO]: Epoch 010 - training loss (MAE): 0.6173, validation MSE: 0.0326\n",
      "2025-06-26 22:48:12 [INFO]: Epoch 011 - training loss (MAE): 0.5231, validation MSE: 0.0248\n",
      "2025-06-26 22:48:18 [INFO]: Epoch 012 - training loss (MAE): 0.4547, validation MSE: 0.0187\n",
      "2025-06-26 22:48:23 [INFO]: Epoch 013 - training loss (MAE): 0.4083, validation MSE: 0.0141\n",
      "2025-06-26 22:48:29 [INFO]: Epoch 014 - training loss (MAE): 0.3480, validation MSE: 0.0110\n",
      "2025-06-26 22:48:34 [INFO]: Epoch 015 - training loss (MAE): 0.3038, validation MSE: 0.0085\n",
      "2025-06-26 22:48:40 [INFO]: Epoch 016 - training loss (MAE): 0.2647, validation MSE: 0.0069\n",
      "2025-06-26 22:48:45 [INFO]: Epoch 017 - training loss (MAE): 0.2371, validation MSE: 0.0061\n",
      "2025-06-26 22:48:49 [INFO]: Epoch 018 - training loss (MAE): 0.2122, validation MSE: 0.0056\n",
      "2025-06-26 22:48:54 [INFO]: Epoch 019 - training loss (MAE): 0.1988, validation MSE: 0.0055\n",
      "2025-06-26 22:48:59 [INFO]: Epoch 020 - training loss (MAE): 0.1768, validation MSE: 0.0052\n",
      "2025-06-26 22:49:03 [INFO]: Epoch 021 - training loss (MAE): 0.1670, validation MSE: 0.0054\n",
      "2025-06-26 22:49:08 [INFO]: Epoch 022 - training loss (MAE): 0.1529, validation MSE: 0.0050\n",
      "2025-06-26 22:49:13 [INFO]: Epoch 023 - training loss (MAE): 0.1456, validation MSE: 0.0050\n",
      "2025-06-26 22:49:18 [INFO]: Epoch 024 - training loss (MAE): 0.1383, validation MSE: 0.0043\n",
      "2025-06-26 22:49:24 [INFO]: Epoch 025 - training loss (MAE): 0.1335, validation MSE: 0.0042\n",
      "2025-06-26 22:49:24 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 22:49:24 [INFO]: Saved the model to ./brits_model\\20250626_T224712\\BRITS.pypots\n",
      "2025-06-26 22:49:24 [INFO]: Using the given device: cpu\n",
      "2025-06-26 22:49:24 [INFO]: Model files will be saved to ./brits_model\\20250626_T224924\n",
      "2025-06-26 22:49:24 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T224924\\tensorboard\n",
      "2025-06-26 22:49:24 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 22:49:24 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 22:49:24 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:49:36 [INFO]: Epoch 001 - training loss (MAE): 1.6009, validation MSE: 0.9365\n",
      "2025-06-26 22:49:41 [INFO]: Epoch 002 - training loss (MAE): 1.4759, validation MSE: 0.8344\n",
      "2025-06-26 22:49:46 [INFO]: Epoch 003 - training loss (MAE): 1.3807, validation MSE: 0.7154\n",
      "2025-06-26 22:49:51 [INFO]: Epoch 004 - training loss (MAE): 1.2512, validation MSE: 0.5903\n",
      "2025-06-26 22:49:56 [INFO]: Epoch 005 - training loss (MAE): 1.1628, validation MSE: 0.4708\n",
      "2025-06-26 22:50:01 [INFO]: Epoch 006 - training loss (MAE): 1.0002, validation MSE: 0.3517\n",
      "2025-06-26 22:50:06 [INFO]: Epoch 007 - training loss (MAE): 0.9041, validation MSE: 0.2441\n",
      "2025-06-26 22:50:10 [INFO]: Epoch 008 - training loss (MAE): 0.7644, validation MSE: 0.1632\n",
      "2025-06-26 22:50:15 [INFO]: Epoch 009 - training loss (MAE): 0.6791, validation MSE: 0.1088\n",
      "2025-06-26 22:50:20 [INFO]: Epoch 010 - training loss (MAE): 0.5641, validation MSE: 0.0832\n",
      "2025-06-26 22:50:25 [INFO]: Epoch 011 - training loss (MAE): 0.4811, validation MSE: 0.0678\n",
      "2025-06-26 22:50:30 [INFO]: Epoch 012 - training loss (MAE): 0.4162, validation MSE: 0.0590\n",
      "2025-06-26 22:50:35 [INFO]: Epoch 013 - training loss (MAE): 0.3632, validation MSE: 0.0565\n",
      "2025-06-26 22:50:40 [INFO]: Epoch 014 - training loss (MAE): 0.3139, validation MSE: 0.0524\n",
      "2025-06-26 22:50:45 [INFO]: Epoch 015 - training loss (MAE): 0.2751, validation MSE: 0.0416\n",
      "2025-06-26 22:50:49 [INFO]: Epoch 016 - training loss (MAE): 0.2504, validation MSE: 0.0377\n",
      "2025-06-26 22:50:54 [INFO]: Epoch 017 - training loss (MAE): 0.2252, validation MSE: 0.0351\n",
      "2025-06-26 22:50:59 [INFO]: Epoch 018 - training loss (MAE): 0.2066, validation MSE: 0.0345\n",
      "2025-06-26 22:51:04 [INFO]: Epoch 019 - training loss (MAE): 0.1870, validation MSE: 0.0302\n",
      "2025-06-26 22:51:10 [INFO]: Epoch 020 - training loss (MAE): 0.1750, validation MSE: 0.0306\n",
      "2025-06-26 22:51:17 [INFO]: Epoch 021 - training loss (MAE): 0.1641, validation MSE: 0.0342\n",
      "2025-06-26 22:51:26 [INFO]: Epoch 022 - training loss (MAE): 0.1526, validation MSE: 0.0322\n",
      "2025-06-26 22:51:33 [INFO]: Epoch 023 - training loss (MAE): 0.1455, validation MSE: 0.0314\n",
      "2025-06-26 22:51:40 [INFO]: Epoch 024 - training loss (MAE): 0.1392, validation MSE: 0.0316\n",
      "2025-06-26 22:51:40 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-06-26 22:51:40 [INFO]: Finished training. The best model is from epoch#19.\n",
      "2025-06-26 22:51:40 [INFO]: Saved the model to ./brits_model\\20250626_T224924\\BRITS.pypots\n",
      "2025-06-26 22:51:40 [INFO]: Using the given device: cpu\n",
      "2025-06-26 22:51:40 [INFO]: Model files will be saved to ./brits_model\\20250626_T225140\n",
      "2025-06-26 22:51:40 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T225140\\tensorboard\n",
      "2025-06-26 22:51:40 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 22:51:40 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 22:51:40 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.99 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:51:48 [INFO]: Epoch 001 - training loss (MAE): 1.8617, validation MSE: 1.1129\n",
      "2025-06-26 22:51:53 [INFO]: Epoch 002 - training loss (MAE): 1.7777, validation MSE: 1.0990\n",
      "2025-06-26 22:51:59 [INFO]: Epoch 003 - training loss (MAE): 1.7086, validation MSE: 1.0853\n",
      "2025-06-26 22:52:05 [INFO]: Epoch 004 - training loss (MAE): 1.5786, validation MSE: 1.0667\n",
      "2025-06-26 22:52:10 [INFO]: Epoch 005 - training loss (MAE): 1.4761, validation MSE: 1.0287\n",
      "2025-06-26 22:52:15 [INFO]: Epoch 006 - training loss (MAE): 1.3314, validation MSE: 0.9739\n",
      "2025-06-26 22:52:20 [INFO]: Epoch 007 - training loss (MAE): 1.1608, validation MSE: 0.9200\n",
      "2025-06-26 22:52:25 [INFO]: Epoch 008 - training loss (MAE): 1.0126, validation MSE: 0.8667\n",
      "2025-06-26 22:52:30 [INFO]: Epoch 009 - training loss (MAE): 0.8185, validation MSE: 0.8069\n",
      "2025-06-26 22:52:36 [INFO]: Epoch 010 - training loss (MAE): 0.6355, validation MSE: 0.7405\n",
      "2025-06-26 22:52:41 [INFO]: Epoch 011 - training loss (MAE): 0.4983, validation MSE: 0.6924\n",
      "2025-06-26 22:52:47 [INFO]: Epoch 012 - training loss (MAE): 0.3996, validation MSE: 0.6787\n",
      "2025-06-26 22:52:53 [INFO]: Epoch 013 - training loss (MAE): 0.3362, validation MSE: 0.6674\n",
      "2025-06-26 22:52:58 [INFO]: Epoch 014 - training loss (MAE): 0.2738, validation MSE: 0.6398\n",
      "2025-06-26 22:53:04 [INFO]: Epoch 015 - training loss (MAE): 0.2372, validation MSE: 0.5939\n",
      "2025-06-26 22:53:09 [INFO]: Epoch 016 - training loss (MAE): 0.2111, validation MSE: 0.5551\n",
      "2025-06-26 22:53:14 [INFO]: Epoch 017 - training loss (MAE): 0.1997, validation MSE: 0.5229\n",
      "2025-06-26 22:53:22 [INFO]: Epoch 018 - training loss (MAE): 0.1939, validation MSE: 0.4935\n",
      "2025-06-26 22:53:29 [INFO]: Epoch 019 - training loss (MAE): 0.1882, validation MSE: 0.4704\n",
      "2025-06-26 22:53:37 [INFO]: Epoch 020 - training loss (MAE): 0.1806, validation MSE: 0.4498\n",
      "2025-06-26 22:53:45 [INFO]: Epoch 021 - training loss (MAE): 0.1782, validation MSE: 0.4282\n",
      "2025-06-26 22:53:52 [INFO]: Epoch 022 - training loss (MAE): 0.1760, validation MSE: 0.4107\n",
      "2025-06-26 22:54:00 [INFO]: Epoch 023 - training loss (MAE): 0.1772, validation MSE: 0.3940\n",
      "2025-06-26 22:54:08 [INFO]: Epoch 024 - training loss (MAE): 0.1717, validation MSE: 0.3797\n",
      "2025-06-26 22:54:16 [INFO]: Epoch 025 - training loss (MAE): 0.1660, validation MSE: 0.3688\n",
      "2025-06-26 22:54:16 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 22:54:16 [INFO]: Saved the model to ./brits_model\\20250626_T225140\\BRITS.pypots\n",
      "2025-06-26 22:54:16 [INFO]: Using the given device: cpu\n",
      "2025-06-26 22:54:16 [INFO]: Model files will be saved to ./brits_model\\20250626_T225416\n",
      "2025-06-26 22:54:16 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T225416\\tensorboard\n",
      "2025-06-26 22:54:16 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 22:54:16 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 22:54:16 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 2...\n",
      "Training model for missing rate 0.05 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:54:25 [INFO]: Epoch 001 - training loss (MAE): 1.6567, validation MSE: 0.9085\n",
      "2025-06-26 22:54:29 [INFO]: Epoch 002 - training loss (MAE): 1.5923, validation MSE: 0.8392\n",
      "2025-06-26 22:54:33 [INFO]: Epoch 003 - training loss (MAE): 1.4906, validation MSE: 0.7595\n",
      "2025-06-26 22:54:38 [INFO]: Epoch 004 - training loss (MAE): 1.4111, validation MSE: 0.6672\n",
      "2025-06-26 22:54:42 [INFO]: Epoch 005 - training loss (MAE): 1.3223, validation MSE: 0.5712\n",
      "2025-06-26 22:54:46 [INFO]: Epoch 006 - training loss (MAE): 1.2281, validation MSE: 0.4793\n",
      "2025-06-26 22:54:50 [INFO]: Epoch 007 - training loss (MAE): 1.1392, validation MSE: 0.3925\n",
      "2025-06-26 22:54:55 [INFO]: Epoch 008 - training loss (MAE): 1.0533, validation MSE: 0.3107\n",
      "2025-06-26 22:54:59 [INFO]: Epoch 009 - training loss (MAE): 0.9568, validation MSE: 0.2379\n",
      "2025-06-26 22:55:03 [INFO]: Epoch 010 - training loss (MAE): 0.8572, validation MSE: 0.1790\n",
      "2025-06-26 22:55:07 [INFO]: Epoch 011 - training loss (MAE): 0.7739, validation MSE: 0.1351\n",
      "2025-06-26 22:55:12 [INFO]: Epoch 012 - training loss (MAE): 0.7032, validation MSE: 0.1045\n",
      "2025-06-26 22:55:16 [INFO]: Epoch 013 - training loss (MAE): 0.6538, validation MSE: 0.0836\n",
      "2025-06-26 22:55:20 [INFO]: Epoch 014 - training loss (MAE): 0.6067, validation MSE: 0.0699\n",
      "2025-06-26 22:55:24 [INFO]: Epoch 015 - training loss (MAE): 0.5648, validation MSE: 0.0574\n",
      "2025-06-26 22:55:28 [INFO]: Epoch 016 - training loss (MAE): 0.5348, validation MSE: 0.0510\n",
      "2025-06-26 22:55:33 [INFO]: Epoch 017 - training loss (MAE): 0.5083, validation MSE: 0.0481\n",
      "2025-06-26 22:55:37 [INFO]: Epoch 018 - training loss (MAE): 0.4831, validation MSE: 0.0401\n",
      "2025-06-26 22:55:41 [INFO]: Epoch 019 - training loss (MAE): 0.4622, validation MSE: 0.0385\n",
      "2025-06-26 22:55:45 [INFO]: Epoch 020 - training loss (MAE): 0.4435, validation MSE: 0.0351\n",
      "2025-06-26 22:55:49 [INFO]: Epoch 021 - training loss (MAE): 0.4251, validation MSE: 0.0319\n",
      "2025-06-26 22:55:53 [INFO]: Epoch 022 - training loss (MAE): 0.4096, validation MSE: 0.0300\n",
      "2025-06-26 22:55:58 [INFO]: Epoch 023 - training loss (MAE): 0.3915, validation MSE: 0.0274\n",
      "2025-06-26 22:56:02 [INFO]: Epoch 024 - training loss (MAE): 0.3781, validation MSE: 0.0267\n",
      "2025-06-26 22:56:07 [INFO]: Epoch 025 - training loss (MAE): 0.3638, validation MSE: 0.0252\n",
      "2025-06-26 22:56:07 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 22:56:07 [INFO]: Saved the model to ./brits_model\\20250626_T225416\\BRITS.pypots\n",
      "2025-06-26 22:56:07 [INFO]: Using the given device: cpu\n",
      "2025-06-26 22:56:07 [INFO]: Model files will be saved to ./brits_model\\20250626_T225607\n",
      "2025-06-26 22:56:07 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T225607\\tensorboard\n",
      "2025-06-26 22:56:07 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 22:56:07 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 22:56:07 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.4 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:56:15 [INFO]: Epoch 001 - training loss (MAE): 1.7524, validation MSE: 1.3233\n",
      "2025-06-26 22:56:19 [INFO]: Epoch 002 - training loss (MAE): 1.6771, validation MSE: 1.2626\n",
      "2025-06-26 22:56:24 [INFO]: Epoch 003 - training loss (MAE): 1.6204, validation MSE: 1.1905\n",
      "2025-06-26 22:56:29 [INFO]: Epoch 004 - training loss (MAE): 1.5452, validation MSE: 1.1074\n",
      "2025-06-26 22:56:34 [INFO]: Epoch 005 - training loss (MAE): 1.4947, validation MSE: 1.0103\n",
      "2025-06-26 22:56:38 [INFO]: Epoch 006 - training loss (MAE): 1.3869, validation MSE: 0.8978\n",
      "2025-06-26 22:56:43 [INFO]: Epoch 007 - training loss (MAE): 1.3039, validation MSE: 0.7695\n",
      "2025-06-26 22:56:48 [INFO]: Epoch 008 - training loss (MAE): 1.1642, validation MSE: 0.6377\n",
      "2025-06-26 22:56:52 [INFO]: Epoch 009 - training loss (MAE): 1.0581, validation MSE: 0.5141\n",
      "2025-06-26 22:56:57 [INFO]: Epoch 010 - training loss (MAE): 0.9574, validation MSE: 0.4118\n",
      "2025-06-26 22:57:01 [INFO]: Epoch 011 - training loss (MAE): 0.8516, validation MSE: 0.3319\n",
      "2025-06-26 22:57:06 [INFO]: Epoch 012 - training loss (MAE): 0.7625, validation MSE: 0.2751\n",
      "2025-06-26 22:57:11 [INFO]: Epoch 013 - training loss (MAE): 0.7147, validation MSE: 0.2229\n",
      "2025-06-26 22:57:17 [INFO]: Epoch 014 - training loss (MAE): 0.6458, validation MSE: 0.1753\n",
      "2025-06-26 22:57:22 [INFO]: Epoch 015 - training loss (MAE): 0.6018, validation MSE: 0.1344\n",
      "2025-06-26 22:57:27 [INFO]: Epoch 016 - training loss (MAE): 0.5668, validation MSE: 0.1283\n",
      "2025-06-26 22:57:31 [INFO]: Epoch 017 - training loss (MAE): 0.5336, validation MSE: 0.0992\n",
      "2025-06-26 22:57:36 [INFO]: Epoch 018 - training loss (MAE): 0.5191, validation MSE: 0.0908\n",
      "2025-06-26 22:57:40 [INFO]: Epoch 019 - training loss (MAE): 0.4823, validation MSE: 0.0769\n",
      "2025-06-26 22:57:44 [INFO]: Epoch 020 - training loss (MAE): 0.4540, validation MSE: 0.0706\n",
      "2025-06-26 22:57:48 [INFO]: Epoch 021 - training loss (MAE): 0.4391, validation MSE: 0.0619\n",
      "2025-06-26 22:57:53 [INFO]: Epoch 022 - training loss (MAE): 0.4309, validation MSE: 0.0586\n",
      "2025-06-26 22:57:57 [INFO]: Epoch 023 - training loss (MAE): 0.4032, validation MSE: 0.0541\n",
      "2025-06-26 22:58:02 [INFO]: Epoch 024 - training loss (MAE): 0.3918, validation MSE: 0.0521\n",
      "2025-06-26 22:58:06 [INFO]: Epoch 025 - training loss (MAE): 0.3767, validation MSE: 0.0465\n",
      "2025-06-26 22:58:06 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 22:58:06 [INFO]: Saved the model to ./brits_model\\20250626_T225607\\BRITS.pypots\n",
      "2025-06-26 22:58:06 [INFO]: Using the given device: cpu\n",
      "2025-06-26 22:58:06 [INFO]: Model files will be saved to ./brits_model\\20250626_T225806\n",
      "2025-06-26 22:58:06 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T225806\\tensorboard\n",
      "2025-06-26 22:58:06 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 22:58:06 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 22:58:06 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 22:58:13 [INFO]: Epoch 001 - training loss (MAE): 1.7891, validation MSE: 1.1611\n",
      "2025-06-26 22:58:18 [INFO]: Epoch 002 - training loss (MAE): 1.7206, validation MSE: 1.1305\n",
      "2025-06-26 22:58:23 [INFO]: Epoch 003 - training loss (MAE): 1.6760, validation MSE: 1.0961\n",
      "2025-06-26 22:58:27 [INFO]: Epoch 004 - training loss (MAE): 1.6334, validation MSE: 1.0575\n",
      "2025-06-26 22:58:32 [INFO]: Epoch 005 - training loss (MAE): 1.5133, validation MSE: 1.0078\n",
      "2025-06-26 22:58:37 [INFO]: Epoch 006 - training loss (MAE): 1.4519, validation MSE: 0.9366\n",
      "2025-06-26 22:58:41 [INFO]: Epoch 007 - training loss (MAE): 1.3966, validation MSE: 0.8639\n",
      "2025-06-26 22:58:46 [INFO]: Epoch 008 - training loss (MAE): 1.2855, validation MSE: 0.7957\n",
      "2025-06-26 22:58:51 [INFO]: Epoch 009 - training loss (MAE): 1.2078, validation MSE: 0.7196\n",
      "2025-06-26 22:58:56 [INFO]: Epoch 010 - training loss (MAE): 1.1388, validation MSE: 0.6541\n",
      "2025-06-26 22:59:00 [INFO]: Epoch 011 - training loss (MAE): 1.0808, validation MSE: 0.5880\n",
      "2025-06-26 22:59:05 [INFO]: Epoch 012 - training loss (MAE): 0.9799, validation MSE: 0.5251\n",
      "2025-06-26 22:59:10 [INFO]: Epoch 013 - training loss (MAE): 0.9130, validation MSE: 0.4794\n",
      "2025-06-26 22:59:15 [INFO]: Epoch 014 - training loss (MAE): 0.8583, validation MSE: 0.4478\n",
      "2025-06-26 22:59:19 [INFO]: Epoch 015 - training loss (MAE): 0.8208, validation MSE: 0.4228\n",
      "2025-06-26 22:59:23 [INFO]: Epoch 016 - training loss (MAE): 0.7566, validation MSE: 0.3679\n",
      "2025-06-26 22:59:28 [INFO]: Epoch 017 - training loss (MAE): 0.7126, validation MSE: 0.3353\n",
      "2025-06-26 22:59:32 [INFO]: Epoch 018 - training loss (MAE): 0.6693, validation MSE: 0.2987\n",
      "2025-06-26 22:59:36 [INFO]: Epoch 019 - training loss (MAE): 0.6304, validation MSE: 0.2523\n",
      "2025-06-26 22:59:41 [INFO]: Epoch 020 - training loss (MAE): 0.5996, validation MSE: 0.2397\n",
      "2025-06-26 22:59:46 [INFO]: Epoch 021 - training loss (MAE): 0.5682, validation MSE: 0.2067\n",
      "2025-06-26 22:59:50 [INFO]: Epoch 022 - training loss (MAE): 0.5513, validation MSE: 0.1970\n",
      "2025-06-26 22:59:54 [INFO]: Epoch 023 - training loss (MAE): 0.5160, validation MSE: 0.1671\n",
      "2025-06-26 22:59:58 [INFO]: Epoch 024 - training loss (MAE): 0.5026, validation MSE: 0.1540\n",
      "2025-06-26 23:00:02 [INFO]: Epoch 025 - training loss (MAE): 0.4711, validation MSE: 0.1335\n",
      "2025-06-26 23:00:02 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 23:00:02 [INFO]: Saved the model to ./brits_model\\20250626_T225806\\BRITS.pypots\n",
      "2025-06-26 23:00:02 [INFO]: Using the given device: cpu\n",
      "2025-06-26 23:00:02 [INFO]: Model files will be saved to ./brits_model\\20250626_T230002\n",
      "2025-06-26 23:00:02 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T230002\\tensorboard\n",
      "2025-06-26 23:00:02 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 23:00:02 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 23:00:02 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 3,776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.99 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 23:00:09 [INFO]: Epoch 001 - training loss (MAE): 1.7979, validation MSE: 0.9018\n",
      "2025-06-26 23:00:13 [INFO]: Epoch 002 - training loss (MAE): 1.8029, validation MSE: 0.8983\n",
      "2025-06-26 23:00:18 [INFO]: Epoch 003 - training loss (MAE): 1.7714, validation MSE: 0.8947\n",
      "2025-06-26 23:00:22 [INFO]: Epoch 004 - training loss (MAE): 1.6777, validation MSE: 0.8897\n",
      "2025-06-26 23:00:27 [INFO]: Epoch 005 - training loss (MAE): 1.6441, validation MSE: 0.8860\n",
      "2025-06-26 23:00:31 [INFO]: Epoch 006 - training loss (MAE): 1.5179, validation MSE: 0.8845\n",
      "2025-06-26 23:00:36 [INFO]: Epoch 007 - training loss (MAE): 1.4198, validation MSE: 0.8760\n",
      "2025-06-26 23:00:42 [INFO]: Epoch 008 - training loss (MAE): 1.3206, validation MSE: 0.8631\n",
      "2025-06-26 23:00:47 [INFO]: Epoch 009 - training loss (MAE): 1.2138, validation MSE: 0.8522\n",
      "2025-06-26 23:00:52 [INFO]: Epoch 010 - training loss (MAE): 1.1335, validation MSE: 0.8597\n",
      "2025-06-26 23:00:57 [INFO]: Epoch 011 - training loss (MAE): 0.9731, validation MSE: 0.8700\n",
      "2025-06-26 23:01:03 [INFO]: Epoch 012 - training loss (MAE): 0.8818, validation MSE: 0.8820\n",
      "2025-06-26 23:01:08 [INFO]: Epoch 013 - training loss (MAE): 0.7722, validation MSE: 0.8999\n",
      "2025-06-26 23:01:14 [INFO]: Epoch 014 - training loss (MAE): 0.6953, validation MSE: 0.8900\n",
      "2025-06-26 23:01:14 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-06-26 23:01:14 [INFO]: Finished training. The best model is from epoch#9.\n",
      "2025-06-26 23:01:14 [INFO]: Saved the model to ./brits_model\\20250626_T230002\\BRITS.pypots\n",
      "2025-06-26 23:01:14 [INFO]: Using the given device: cpu\n",
      "2025-06-26 23:01:14 [INFO]: Model files will be saved to ./brits_model\\20250626_T230114\n",
      "2025-06-26 23:01:14 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T230114\\tensorboard\n",
      "2025-06-26 23:01:14 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 23:01:14 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 23:01:14 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 3...\n",
      "Training model for missing rate 0.05 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 23:01:22 [INFO]: Epoch 001 - training loss (MAE): 1.5514, validation MSE: 1.0501\n",
      "2025-06-26 23:01:28 [INFO]: Epoch 002 - training loss (MAE): 1.4544, validation MSE: 0.8612\n",
      "2025-06-26 23:01:34 [INFO]: Epoch 003 - training loss (MAE): 1.3077, validation MSE: 0.6729\n",
      "2025-06-26 23:01:39 [INFO]: Epoch 004 - training loss (MAE): 1.1728, validation MSE: 0.4998\n",
      "2025-06-26 23:01:44 [INFO]: Epoch 005 - training loss (MAE): 1.0487, validation MSE: 0.3563\n",
      "2025-06-26 23:01:50 [INFO]: Epoch 006 - training loss (MAE): 0.9140, validation MSE: 0.2415\n",
      "2025-06-26 23:01:55 [INFO]: Epoch 007 - training loss (MAE): 0.8087, validation MSE: 0.1542\n",
      "2025-06-26 23:02:00 [INFO]: Epoch 008 - training loss (MAE): 0.6773, validation MSE: 0.0956\n",
      "2025-06-26 23:02:06 [INFO]: Epoch 009 - training loss (MAE): 0.5829, validation MSE: 0.0579\n",
      "2025-06-26 23:02:11 [INFO]: Epoch 010 - training loss (MAE): 0.5058, validation MSE: 0.0366\n",
      "2025-06-26 23:02:16 [INFO]: Epoch 011 - training loss (MAE): 0.4461, validation MSE: 0.0259\n",
      "2025-06-26 23:02:22 [INFO]: Epoch 012 - training loss (MAE): 0.3994, validation MSE: 0.0208\n",
      "2025-06-26 23:02:27 [INFO]: Epoch 013 - training loss (MAE): 0.3629, validation MSE: 0.0178\n",
      "2025-06-26 23:02:33 [INFO]: Epoch 014 - training loss (MAE): 0.3367, validation MSE: 0.0166\n",
      "2025-06-26 23:02:38 [INFO]: Epoch 015 - training loss (MAE): 0.3167, validation MSE: 0.0156\n",
      "2025-06-26 23:02:43 [INFO]: Epoch 016 - training loss (MAE): 0.2980, validation MSE: 0.0147\n",
      "2025-06-26 23:02:48 [INFO]: Epoch 017 - training loss (MAE): 0.2869, validation MSE: 0.0142\n",
      "2025-06-26 23:02:54 [INFO]: Epoch 018 - training loss (MAE): 0.2754, validation MSE: 0.0135\n",
      "2025-06-26 23:02:59 [INFO]: Epoch 019 - training loss (MAE): 0.2666, validation MSE: 0.0131\n",
      "2025-06-26 23:03:05 [INFO]: Epoch 020 - training loss (MAE): 0.2590, validation MSE: 0.0129\n",
      "2025-06-26 23:03:10 [INFO]: Epoch 021 - training loss (MAE): 0.2532, validation MSE: 0.0125\n",
      "2025-06-26 23:03:16 [INFO]: Epoch 022 - training loss (MAE): 0.2547, validation MSE: 0.0125\n",
      "2025-06-26 23:03:21 [INFO]: Epoch 023 - training loss (MAE): 0.2480, validation MSE: 0.0121\n",
      "2025-06-26 23:03:26 [INFO]: Epoch 024 - training loss (MAE): 0.2465, validation MSE: 0.0123\n",
      "2025-06-26 23:03:32 [INFO]: Epoch 025 - training loss (MAE): 0.2424, validation MSE: 0.0120\n",
      "2025-06-26 23:03:32 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 23:03:32 [INFO]: Saved the model to ./brits_model\\20250626_T230114\\BRITS.pypots\n",
      "2025-06-26 23:03:32 [INFO]: Using the given device: cpu\n",
      "2025-06-26 23:03:32 [INFO]: Model files will be saved to ./brits_model\\20250626_T230332\n",
      "2025-06-26 23:03:32 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T230332\\tensorboard\n",
      "2025-06-26 23:03:32 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 23:03:32 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 23:03:32 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.4 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 23:03:42 [INFO]: Epoch 001 - training loss (MAE): 1.6447, validation MSE: 0.5789\n",
      "2025-06-26 23:03:47 [INFO]: Epoch 002 - training loss (MAE): 1.5459, validation MSE: 0.4819\n",
      "2025-06-26 23:03:52 [INFO]: Epoch 003 - training loss (MAE): 1.4397, validation MSE: 0.3851\n",
      "2025-06-26 23:03:57 [INFO]: Epoch 004 - training loss (MAE): 1.3541, validation MSE: 0.2934\n",
      "2025-06-26 23:04:02 [INFO]: Epoch 005 - training loss (MAE): 1.2057, validation MSE: 0.2096\n",
      "2025-06-26 23:04:07 [INFO]: Epoch 006 - training loss (MAE): 1.0581, validation MSE: 0.1384\n",
      "2025-06-26 23:04:13 [INFO]: Epoch 007 - training loss (MAE): 0.9195, validation MSE: 0.0849\n",
      "2025-06-26 23:04:18 [INFO]: Epoch 008 - training loss (MAE): 0.7972, validation MSE: 0.0523\n",
      "2025-06-26 23:04:23 [INFO]: Epoch 009 - training loss (MAE): 0.6819, validation MSE: 0.0373\n",
      "2025-06-26 23:04:29 [INFO]: Epoch 010 - training loss (MAE): 0.5947, validation MSE: 0.0318\n",
      "2025-06-26 23:04:34 [INFO]: Epoch 011 - training loss (MAE): 0.5127, validation MSE: 0.0292\n",
      "2025-06-26 23:04:39 [INFO]: Epoch 012 - training loss (MAE): 0.4592, validation MSE: 0.0275\n",
      "2025-06-26 23:04:45 [INFO]: Epoch 013 - training loss (MAE): 0.4192, validation MSE: 0.0262\n",
      "2025-06-26 23:04:50 [INFO]: Epoch 014 - training loss (MAE): 0.3847, validation MSE: 0.0249\n",
      "2025-06-26 23:04:55 [INFO]: Epoch 015 - training loss (MAE): 0.3452, validation MSE: 0.0236\n",
      "2025-06-26 23:05:01 [INFO]: Epoch 016 - training loss (MAE): 0.3222, validation MSE: 0.0229\n",
      "2025-06-26 23:05:06 [INFO]: Epoch 017 - training loss (MAE): 0.3033, validation MSE: 0.0227\n",
      "2025-06-26 23:05:11 [INFO]: Epoch 018 - training loss (MAE): 0.3002, validation MSE: 0.0221\n",
      "2025-06-26 23:05:18 [INFO]: Epoch 019 - training loss (MAE): 0.2775, validation MSE: 0.0215\n",
      "2025-06-26 23:05:23 [INFO]: Epoch 020 - training loss (MAE): 0.2716, validation MSE: 0.0213\n",
      "2025-06-26 23:05:28 [INFO]: Epoch 021 - training loss (MAE): 0.2707, validation MSE: 0.0211\n",
      "2025-06-26 23:05:33 [INFO]: Epoch 022 - training loss (MAE): 0.2610, validation MSE: 0.0208\n",
      "2025-06-26 23:05:38 [INFO]: Epoch 023 - training loss (MAE): 0.2574, validation MSE: 0.0206\n",
      "2025-06-26 23:05:43 [INFO]: Epoch 024 - training loss (MAE): 0.2536, validation MSE: 0.0207\n",
      "2025-06-26 23:05:49 [INFO]: Epoch 025 - training loss (MAE): 0.2527, validation MSE: 0.0207\n",
      "2025-06-26 23:05:49 [INFO]: Finished training. The best model is from epoch#23.\n",
      "2025-06-26 23:05:49 [INFO]: Saved the model to ./brits_model\\20250626_T230332\\BRITS.pypots\n",
      "2025-06-26 23:05:49 [INFO]: Using the given device: cpu\n",
      "2025-06-26 23:05:49 [INFO]: Model files will be saved to ./brits_model\\20250626_T230549\n",
      "2025-06-26 23:05:49 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T230549\\tensorboard\n",
      "2025-06-26 23:05:49 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 23:05:49 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 23:05:49 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 23:05:57 [INFO]: Epoch 001 - training loss (MAE): 1.7100, validation MSE: 0.8611\n",
      "2025-06-26 23:06:02 [INFO]: Epoch 002 - training loss (MAE): 1.6469, validation MSE: 0.7792\n",
      "2025-06-26 23:06:07 [INFO]: Epoch 003 - training loss (MAE): 1.4979, validation MSE: 0.6938\n",
      "2025-06-26 23:06:13 [INFO]: Epoch 004 - training loss (MAE): 1.3861, validation MSE: 0.6051\n",
      "2025-06-26 23:06:18 [INFO]: Epoch 005 - training loss (MAE): 1.2693, validation MSE: 0.5079\n",
      "2025-06-26 23:06:24 [INFO]: Epoch 006 - training loss (MAE): 1.1088, validation MSE: 0.4018\n",
      "2025-06-26 23:06:30 [INFO]: Epoch 007 - training loss (MAE): 0.9662, validation MSE: 0.2939\n",
      "2025-06-26 23:06:35 [INFO]: Epoch 008 - training loss (MAE): 0.8216, validation MSE: 0.2033\n",
      "2025-06-26 23:06:40 [INFO]: Epoch 009 - training loss (MAE): 0.6885, validation MSE: 0.1371\n",
      "2025-06-26 23:06:46 [INFO]: Epoch 010 - training loss (MAE): 0.5787, validation MSE: 0.0971\n",
      "2025-06-26 23:06:51 [INFO]: Epoch 011 - training loss (MAE): 0.5025, validation MSE: 0.0783\n",
      "2025-06-26 23:06:56 [INFO]: Epoch 012 - training loss (MAE): 0.4496, validation MSE: 0.0662\n",
      "2025-06-26 23:07:02 [INFO]: Epoch 013 - training loss (MAE): 0.3954, validation MSE: 0.0577\n",
      "2025-06-26 23:07:07 [INFO]: Epoch 014 - training loss (MAE): 0.3611, validation MSE: 0.0520\n",
      "2025-06-26 23:07:12 [INFO]: Epoch 015 - training loss (MAE): 0.3298, validation MSE: 0.0461\n",
      "2025-06-26 23:07:18 [INFO]: Epoch 016 - training loss (MAE): 0.3047, validation MSE: 0.0422\n",
      "2025-06-26 23:07:23 [INFO]: Epoch 017 - training loss (MAE): 0.2876, validation MSE: 0.0392\n",
      "2025-06-26 23:07:28 [INFO]: Epoch 018 - training loss (MAE): 0.2752, validation MSE: 0.0369\n",
      "2025-06-26 23:07:34 [INFO]: Epoch 019 - training loss (MAE): 0.2649, validation MSE: 0.0350\n",
      "2025-06-26 23:07:39 [INFO]: Epoch 020 - training loss (MAE): 0.2566, validation MSE: 0.0338\n",
      "2025-06-26 23:07:44 [INFO]: Epoch 021 - training loss (MAE): 0.2499, validation MSE: 0.0318\n",
      "2025-06-26 23:07:49 [INFO]: Epoch 022 - training loss (MAE): 0.2477, validation MSE: 0.0318\n",
      "2025-06-26 23:07:55 [INFO]: Epoch 023 - training loss (MAE): 0.2442, validation MSE: 0.0330\n",
      "2025-06-26 23:08:00 [INFO]: Epoch 024 - training loss (MAE): 0.2403, validation MSE: 0.0321\n",
      "2025-06-26 23:08:06 [INFO]: Epoch 025 - training loss (MAE): 0.2360, validation MSE: 0.0309\n",
      "2025-06-26 23:08:06 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 23:08:06 [INFO]: Saved the model to ./brits_model\\20250626_T230549\\BRITS.pypots\n",
      "2025-06-26 23:08:06 [INFO]: Using the given device: cpu\n",
      "2025-06-26 23:08:06 [INFO]: Model files will be saved to ./brits_model\\20250626_T230806\n",
      "2025-06-26 23:08:06 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T230806\\tensorboard\n",
      "2025-06-26 23:08:06 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 23:08:06 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 23:08:06 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.99 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 23:08:14 [INFO]: Epoch 001 - training loss (MAE): 1.6525, validation MSE: 1.1095\n",
      "2025-06-26 23:08:19 [INFO]: Epoch 002 - training loss (MAE): 1.5806, validation MSE: 1.0877\n",
      "2025-06-26 23:08:25 [INFO]: Epoch 003 - training loss (MAE): 1.5077, validation MSE: 1.0691\n",
      "2025-06-26 23:08:30 [INFO]: Epoch 004 - training loss (MAE): 1.4219, validation MSE: 1.0600\n",
      "2025-06-26 23:08:36 [INFO]: Epoch 005 - training loss (MAE): 1.2983, validation MSE: 1.0582\n",
      "2025-06-26 23:08:41 [INFO]: Epoch 006 - training loss (MAE): 1.1673, validation MSE: 1.0312\n",
      "2025-06-26 23:08:46 [INFO]: Epoch 007 - training loss (MAE): 1.0145, validation MSE: 0.9658\n",
      "2025-06-26 23:08:52 [INFO]: Epoch 008 - training loss (MAE): 0.8286, validation MSE: 0.8773\n",
      "2025-06-26 23:08:57 [INFO]: Epoch 009 - training loss (MAE): 0.6585, validation MSE: 0.7872\n",
      "2025-06-26 23:09:02 [INFO]: Epoch 010 - training loss (MAE): 0.5340, validation MSE: 0.7369\n",
      "2025-06-26 23:09:07 [INFO]: Epoch 011 - training loss (MAE): 0.4448, validation MSE: 0.6853\n",
      "2025-06-26 23:09:12 [INFO]: Epoch 012 - training loss (MAE): 0.3858, validation MSE: 0.6469\n",
      "2025-06-26 23:09:18 [INFO]: Epoch 013 - training loss (MAE): 0.3439, validation MSE: 0.6272\n",
      "2025-06-26 23:09:23 [INFO]: Epoch 014 - training loss (MAE): 0.3069, validation MSE: 0.6113\n",
      "2025-06-26 23:09:28 [INFO]: Epoch 015 - training loss (MAE): 0.2990, validation MSE: 0.5968\n",
      "2025-06-26 23:09:34 [INFO]: Epoch 016 - training loss (MAE): 0.2906, validation MSE: 0.5800\n",
      "2025-06-26 23:09:39 [INFO]: Epoch 017 - training loss (MAE): 0.2808, validation MSE: 0.5619\n",
      "2025-06-26 23:09:44 [INFO]: Epoch 018 - training loss (MAE): 0.2707, validation MSE: 0.5475\n",
      "2025-06-26 23:09:49 [INFO]: Epoch 019 - training loss (MAE): 0.2713, validation MSE: 0.5370\n",
      "2025-06-26 23:09:55 [INFO]: Epoch 020 - training loss (MAE): 0.2657, validation MSE: 0.5292\n",
      "2025-06-26 23:10:00 [INFO]: Epoch 021 - training loss (MAE): 0.2665, validation MSE: 0.5228\n",
      "2025-06-26 23:10:06 [INFO]: Epoch 022 - training loss (MAE): 0.2605, validation MSE: 0.5134\n",
      "2025-06-26 23:10:11 [INFO]: Epoch 023 - training loss (MAE): 0.2605, validation MSE: 0.5041\n",
      "2025-06-26 23:10:16 [INFO]: Epoch 024 - training loss (MAE): 0.2559, validation MSE: 0.4966\n",
      "2025-06-26 23:10:22 [INFO]: Epoch 025 - training loss (MAE): 0.2573, validation MSE: 0.4909\n",
      "2025-06-26 23:10:22 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 23:10:22 [INFO]: Saved the model to ./brits_model\\20250626_T230806\\BRITS.pypots\n",
      "2025-06-26 23:10:22 [INFO]: Using the given device: cpu\n",
      "2025-06-26 23:10:22 [INFO]: Model files will be saved to ./brits_model\\20250626_T231022\n",
      "2025-06-26 23:10:22 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T231022\\tensorboard\n",
      "2025-06-26 23:10:22 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 23:10:22 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 23:10:22 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 40,048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 4...\n",
      "Training model for missing rate 0.05 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 23:10:31 [INFO]: Epoch 001 - training loss (MAE): 1.5679, validation MSE: 0.5958\n",
      "2025-06-26 23:10:37 [INFO]: Epoch 002 - training loss (MAE): 1.2106, validation MSE: 0.2929\n",
      "2025-06-26 23:10:43 [INFO]: Epoch 003 - training loss (MAE): 0.9195, validation MSE: 0.1436\n",
      "2025-06-26 23:10:49 [INFO]: Epoch 004 - training loss (MAE): 0.6891, validation MSE: 0.0863\n",
      "2025-06-26 23:10:55 [INFO]: Epoch 005 - training loss (MAE): 0.5154, validation MSE: 0.0628\n",
      "2025-06-26 23:11:01 [INFO]: Epoch 006 - training loss (MAE): 0.4072, validation MSE: 0.0561\n",
      "2025-06-26 23:11:07 [INFO]: Epoch 007 - training loss (MAE): 0.3426, validation MSE: 0.0533\n",
      "2025-06-26 23:11:13 [INFO]: Epoch 008 - training loss (MAE): 0.3050, validation MSE: 0.0513\n",
      "2025-06-26 23:11:19 [INFO]: Epoch 009 - training loss (MAE): 0.2812, validation MSE: 0.0502\n",
      "2025-06-26 23:11:25 [INFO]: Epoch 010 - training loss (MAE): 0.2648, validation MSE: 0.0493\n",
      "2025-06-26 23:11:31 [INFO]: Epoch 011 - training loss (MAE): 0.2533, validation MSE: 0.0482\n",
      "2025-06-26 23:11:37 [INFO]: Epoch 012 - training loss (MAE): 0.2512, validation MSE: 0.0478\n",
      "2025-06-26 23:11:42 [INFO]: Epoch 013 - training loss (MAE): 0.2416, validation MSE: 0.0472\n",
      "2025-06-26 23:11:48 [INFO]: Epoch 014 - training loss (MAE): 0.2362, validation MSE: 0.0465\n",
      "2025-06-26 23:11:54 [INFO]: Epoch 015 - training loss (MAE): 0.2372, validation MSE: 0.0464\n",
      "2025-06-26 23:12:00 [INFO]: Epoch 016 - training loss (MAE): 0.2323, validation MSE: 0.0458\n",
      "2025-06-26 23:12:06 [INFO]: Epoch 017 - training loss (MAE): 0.2307, validation MSE: 0.0454\n",
      "2025-06-26 23:12:12 [INFO]: Epoch 018 - training loss (MAE): 0.2293, validation MSE: 0.0451\n",
      "2025-06-26 23:12:18 [INFO]: Epoch 019 - training loss (MAE): 0.2224, validation MSE: 0.0445\n",
      "2025-06-26 23:12:24 [INFO]: Epoch 020 - training loss (MAE): 0.2194, validation MSE: 0.0441\n",
      "2025-06-26 23:12:30 [INFO]: Epoch 021 - training loss (MAE): 0.2173, validation MSE: 0.0435\n",
      "2025-06-26 23:12:36 [INFO]: Epoch 022 - training loss (MAE): 0.2159, validation MSE: 0.0432\n",
      "2025-06-26 23:12:42 [INFO]: Epoch 023 - training loss (MAE): 0.2183, validation MSE: 0.0430\n",
      "2025-06-26 23:12:48 [INFO]: Epoch 024 - training loss (MAE): 0.2145, validation MSE: 0.0427\n",
      "2025-06-26 23:12:53 [INFO]: Epoch 025 - training loss (MAE): 0.2174, validation MSE: 0.0424\n",
      "2025-06-26 23:12:53 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 23:12:53 [INFO]: Saved the model to ./brits_model\\20250626_T231022\\BRITS.pypots\n",
      "2025-06-26 23:12:53 [INFO]: Using the given device: cpu\n",
      "2025-06-26 23:12:53 [INFO]: Model files will be saved to ./brits_model\\20250626_T231253\n",
      "2025-06-26 23:12:53 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T231253\\tensorboard\n",
      "2025-06-26 23:12:53 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 23:12:53 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 23:12:53 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 40,048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.4 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 23:13:02 [INFO]: Epoch 001 - training loss (MAE): 1.6557, validation MSE: 0.6859\n",
      "2025-06-26 23:13:08 [INFO]: Epoch 002 - training loss (MAE): 1.3154, validation MSE: 0.4070\n",
      "2025-06-26 23:13:14 [INFO]: Epoch 003 - training loss (MAE): 1.0158, validation MSE: 0.1906\n",
      "2025-06-26 23:13:21 [INFO]: Epoch 004 - training loss (MAE): 0.7633, validation MSE: 0.0888\n",
      "2025-06-26 23:13:26 [INFO]: Epoch 005 - training loss (MAE): 0.5868, validation MSE: 0.0610\n",
      "2025-06-26 23:13:33 [INFO]: Epoch 006 - training loss (MAE): 0.4816, validation MSE: 0.0549\n",
      "2025-06-26 23:13:39 [INFO]: Epoch 007 - training loss (MAE): 0.4013, validation MSE: 0.0513\n",
      "2025-06-26 23:13:45 [INFO]: Epoch 008 - training loss (MAE): 0.3525, validation MSE: 0.0484\n",
      "2025-06-26 23:13:50 [INFO]: Epoch 009 - training loss (MAE): 0.3246, validation MSE: 0.0462\n",
      "2025-06-26 23:13:56 [INFO]: Epoch 010 - training loss (MAE): 0.2983, validation MSE: 0.0450\n",
      "2025-06-26 23:14:02 [INFO]: Epoch 011 - training loss (MAE): 0.2898, validation MSE: 0.0442\n",
      "2025-06-26 23:14:08 [INFO]: Epoch 012 - training loss (MAE): 0.2801, validation MSE: 0.0432\n",
      "2025-06-26 23:14:14 [INFO]: Epoch 013 - training loss (MAE): 0.2648, validation MSE: 0.0428\n",
      "2025-06-26 23:14:20 [INFO]: Epoch 014 - training loss (MAE): 0.2622, validation MSE: 0.0421\n",
      "2025-06-26 23:14:26 [INFO]: Epoch 015 - training loss (MAE): 0.2528, validation MSE: 0.0417\n",
      "2025-06-26 23:14:32 [INFO]: Epoch 016 - training loss (MAE): 0.2504, validation MSE: 0.0414\n",
      "2025-06-26 23:14:38 [INFO]: Epoch 017 - training loss (MAE): 0.2495, validation MSE: 0.0406\n",
      "2025-06-26 23:14:44 [INFO]: Epoch 018 - training loss (MAE): 0.2411, validation MSE: 0.0406\n",
      "2025-06-26 23:14:50 [INFO]: Epoch 019 - training loss (MAE): 0.2406, validation MSE: 0.0402\n",
      "2025-06-26 23:14:56 [INFO]: Epoch 020 - training loss (MAE): 0.2361, validation MSE: 0.0398\n",
      "2025-06-26 23:15:02 [INFO]: Epoch 021 - training loss (MAE): 0.2341, validation MSE: 0.0395\n",
      "2025-06-26 23:15:08 [INFO]: Epoch 022 - training loss (MAE): 0.2313, validation MSE: 0.0390\n",
      "2025-06-26 23:15:14 [INFO]: Epoch 023 - training loss (MAE): 0.2310, validation MSE: 0.0388\n",
      "2025-06-26 23:15:20 [INFO]: Epoch 024 - training loss (MAE): 0.2295, validation MSE: 0.0384\n",
      "2025-06-26 23:15:26 [INFO]: Epoch 025 - training loss (MAE): 0.2256, validation MSE: 0.0382\n",
      "2025-06-26 23:15:26 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 23:15:26 [INFO]: Saved the model to ./brits_model\\20250626_T231253\\BRITS.pypots\n",
      "2025-06-26 23:15:26 [INFO]: Using the given device: cpu\n",
      "2025-06-26 23:15:26 [INFO]: Model files will be saved to ./brits_model\\20250626_T231526\n",
      "2025-06-26 23:15:26 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T231526\\tensorboard\n",
      "2025-06-26 23:15:26 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 23:15:26 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 23:15:26 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 40,048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 23:15:35 [INFO]: Epoch 001 - training loss (MAE): 1.7137, validation MSE: 0.6382\n",
      "2025-06-26 23:15:41 [INFO]: Epoch 002 - training loss (MAE): 1.3851, validation MSE: 0.4039\n",
      "2025-06-26 23:15:47 [INFO]: Epoch 003 - training loss (MAE): 1.1112, validation MSE: 0.2225\n",
      "2025-06-26 23:15:54 [INFO]: Epoch 004 - training loss (MAE): 0.8550, validation MSE: 0.1204\n",
      "2025-06-26 23:16:00 [INFO]: Epoch 005 - training loss (MAE): 0.6693, validation MSE: 0.0857\n",
      "2025-06-26 23:16:06 [INFO]: Epoch 006 - training loss (MAE): 0.5372, validation MSE: 0.0675\n",
      "2025-06-26 23:16:11 [INFO]: Epoch 007 - training loss (MAE): 0.4385, validation MSE: 0.0570\n",
      "2025-06-26 23:16:17 [INFO]: Epoch 008 - training loss (MAE): 0.3810, validation MSE: 0.0531\n",
      "2025-06-26 23:16:23 [INFO]: Epoch 009 - training loss (MAE): 0.3365, validation MSE: 0.0496\n",
      "2025-06-26 23:16:29 [INFO]: Epoch 010 - training loss (MAE): 0.3072, validation MSE: 0.0478\n",
      "2025-06-26 23:16:35 [INFO]: Epoch 011 - training loss (MAE): 0.2886, validation MSE: 0.0470\n",
      "2025-06-26 23:16:41 [INFO]: Epoch 012 - training loss (MAE): 0.2716, validation MSE: 0.0461\n",
      "2025-06-26 23:16:47 [INFO]: Epoch 013 - training loss (MAE): 0.2686, validation MSE: 0.0466\n",
      "2025-06-26 23:16:53 [INFO]: Epoch 014 - training loss (MAE): 0.2545, validation MSE: 0.0458\n",
      "2025-06-26 23:16:59 [INFO]: Epoch 015 - training loss (MAE): 0.2485, validation MSE: 0.0452\n",
      "2025-06-26 23:17:05 [INFO]: Epoch 016 - training loss (MAE): 0.2464, validation MSE: 0.0455\n",
      "2025-06-26 23:17:11 [INFO]: Epoch 017 - training loss (MAE): 0.2428, validation MSE: 0.0449\n",
      "2025-06-26 23:17:17 [INFO]: Epoch 018 - training loss (MAE): 0.2372, validation MSE: 0.0447\n",
      "2025-06-26 23:17:24 [INFO]: Epoch 019 - training loss (MAE): 0.2346, validation MSE: 0.0447\n",
      "2025-06-26 23:17:29 [INFO]: Epoch 020 - training loss (MAE): 0.2289, validation MSE: 0.0441\n",
      "2025-06-26 23:17:35 [INFO]: Epoch 021 - training loss (MAE): 0.2291, validation MSE: 0.0440\n",
      "2025-06-26 23:17:41 [INFO]: Epoch 022 - training loss (MAE): 0.2257, validation MSE: 0.0436\n",
      "2025-06-26 23:17:47 [INFO]: Epoch 023 - training loss (MAE): 0.2308, validation MSE: 0.0442\n",
      "2025-06-26 23:17:53 [INFO]: Epoch 024 - training loss (MAE): 0.2231, validation MSE: 0.0432\n",
      "2025-06-26 23:17:59 [INFO]: Epoch 025 - training loss (MAE): 0.2235, validation MSE: 0.0433\n",
      "2025-06-26 23:17:59 [INFO]: Finished training. The best model is from epoch#24.\n",
      "2025-06-26 23:17:59 [INFO]: Saved the model to ./brits_model\\20250626_T231526\\BRITS.pypots\n",
      "2025-06-26 23:17:59 [INFO]: Using the given device: cpu\n",
      "2025-06-26 23:17:59 [INFO]: Model files will be saved to ./brits_model\\20250626_T231759\n",
      "2025-06-26 23:17:59 [INFO]: Tensorboard file will be saved to ./brits_model\\20250626_T231759\\tensorboard\n",
      "2025-06-26 23:17:59 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-26 23:17:59 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-26 23:17:59 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 40,048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.99 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 23:18:08 [INFO]: Epoch 001 - training loss (MAE): 1.7173, validation MSE: 0.9065\n",
      "2025-06-26 23:18:14 [INFO]: Epoch 002 - training loss (MAE): 1.4286, validation MSE: 0.8209\n",
      "2025-06-26 23:18:20 [INFO]: Epoch 003 - training loss (MAE): 1.1593, validation MSE: 0.6994\n",
      "2025-06-26 23:18:26 [INFO]: Epoch 004 - training loss (MAE): 0.8615, validation MSE: 0.5847\n",
      "2025-06-26 23:18:33 [INFO]: Epoch 005 - training loss (MAE): 0.6222, validation MSE: 0.5059\n",
      "2025-06-26 23:18:39 [INFO]: Epoch 006 - training loss (MAE): 0.4930, validation MSE: 0.4380\n",
      "2025-06-26 23:18:45 [INFO]: Epoch 007 - training loss (MAE): 0.4173, validation MSE: 0.3962\n",
      "2025-06-26 23:18:50 [INFO]: Epoch 008 - training loss (MAE): 0.3726, validation MSE: 0.3559\n",
      "2025-06-26 23:18:57 [INFO]: Epoch 009 - training loss (MAE): 0.3462, validation MSE: 0.3197\n",
      "2025-06-26 23:19:02 [INFO]: Epoch 010 - training loss (MAE): 0.3327, validation MSE: 0.2934\n",
      "2025-06-26 23:19:08 [INFO]: Epoch 011 - training loss (MAE): 0.3285, validation MSE: 0.2658\n",
      "2025-06-26 23:19:14 [INFO]: Epoch 012 - training loss (MAE): 0.3122, validation MSE: 0.2430\n",
      "2025-06-26 23:19:20 [INFO]: Epoch 013 - training loss (MAE): 0.3057, validation MSE: 0.2285\n",
      "2025-06-26 23:19:26 [INFO]: Epoch 014 - training loss (MAE): 0.2964, validation MSE: 0.2121\n",
      "2025-06-26 23:19:32 [INFO]: Epoch 015 - training loss (MAE): 0.2941, validation MSE: 0.1992\n",
      "2025-06-26 23:19:38 [INFO]: Epoch 016 - training loss (MAE): 0.2916, validation MSE: 0.1911\n",
      "2025-06-26 23:19:44 [INFO]: Epoch 017 - training loss (MAE): 0.2850, validation MSE: 0.1792\n",
      "2025-06-26 23:19:50 [INFO]: Epoch 018 - training loss (MAE): 0.2833, validation MSE: 0.1754\n",
      "2025-06-26 23:19:56 [INFO]: Epoch 019 - training loss (MAE): 0.2794, validation MSE: 0.1646\n",
      "2025-06-26 23:20:02 [INFO]: Epoch 020 - training loss (MAE): 0.2782, validation MSE: 0.1564\n",
      "2025-06-26 23:20:08 [INFO]: Epoch 021 - training loss (MAE): 0.2753, validation MSE: 0.1493\n",
      "2025-06-26 23:20:14 [INFO]: Epoch 022 - training loss (MAE): 0.2754, validation MSE: 0.1432\n",
      "2025-06-26 23:20:20 [INFO]: Epoch 023 - training loss (MAE): 0.2701, validation MSE: 0.1335\n",
      "2025-06-26 23:20:26 [INFO]: Epoch 024 - training loss (MAE): 0.2662, validation MSE: 0.1271\n",
      "2025-06-26 23:20:32 [INFO]: Epoch 025 - training loss (MAE): 0.2640, validation MSE: 0.1262\n",
      "2025-06-26 23:20:32 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-26 23:20:32 [INFO]: Saved the model to ./brits_model\\20250626_T231759\\BRITS.pypots\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "rnn_hidden = 0\n",
    "# Initialize and fit BRITS models for each missing rate\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    print(f\"Training BRITS models for cluster {cluster_id}...\")\n",
    "    models[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        print(f\"Training model for missing rate {rate} in cluster {cluster_id}...\")\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        _, n_steps, n_features = train_data[cluster_id][key][\"X\"].shape\n",
    "        \n",
    "        # Reduce complexity of model for less features\n",
    "        if cluster_id != len(clusters) - 1:\n",
    "            rnn_hidden = 16\n",
    "        else:\n",
    "            rnn_hidden = 32\n",
    "        \n",
    "        models[cluster_id][key] = intialize_BRITS(n_steps, n_features, rnn_hidden)\n",
    "        models[cluster_id][key].fit(train_data[cluster_id][key], val_set=val_data[cluster_id][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2ebffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluation, since BRITS does not have passed ground truth without missing values.\n",
    "\n",
    "imputed = {}\n",
    "\n",
    "# Impute missing values using the trained models\n",
    "for cluster_id in range(len(clusters)):\n",
    "    imputed[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        imputed[cluster_id][key] = models[cluster_id][key].impute(val_data[cluster_id][key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f816a26",
   "metadata": {},
   "source": [
    "### Unscale data before evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08462023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "imputed_unscaled = {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    imputed_unscaled[cluster_id] = {}\n",
    "    \n",
    "    scaler = joblib.load(f\"flow_scaler_{cluster_id}.pkl\")\n",
    "\n",
    "# Unscale the imputed values for each cluster and missing rate\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        n_samples, n_steps, n_features = imputed[cluster_id][key].shape\n",
    "        tensor_2d = imputed[cluster_id][key].reshape(-1, n_features)  # Flatten time dimension\n",
    "        tensor_2d_unscaled = scaler.inverse_transform(tensor_2d)\n",
    "        imputed_unscaled[cluster_id][key] = tensor_2d_unscaled.reshape(n_samples, n_steps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78884b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputed_unscaled[0][60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca3669fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputed_unscaled[0][99]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f95fed",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c05ad670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Cluster 0 Rate 5%: 0.968\n",
      "R² Cluster 0 Rate 40%: 0.961\n",
      "R² Cluster 0 Rate 60%: 0.860\n",
      "R² Cluster 0 Rate 99%: 0.407\n",
      "R² Cluster 1 Rate 5%: 0.994\n",
      "R² Cluster 1 Rate 40%: 0.990\n",
      "R² Cluster 1 Rate 60%: 0.957\n",
      "R² Cluster 1 Rate 99%: 0.512\n",
      "R² Cluster 2 Rate 5%: 0.941\n",
      "R² Cluster 2 Rate 40%: 0.921\n",
      "R² Cluster 2 Rate 60%: 0.800\n",
      "R² Cluster 2 Rate 99%: -0.138\n",
      "R² Cluster 3 Rate 5%: 0.976\n",
      "R² Cluster 3 Rate 40%: 0.963\n",
      "R² Cluster 3 Rate 60%: 0.944\n",
      "R² Cluster 3 Rate 99%: 0.333\n",
      "R² Cluster 4 Rate 5%: 0.924\n",
      "R² Cluster 4 Rate 40%: 0.936\n",
      "R² Cluster 4 Rate 60%: 0.932\n",
      "R² Cluster 4 Rate 99%: 0.829\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_scores = {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    r2_scores[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        imputed = imputed_unscaled[cluster_id][key]\n",
    "        original = X_val_full_unscaled_seq_tensor[cluster_id]\n",
    "        mask = val_masks_seq[cluster_id][key]\n",
    "\n",
    "        # Initialize list for per-feature R²\n",
    "        feature_r2 = []\n",
    "\n",
    "        for f in range(original.shape[2]):  # loop over features\n",
    "            f_mask = mask[:, :, f]\n",
    "            if not np.any(f_mask):\n",
    "                continue  # skip if no missing values for this feature\n",
    "\n",
    "            y_true = original[:, :, f][f_mask]\n",
    "            y_pred = imputed[:, :, f][f_mask]\n",
    "\n",
    "            if len(y_true) < 2:\n",
    "                continue  # not enough points to compute R²\n",
    "\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            feature_r2.append(r2)\n",
    "\n",
    "        if feature_r2:\n",
    "            r2_scores[cluster_id][key] = np.mean(feature_r2)\n",
    "        else:\n",
    "            r2_scores[cluster_id][key] = np.nan  # or 0 or another fallback\n",
    "\n",
    "        print(f\"R² Cluster {cluster_id} Rate {rate*100:.0f}%: {r2_scores[cluster_id][key]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f44ec722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE Cluster 0 Rate 5.0%: 5.36%\n",
      "SMAPE Cluster 0 Rate 40.0%: 4.10%\n",
      "SMAPE Cluster 0 Rate 60.0%: 20.61%\n",
      "SMAPE Cluster 0 Rate 99.0%: 29.54%\n",
      "SMAPE Cluster 1 Rate 5.0%: 1.23%\n",
      "SMAPE Cluster 1 Rate 40.0%: 1.60%\n",
      "SMAPE Cluster 1 Rate 60.0%: 6.62%\n",
      "SMAPE Cluster 1 Rate 99.0%: 18.47%\n",
      "SMAPE Cluster 2 Rate 5.0%: 5.36%\n",
      "SMAPE Cluster 2 Rate 40.0%: 8.86%\n",
      "SMAPE Cluster 2 Rate 60.0%: 14.59%\n",
      "SMAPE Cluster 2 Rate 99.0%: 29.39%\n",
      "SMAPE Cluster 3 Rate 5.0%: 3.65%\n",
      "SMAPE Cluster 3 Rate 40.0%: 4.03%\n",
      "SMAPE Cluster 3 Rate 60.0%: 4.95%\n",
      "SMAPE Cluster 3 Rate 99.0%: 21.88%\n",
      "SMAPE Cluster 4 Rate 5.0%: 5.69%\n",
      "SMAPE Cluster 4 Rate 40.0%: 6.38%\n",
      "SMAPE Cluster 4 Rate 60.0%: 6.92%\n",
      "SMAPE Cluster 4 Rate 99.0%: 13.89%\n"
     ]
    }
   ],
   "source": [
    "smape = {}\n",
    "for cluster_id in range(len(clusters)):\n",
    "    smape[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        imputed = imputed_unscaled[cluster_id][key]  # shape (n_samples, n_steps, n_features)\n",
    "        original = X_val_full_unscaled_seq_tensor[cluster_id]  # same shape\n",
    "        mask = val_masks_seq[cluster_id][key]  # same shape (bool mask)\n",
    "\n",
    "        n_samples, n_steps, n_features = original.shape\n",
    "\n",
    "        feature_smapes = []\n",
    "        for f in range(n_features):\n",
    "            # Select the mask and data for feature f\n",
    "            f_mask = mask[:, :, f]\n",
    "            if not np.any(f_mask):\n",
    "                continue  # skip if no missing values for this feature\n",
    "\n",
    "            numerator = np.abs(imputed[:, :, f][f_mask] - original[:, :, f][f_mask])\n",
    "            denominator = np.abs(imputed[:, :, f][f_mask]) + np.abs(original[:, :, f][f_mask]) + 1e-8\n",
    "            smape_f = 100 * np.mean(2 * numerator / denominator)\n",
    "            feature_smapes.append(smape_f)\n",
    "\n",
    "        smape[cluster_id][key] = np.mean(feature_smapes) if feature_smapes else np.nan\n",
    "        print(f\"SMAPE Cluster {cluster_id} Rate {rate*100}%: {smape[cluster_id][key]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d343a",
   "metadata": {},
   "source": [
    "### Average errors per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cda8d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_per_cluster = {i: X_val_full_unscaled_seq_tensor[i].shape[-1] for i in range(len(clusters))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7af81258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 10, 1: 10, 2: 4, 3: 10, 4: 34}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7f27ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average NRMSE for rate 5.0%: 0.97%\n",
      "NRMSE for full at rate 5.0%: 0.92%\n",
      "Weighted Average NRMSE for rate 40.0%: 0.97%\n",
      "NRMSE for full at rate 40.0%: 0.94%\n",
      "Weighted Average NRMSE for rate 60.0%: 0.91%\n",
      "NRMSE for full at rate 60.0%: 0.93%\n",
      "Weighted Average NRMSE for rate 99.0%: 0.35%\n",
      "NRMSE for full at rate 99.0%: 0.83%\n"
     ]
    }
   ],
   "source": [
    "n_clusters = len(clusters) - 1  # number of actual clusters\n",
    "flow_all_id = len(clusters) - 1  # index of the full dataset\n",
    "\n",
    "avg_r2_cluster = {}\n",
    "r2_all = {}\n",
    "\n",
    "for rate in missing_rates:\n",
    "    key = int(rate * 100)\n",
    "\n",
    "    # Gather NRMSE and weights (number of features per cluster)\n",
    "    r2_values = np.array([r2_scores[cluster_id][key] for cluster_id in range(n_clusters)])\n",
    "    feature_counts = np.array([features_per_cluster[cluster_id] for cluster_id in range(n_clusters)])\n",
    "\n",
    "    # Compute weighted average\n",
    "    weighted_avg = np.average(r2_values, weights=feature_counts)\n",
    "    \n",
    "    avg_r2_cluster[key] = weighted_avg\n",
    "    r2_all[key] = r2_scores[flow_all_id][key]  # for full feature set\n",
    "\n",
    "    print(f\"Weighted Average NRMSE for rate {rate*100}%: {avg_r2_cluster[key]:.2f}%\")\n",
    "    print(f\"NRMSE for full at rate {rate*100}%: {r2_all[key]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc8b7010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average SMAPE for rate 5.0%: 3.64%\n",
      "SMAPE for full at rate 5.0%: 5.69%\n",
      "Weighted Average SMAPE for rate 40.0%: 3.91%\n",
      "SMAPE for full at rate 40.0%: 6.38%\n",
      "Weighted Average SMAPE for rate 60.0%: 11.18%\n",
      "SMAPE for full at rate 60.0%: 6.92%\n",
      "Weighted Average SMAPE for rate 99.0%: 24.02%\n",
      "SMAPE for full at rate 99.0%: 13.89%\n"
     ]
    }
   ],
   "source": [
    "avg_smape_cluster = {}\n",
    "smape_all = {}\n",
    "\n",
    "for rate in missing_rates:\n",
    "    key = int(rate * 100)\n",
    "    \n",
    "    # Gather SMAPE and weights (number of features per cluster)\n",
    "    smape_values = np.array([smape[cluster_id][key] for cluster_id in range(n_clusters)])\n",
    "    feature_counts = np.array([features_per_cluster[cluster_id] for cluster_id in range(n_clusters)])\n",
    "    \n",
    "    # Compute weighted average\n",
    "    weighted_avg = np.average(smape_values, weights=feature_counts)\n",
    "    \n",
    "    avg_smape_cluster[key] = weighted_avg\n",
    "    smape_all[key] = smape[flow_all_id][key]  # for full feature set\n",
    "    \n",
    "    print(f\"Weighted Average SMAPE for rate {rate*100}%: {avg_smape_cluster[key]:.2f}%\")\n",
    "    print(f\"SMAPE for full at rate {rate*100}%: {smape_all[key]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3e8203d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_missing_vs_observed(data, mask, feature_name=\"flow\"):\n",
    "    \"\"\"\n",
    "    data: 1D array of original values\n",
    "    mask: 1D boolean array, True if missing\n",
    "    feature_name: for labeling\n",
    "    \"\"\"\n",
    "    data_missing = data[mask]\n",
    "    data_observed = data[~mask]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(data_observed, color='blue', label='Observed', kde=True, stat=\"density\", bins=30)\n",
    "    sns.histplot(data_missing, color='red', label='Missing', kde=True, stat=\"density\", bins=30)\n",
    "    plt.title(f\"Distribution of {feature_name} - Observed vs Missing\")\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_missing_vs_observed(X_val_full_unscaled_seq_tensor[0].flatten(), val_masks_seq[0][99].flatten(), feature_name=\"Flow at 20% missingness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e346c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example error values (replace with your real variables)\n",
    "missing_levels = ['5%', '40%', '60%', '90%']\n",
    "\n",
    "# Bar chart setup\n",
    "x = np.arange(len(missing_levels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# --- MAE plot ---\n",
    "ax[0].bar(x - width/2, r2_all.values(), width, label='Without Semantics', color='tab:blue')\n",
    "ax[0].bar(x + width/2, avg_r2_cluster.values(), width, label='With Semantics', color='tab:orange')\n",
    "ax[0].set_ylabel('MAE')\n",
    "ax[0].set_title('MAE by Missingness Level')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# --- SMAPE plot ---\n",
    "ax[1].bar(x - width/2, smape_all.values(), width, label='Without Semantics', color='tab:blue')\n",
    "ax[1].bar(x + width/2, avg_smape_cluster.values(), width, label='With Semantics', color='tab:orange')\n",
    "ax[1].set_ylabel('SMAPE (%)')\n",
    "ax[1].set_title('SMAPE by Missingness Level')\n",
    "ax[1].set_xticks(x)\n",
    "ax[1].set_xticklabels(missing_levels)\n",
    "ax[1].legend()\n",
    "ax[1].grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e364c",
   "metadata": {},
   "source": [
    "With MNAR, mean imputation works much worse, around 40% SMAPE. On the other hand, BRITS with all features, and MNAR on 80% of values missingness on 30% of columns with values deviated from 70% of mean, performs 22% SMAPE.\n",
    "When using only semantically relevant features with same percentage as above, SMAPE is 21% so almost no improvement. It seems that best improvements, in general, come when percentage of missing data is very big, which makes other features more important thus their relevance increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73a5b2",
   "metadata": {},
   "source": [
    "With 100% missingness of values above 0.5 treshold (so real 50% MNAR missingness in 30% of columns), SMAPE for average is  62%. \n",
    "For BRITS with all features, it is 26,62%.\n",
    "For average imputation with semantically relevant features 51%, for BRITS with semantically relevant features, it is 11,21%. AMAZING IMPROVEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b871ce",
   "metadata": {},
   "source": [
    "## probar con otro modelo mas sencillo, mirar ultima celda distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
