{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8bdfe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134d6af4",
   "metadata": {},
   "source": [
    "## Get measurements from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc42a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_readings = pd.read_csv(\"D:\\Master\\Thesis\\Code\\L-Town\\measurements_LTown.csv\", index_col = 0)\n",
    "\n",
    "sensor_readings['Timestamp'] = pd.to_datetime(sensor_readings['Timestamp'])\n",
    "\n",
    "# Extract entity ID and type\n",
    "sensor_readings['entity_id'] = sensor_readings['sensor_id'].apply(lambda x: \"_\".join(x.split(\"_\")[:2]))  \n",
    "sensor_readings['measurement_type'] = sensor_readings['sensor_type']  # demand, pressure, flow\n",
    "sensor_readings['entity_type'] = sensor_readings['entity_id'].apply(lambda x: x.split(\"_\")[0])  # Node or Pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98956d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['demand', 'flow', 'level', 'pressure'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_readings[\"measurement_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bede15ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>measurement</th>\n",
       "      <th>sensor_type</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>measurement_type</th>\n",
       "      <th>entity_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>n1_demand</td>\n",
       "      <td>41.801667</td>\n",
       "      <td>demand</td>\n",
       "      <td>n1_demand_2018-01-01 00:00:00</td>\n",
       "      <td>n1_demand</td>\n",
       "      <td>demand</td>\n",
       "      <td>n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:30:00</td>\n",
       "      <td>n1_demand</td>\n",
       "      <td>37.711667</td>\n",
       "      <td>demand</td>\n",
       "      <td>n1_demand_2018-01-01 00:30:00</td>\n",
       "      <td>n1_demand</td>\n",
       "      <td>demand</td>\n",
       "      <td>n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>n1_demand</td>\n",
       "      <td>37.425000</td>\n",
       "      <td>demand</td>\n",
       "      <td>n1_demand_2018-01-01 01:00:00</td>\n",
       "      <td>n1_demand</td>\n",
       "      <td>demand</td>\n",
       "      <td>n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 01:30:00</td>\n",
       "      <td>n1_demand</td>\n",
       "      <td>41.076667</td>\n",
       "      <td>demand</td>\n",
       "      <td>n1_demand_2018-01-01 01:30:00</td>\n",
       "      <td>n1_demand</td>\n",
       "      <td>demand</td>\n",
       "      <td>n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>n1_demand</td>\n",
       "      <td>39.751667</td>\n",
       "      <td>demand</td>\n",
       "      <td>n1_demand_2018-01-01 02:00:00</td>\n",
       "      <td>n1_demand</td>\n",
       "      <td>demand</td>\n",
       "      <td>n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326075</th>\n",
       "      <td>2018-12-31 23:35:00</td>\n",
       "      <td>n769_pressure</td>\n",
       "      <td>48.330000</td>\n",
       "      <td>pressure</td>\n",
       "      <td>n769_pressure_2018-12-31 23:35:00</td>\n",
       "      <td>n769_pressure</td>\n",
       "      <td>pressure</td>\n",
       "      <td>n769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326076</th>\n",
       "      <td>2018-12-31 23:40:00</td>\n",
       "      <td>n769_pressure</td>\n",
       "      <td>48.330000</td>\n",
       "      <td>pressure</td>\n",
       "      <td>n769_pressure_2018-12-31 23:40:00</td>\n",
       "      <td>n769_pressure</td>\n",
       "      <td>pressure</td>\n",
       "      <td>n769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326077</th>\n",
       "      <td>2018-12-31 23:45:00</td>\n",
       "      <td>n769_pressure</td>\n",
       "      <td>48.360000</td>\n",
       "      <td>pressure</td>\n",
       "      <td>n769_pressure_2018-12-31 23:45:00</td>\n",
       "      <td>n769_pressure</td>\n",
       "      <td>pressure</td>\n",
       "      <td>n769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326078</th>\n",
       "      <td>2018-12-31 23:50:00</td>\n",
       "      <td>n769_pressure</td>\n",
       "      <td>48.320000</td>\n",
       "      <td>pressure</td>\n",
       "      <td>n769_pressure_2018-12-31 23:50:00</td>\n",
       "      <td>n769_pressure</td>\n",
       "      <td>pressure</td>\n",
       "      <td>n769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326079</th>\n",
       "      <td>2018-12-31 23:55:00</td>\n",
       "      <td>n769_pressure</td>\n",
       "      <td>48.420000</td>\n",
       "      <td>pressure</td>\n",
       "      <td>n769_pressure_2018-12-31 23:55:00</td>\n",
       "      <td>n769_pressure</td>\n",
       "      <td>pressure</td>\n",
       "      <td>n769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5326080 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp      sensor_id  measurement sensor_type  \\\n",
       "0       2018-01-01 00:00:00      n1_demand    41.801667      demand   \n",
       "1       2018-01-01 00:30:00      n1_demand    37.711667      demand   \n",
       "2       2018-01-01 01:00:00      n1_demand    37.425000      demand   \n",
       "3       2018-01-01 01:30:00      n1_demand    41.076667      demand   \n",
       "4       2018-01-01 02:00:00      n1_demand    39.751667      demand   \n",
       "...                     ...            ...          ...         ...   \n",
       "5326075 2018-12-31 23:35:00  n769_pressure    48.330000    pressure   \n",
       "5326076 2018-12-31 23:40:00  n769_pressure    48.330000    pressure   \n",
       "5326077 2018-12-31 23:45:00  n769_pressure    48.360000    pressure   \n",
       "5326078 2018-12-31 23:50:00  n769_pressure    48.320000    pressure   \n",
       "5326079 2018-12-31 23:55:00  n769_pressure    48.420000    pressure   \n",
       "\n",
       "                                 unique_id      entity_id measurement_type  \\\n",
       "0            n1_demand_2018-01-01 00:00:00      n1_demand           demand   \n",
       "1            n1_demand_2018-01-01 00:30:00      n1_demand           demand   \n",
       "2            n1_demand_2018-01-01 01:00:00      n1_demand           demand   \n",
       "3            n1_demand_2018-01-01 01:30:00      n1_demand           demand   \n",
       "4            n1_demand_2018-01-01 02:00:00      n1_demand           demand   \n",
       "...                                    ...            ...              ...   \n",
       "5326075  n769_pressure_2018-12-31 23:35:00  n769_pressure         pressure   \n",
       "5326076  n769_pressure_2018-12-31 23:40:00  n769_pressure         pressure   \n",
       "5326077  n769_pressure_2018-12-31 23:45:00  n769_pressure         pressure   \n",
       "5326078  n769_pressure_2018-12-31 23:50:00  n769_pressure         pressure   \n",
       "5326079  n769_pressure_2018-12-31 23:55:00  n769_pressure         pressure   \n",
       "\n",
       "        entity_type  \n",
       "0                n1  \n",
       "1                n1  \n",
       "2                n1  \n",
       "3                n1  \n",
       "4                n1  \n",
       "...             ...  \n",
       "5326075        n769  \n",
       "5326076        n769  \n",
       "5326077        n769  \n",
       "5326078        n769  \n",
       "5326079        n769  \n",
       "\n",
       "[5326080 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25f4ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes → demand\n",
    "demands_df = sensor_readings[sensor_readings['measurement_type'] == 'demand']\n",
    "demands_all = demands_df.pivot_table(index='Timestamp', columns=['entity_type'], values='measurement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45cf2c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>entity_type</th>\n",
       "      <th>n1</th>\n",
       "      <th>n10</th>\n",
       "      <th>n11</th>\n",
       "      <th>n13</th>\n",
       "      <th>n16</th>\n",
       "      <th>n17</th>\n",
       "      <th>n18</th>\n",
       "      <th>n19</th>\n",
       "      <th>n2</th>\n",
       "      <th>n20</th>\n",
       "      <th>...</th>\n",
       "      <th>n40</th>\n",
       "      <th>n41</th>\n",
       "      <th>n42</th>\n",
       "      <th>n43</th>\n",
       "      <th>n44</th>\n",
       "      <th>n45</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>n8</th>\n",
       "      <th>n9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>41.801667</td>\n",
       "      <td>42.246667</td>\n",
       "      <td>252.763333</td>\n",
       "      <td>169.983333</td>\n",
       "      <td>61.173333</td>\n",
       "      <td>268.900000</td>\n",
       "      <td>46.381667</td>\n",
       "      <td>95.145000</td>\n",
       "      <td>112.651667</td>\n",
       "      <td>106.310000</td>\n",
       "      <td>...</td>\n",
       "      <td>210.528333</td>\n",
       "      <td>89.528333</td>\n",
       "      <td>133.441667</td>\n",
       "      <td>74.175000</td>\n",
       "      <td>25.051667</td>\n",
       "      <td>217.703333</td>\n",
       "      <td>177.465000</td>\n",
       "      <td>255.903333</td>\n",
       "      <td>231.466667</td>\n",
       "      <td>262.408333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:30:00</th>\n",
       "      <td>37.711667</td>\n",
       "      <td>42.080000</td>\n",
       "      <td>272.173333</td>\n",
       "      <td>101.300000</td>\n",
       "      <td>40.010000</td>\n",
       "      <td>204.651667</td>\n",
       "      <td>42.625000</td>\n",
       "      <td>75.115000</td>\n",
       "      <td>83.136667</td>\n",
       "      <td>66.536667</td>\n",
       "      <td>...</td>\n",
       "      <td>151.203333</td>\n",
       "      <td>83.045000</td>\n",
       "      <td>123.778333</td>\n",
       "      <td>51.951667</td>\n",
       "      <td>18.488333</td>\n",
       "      <td>136.255000</td>\n",
       "      <td>135.065000</td>\n",
       "      <td>210.073333</td>\n",
       "      <td>126.196667</td>\n",
       "      <td>212.028333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>37.425000</td>\n",
       "      <td>23.261667</td>\n",
       "      <td>189.163333</td>\n",
       "      <td>91.825000</td>\n",
       "      <td>36.916667</td>\n",
       "      <td>196.053333</td>\n",
       "      <td>23.851667</td>\n",
       "      <td>51.430000</td>\n",
       "      <td>46.375000</td>\n",
       "      <td>56.936667</td>\n",
       "      <td>...</td>\n",
       "      <td>126.426667</td>\n",
       "      <td>54.695000</td>\n",
       "      <td>81.520000</td>\n",
       "      <td>48.276667</td>\n",
       "      <td>10.311667</td>\n",
       "      <td>116.596667</td>\n",
       "      <td>129.391667</td>\n",
       "      <td>165.678333</td>\n",
       "      <td>116.610000</td>\n",
       "      <td>133.613333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:30:00</th>\n",
       "      <td>41.076667</td>\n",
       "      <td>22.885000</td>\n",
       "      <td>189.800000</td>\n",
       "      <td>43.513333</td>\n",
       "      <td>34.856667</td>\n",
       "      <td>145.695000</td>\n",
       "      <td>28.040000</td>\n",
       "      <td>32.316667</td>\n",
       "      <td>51.645000</td>\n",
       "      <td>44.796667</td>\n",
       "      <td>...</td>\n",
       "      <td>57.490000</td>\n",
       "      <td>42.215000</td>\n",
       "      <td>62.923333</td>\n",
       "      <td>33.740000</td>\n",
       "      <td>11.483333</td>\n",
       "      <td>91.736667</td>\n",
       "      <td>96.156667</td>\n",
       "      <td>120.151667</td>\n",
       "      <td>115.490000</td>\n",
       "      <td>92.256667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>39.751667</td>\n",
       "      <td>14.896667</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>53.878333</td>\n",
       "      <td>34.081667</td>\n",
       "      <td>90.496667</td>\n",
       "      <td>13.090000</td>\n",
       "      <td>17.340000</td>\n",
       "      <td>40.926667</td>\n",
       "      <td>41.073333</td>\n",
       "      <td>...</td>\n",
       "      <td>91.510000</td>\n",
       "      <td>48.531667</td>\n",
       "      <td>72.335000</td>\n",
       "      <td>23.166667</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>84.108333</td>\n",
       "      <td>59.726667</td>\n",
       "      <td>54.741667</td>\n",
       "      <td>76.676667</td>\n",
       "      <td>99.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 21:30:00</th>\n",
       "      <td>214.273333</td>\n",
       "      <td>110.821667</td>\n",
       "      <td>514.861667</td>\n",
       "      <td>238.323333</td>\n",
       "      <td>87.590000</td>\n",
       "      <td>413.788333</td>\n",
       "      <td>62.458333</td>\n",
       "      <td>115.005000</td>\n",
       "      <td>130.740000</td>\n",
       "      <td>155.675000</td>\n",
       "      <td>...</td>\n",
       "      <td>294.626667</td>\n",
       "      <td>144.903333</td>\n",
       "      <td>215.978333</td>\n",
       "      <td>161.385000</td>\n",
       "      <td>29.076667</td>\n",
       "      <td>318.801667</td>\n",
       "      <td>273.091667</td>\n",
       "      <td>534.883333</td>\n",
       "      <td>394.745000</td>\n",
       "      <td>442.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 22:00:00</th>\n",
       "      <td>115.246667</td>\n",
       "      <td>105.376667</td>\n",
       "      <td>393.791667</td>\n",
       "      <td>217.011667</td>\n",
       "      <td>58.318333</td>\n",
       "      <td>468.473333</td>\n",
       "      <td>52.306667</td>\n",
       "      <td>97.768333</td>\n",
       "      <td>170.505000</td>\n",
       "      <td>108.668333</td>\n",
       "      <td>...</td>\n",
       "      <td>336.743333</td>\n",
       "      <td>111.061667</td>\n",
       "      <td>165.533333</td>\n",
       "      <td>93.121667</td>\n",
       "      <td>37.916667</td>\n",
       "      <td>222.533333</td>\n",
       "      <td>309.181667</td>\n",
       "      <td>431.168333</td>\n",
       "      <td>322.828333</td>\n",
       "      <td>519.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 22:30:00</th>\n",
       "      <td>100.130000</td>\n",
       "      <td>93.946667</td>\n",
       "      <td>463.678333</td>\n",
       "      <td>176.165000</td>\n",
       "      <td>115.300000</td>\n",
       "      <td>317.785000</td>\n",
       "      <td>57.188333</td>\n",
       "      <td>92.020000</td>\n",
       "      <td>215.485000</td>\n",
       "      <td>142.785000</td>\n",
       "      <td>...</td>\n",
       "      <td>350.755000</td>\n",
       "      <td>149.801667</td>\n",
       "      <td>223.280000</td>\n",
       "      <td>145.436667</td>\n",
       "      <td>47.916667</td>\n",
       "      <td>292.401667</td>\n",
       "      <td>209.728333</td>\n",
       "      <td>262.151667</td>\n",
       "      <td>309.735000</td>\n",
       "      <td>506.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00</th>\n",
       "      <td>86.341667</td>\n",
       "      <td>79.351667</td>\n",
       "      <td>280.090000</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>49.543333</td>\n",
       "      <td>483.565000</td>\n",
       "      <td>59.020000</td>\n",
       "      <td>123.618333</td>\n",
       "      <td>163.938333</td>\n",
       "      <td>88.136667</td>\n",
       "      <td>...</td>\n",
       "      <td>244.966667</td>\n",
       "      <td>153.910000</td>\n",
       "      <td>229.401667</td>\n",
       "      <td>78.268333</td>\n",
       "      <td>36.455000</td>\n",
       "      <td>180.486667</td>\n",
       "      <td>319.141667</td>\n",
       "      <td>279.896667</td>\n",
       "      <td>242.455000</td>\n",
       "      <td>365.876667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:30:00</th>\n",
       "      <td>162.308333</td>\n",
       "      <td>47.708333</td>\n",
       "      <td>305.051667</td>\n",
       "      <td>116.960000</td>\n",
       "      <td>48.160000</td>\n",
       "      <td>328.928333</td>\n",
       "      <td>50.813333</td>\n",
       "      <td>74.220000</td>\n",
       "      <td>118.056667</td>\n",
       "      <td>101.488333</td>\n",
       "      <td>...</td>\n",
       "      <td>223.375000</td>\n",
       "      <td>119.988333</td>\n",
       "      <td>178.845000</td>\n",
       "      <td>106.420000</td>\n",
       "      <td>26.253333</td>\n",
       "      <td>207.828333</td>\n",
       "      <td>217.085000</td>\n",
       "      <td>269.300000</td>\n",
       "      <td>182.751667</td>\n",
       "      <td>339.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17520 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "entity_type                  n1         n10         n11         n13  \\\n",
       "Timestamp                                                             \n",
       "2018-01-01 00:00:00   41.801667   42.246667  252.763333  169.983333   \n",
       "2018-01-01 00:30:00   37.711667   42.080000  272.173333  101.300000   \n",
       "2018-01-01 01:00:00   37.425000   23.261667  189.163333   91.825000   \n",
       "2018-01-01 01:30:00   41.076667   22.885000  189.800000   43.513333   \n",
       "2018-01-01 02:00:00   39.751667   14.896667  126.500000   53.878333   \n",
       "...                         ...         ...         ...         ...   \n",
       "2018-12-31 21:30:00  214.273333  110.821667  514.861667  238.323333   \n",
       "2018-12-31 22:00:00  115.246667  105.376667  393.791667  217.011667   \n",
       "2018-12-31 22:30:00  100.130000   93.946667  463.678333  176.165000   \n",
       "2018-12-31 23:00:00   86.341667   79.351667  280.090000  129.500000   \n",
       "2018-12-31 23:30:00  162.308333   47.708333  305.051667  116.960000   \n",
       "\n",
       "entity_type                 n16         n17        n18         n19  \\\n",
       "Timestamp                                                            \n",
       "2018-01-01 00:00:00   61.173333  268.900000  46.381667   95.145000   \n",
       "2018-01-01 00:30:00   40.010000  204.651667  42.625000   75.115000   \n",
       "2018-01-01 01:00:00   36.916667  196.053333  23.851667   51.430000   \n",
       "2018-01-01 01:30:00   34.856667  145.695000  28.040000   32.316667   \n",
       "2018-01-01 02:00:00   34.081667   90.496667  13.090000   17.340000   \n",
       "...                         ...         ...        ...         ...   \n",
       "2018-12-31 21:30:00   87.590000  413.788333  62.458333  115.005000   \n",
       "2018-12-31 22:00:00   58.318333  468.473333  52.306667   97.768333   \n",
       "2018-12-31 22:30:00  115.300000  317.785000  57.188333   92.020000   \n",
       "2018-12-31 23:00:00   49.543333  483.565000  59.020000  123.618333   \n",
       "2018-12-31 23:30:00   48.160000  328.928333  50.813333   74.220000   \n",
       "\n",
       "entity_type                  n2         n20  ...         n40         n41  \\\n",
       "Timestamp                                    ...                           \n",
       "2018-01-01 00:00:00  112.651667  106.310000  ...  210.528333   89.528333   \n",
       "2018-01-01 00:30:00   83.136667   66.536667  ...  151.203333   83.045000   \n",
       "2018-01-01 01:00:00   46.375000   56.936667  ...  126.426667   54.695000   \n",
       "2018-01-01 01:30:00   51.645000   44.796667  ...   57.490000   42.215000   \n",
       "2018-01-01 02:00:00   40.926667   41.073333  ...   91.510000   48.531667   \n",
       "...                         ...         ...  ...         ...         ...   \n",
       "2018-12-31 21:30:00  130.740000  155.675000  ...  294.626667  144.903333   \n",
       "2018-12-31 22:00:00  170.505000  108.668333  ...  336.743333  111.061667   \n",
       "2018-12-31 22:30:00  215.485000  142.785000  ...  350.755000  149.801667   \n",
       "2018-12-31 23:00:00  163.938333   88.136667  ...  244.966667  153.910000   \n",
       "2018-12-31 23:30:00  118.056667  101.488333  ...  223.375000  119.988333   \n",
       "\n",
       "entity_type                 n42         n43        n44         n45  \\\n",
       "Timestamp                                                            \n",
       "2018-01-01 00:00:00  133.441667   74.175000  25.051667  217.703333   \n",
       "2018-01-01 00:30:00  123.778333   51.951667  18.488333  136.255000   \n",
       "2018-01-01 01:00:00   81.520000   48.276667  10.311667  116.596667   \n",
       "2018-01-01 01:30:00   62.923333   33.740000  11.483333   91.736667   \n",
       "2018-01-01 02:00:00   72.335000   23.166667   9.100000   84.108333   \n",
       "...                         ...         ...        ...         ...   \n",
       "2018-12-31 21:30:00  215.978333  161.385000  29.076667  318.801667   \n",
       "2018-12-31 22:00:00  165.533333   93.121667  37.916667  222.533333   \n",
       "2018-12-31 22:30:00  223.280000  145.436667  47.916667  292.401667   \n",
       "2018-12-31 23:00:00  229.401667   78.268333  36.455000  180.486667   \n",
       "2018-12-31 23:30:00  178.845000  106.420000  26.253333  207.828333   \n",
       "\n",
       "entity_type                  n6          n7          n8          n9  \n",
       "Timestamp                                                            \n",
       "2018-01-01 00:00:00  177.465000  255.903333  231.466667  262.408333  \n",
       "2018-01-01 00:30:00  135.065000  210.073333  126.196667  212.028333  \n",
       "2018-01-01 01:00:00  129.391667  165.678333  116.610000  133.613333  \n",
       "2018-01-01 01:30:00   96.156667  120.151667  115.490000   92.256667  \n",
       "2018-01-01 02:00:00   59.726667   54.741667   76.676667   99.265000  \n",
       "...                         ...         ...         ...         ...  \n",
       "2018-12-31 21:30:00  273.091667  534.883333  394.745000  442.275000  \n",
       "2018-12-31 22:00:00  309.181667  431.168333  322.828333  519.708333  \n",
       "2018-12-31 22:30:00  209.728333  262.151667  309.735000  506.728333  \n",
       "2018-12-31 23:00:00  319.141667  279.896667  242.455000  365.876667  \n",
       "2018-12-31 23:30:00  217.085000  269.300000  182.751667  339.525000  \n",
       "\n",
       "[17520 rows x 82 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demands_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9516f9a",
   "metadata": {},
   "source": [
    "### Separate data by feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2e6d5f",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1970086",
   "metadata": {},
   "source": [
    "### Split train/val, and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d064d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "import joblib\n",
    "\n",
    "def split_scale(measurements, feature, cluster):\n",
    "\n",
    "    # Step 1: Split the full data into train and validation sets\n",
    "    X_train_full, X_val_full = train_test_split(measurements, test_size=0.2, shuffle = False, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform training data\n",
    "    X_train_full_scaled = X_train_full.copy()\n",
    "    X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
    "    X_train_full_scaled = pd.DataFrame(X_train_full_scaled, columns=X_train_full.columns, index=X_train_full.index)\n",
    "\n",
    "    # Save scaler with specific name for later rescaling\n",
    "    joblib.dump(scaler, f\"{feature}_scaler_{cluster}.pkl\")\n",
    "\n",
    "    # Now, apply ONLY transformation (not fitting) on val data\n",
    "    X_val_full_scaled = X_val_full.copy()\n",
    "    X_val_full_scaled = scaler.transform(X_val_full)\n",
    "    X_val_full_scaled = pd.DataFrame(X_val_full_scaled, columns=X_val_full.columns, index=X_val_full.index)\n",
    "\n",
    "    return X_train_full_scaled, X_val_full_scaled, X_train_full, X_val_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd95d1",
   "metadata": {},
   "source": [
    "### Select semantically relevant pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a094a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "demands_c0 = demands_all[['n1', 'n10', 'n16', 'n19', 'n2', 'n22', 'n29', 'n3', 'n32', 'n345', 'n346', 'n347', 'n349', 'n350', 'n352', 'n354', 'n357', 'n362', 'n368', 'n371', 'n374', 'n375', 'n376', 'n378', 'n379', 'n382', 'n383', 'n384', 'n41']]\n",
    "demands_c1 = demands_all[[\"n11\", \"n13\", \"n17\", \"n355\", \"n360\", \"n386\", \"n388\", \"n40\", \"n42\", \"n45\", \"n8\"]]\n",
    "demands_c2 = demands_all[['n30', 'n344', 'n351', 'n353', 'n358', 'n36', 'n381', 'n6', 'n7', 'n9']]\n",
    "demands_c3 = demands_all[[\"n18\", \"n20\", \"n21\", \"n23\", \"n24\", \"n25\", \"n26\", \"n27\", \"n28\", \"n31\", \"n33\", \"n34\", \"n343\", \"n35\", \"n356\", \"n361\", \"n364\", \"n365\", \"n366\", \"n367\", \"n369\", \"n370\", \"n372\", \"n373\", \"n377\", \"n385\", \"n387\", \"n389\", \"n39\", \"n4\", \"n43\", \"n44\"]]\n",
    "\n",
    "\n",
    "# Initialize the containers\n",
    "X_train_full_scaled = {}\n",
    "X_val_full_scaled = {}\n",
    "X_train_full_unscaled = {}\n",
    "X_val_full_unscaled = {}\n",
    "clusters = [demands_c0, demands_c1, demands_c2, demands_c3, demands_all]\n",
    "\n",
    "# Iterate over the clusters\n",
    "for i, flow_cluster in enumerate(clusters):\n",
    "    X_train_full_scaled[i], X_val_full_scaled[i], X_train_full_unscaled[i], X_val_full_unscaled[i] = split_scale(flow_cluster, \"demand\", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60660cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>entity_type</th>\n",
       "      <th>n11</th>\n",
       "      <th>n13</th>\n",
       "      <th>n17</th>\n",
       "      <th>n355</th>\n",
       "      <th>n360</th>\n",
       "      <th>n386</th>\n",
       "      <th>n388</th>\n",
       "      <th>n40</th>\n",
       "      <th>n42</th>\n",
       "      <th>n45</th>\n",
       "      <th>n8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>252.763333</td>\n",
       "      <td>169.983333</td>\n",
       "      <td>268.900000</td>\n",
       "      <td>144.061667</td>\n",
       "      <td>163.010000</td>\n",
       "      <td>178.736667</td>\n",
       "      <td>307.150000</td>\n",
       "      <td>210.528333</td>\n",
       "      <td>133.441667</td>\n",
       "      <td>217.703333</td>\n",
       "      <td>231.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:30:00</th>\n",
       "      <td>272.173333</td>\n",
       "      <td>101.300000</td>\n",
       "      <td>204.651667</td>\n",
       "      <td>233.173333</td>\n",
       "      <td>117.076667</td>\n",
       "      <td>115.551667</td>\n",
       "      <td>252.593333</td>\n",
       "      <td>151.203333</td>\n",
       "      <td>123.778333</td>\n",
       "      <td>136.255000</td>\n",
       "      <td>126.196667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>189.163333</td>\n",
       "      <td>91.825000</td>\n",
       "      <td>196.053333</td>\n",
       "      <td>182.311667</td>\n",
       "      <td>97.891667</td>\n",
       "      <td>79.065000</td>\n",
       "      <td>205.691667</td>\n",
       "      <td>126.426667</td>\n",
       "      <td>81.520000</td>\n",
       "      <td>116.596667</td>\n",
       "      <td>116.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:30:00</th>\n",
       "      <td>189.800000</td>\n",
       "      <td>43.513333</td>\n",
       "      <td>145.695000</td>\n",
       "      <td>106.415000</td>\n",
       "      <td>44.513333</td>\n",
       "      <td>107.911667</td>\n",
       "      <td>157.490000</td>\n",
       "      <td>57.490000</td>\n",
       "      <td>62.923333</td>\n",
       "      <td>91.736667</td>\n",
       "      <td>115.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>126.500000</td>\n",
       "      <td>53.878333</td>\n",
       "      <td>90.496667</td>\n",
       "      <td>76.330000</td>\n",
       "      <td>70.858333</td>\n",
       "      <td>92.508333</td>\n",
       "      <td>108.628333</td>\n",
       "      <td>91.510000</td>\n",
       "      <td>72.335000</td>\n",
       "      <td>84.108333</td>\n",
       "      <td>76.676667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19 21:30:00</th>\n",
       "      <td>567.195000</td>\n",
       "      <td>266.296667</td>\n",
       "      <td>430.823333</td>\n",
       "      <td>515.263333</td>\n",
       "      <td>244.650000</td>\n",
       "      <td>288.431667</td>\n",
       "      <td>443.606667</td>\n",
       "      <td>315.965000</td>\n",
       "      <td>347.305000</td>\n",
       "      <td>186.545000</td>\n",
       "      <td>138.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19 22:00:00</th>\n",
       "      <td>475.620000</td>\n",
       "      <td>211.653333</td>\n",
       "      <td>432.701667</td>\n",
       "      <td>401.605000</td>\n",
       "      <td>242.830000</td>\n",
       "      <td>307.023333</td>\n",
       "      <td>471.475000</td>\n",
       "      <td>313.611667</td>\n",
       "      <td>260.241667</td>\n",
       "      <td>177.061667</td>\n",
       "      <td>223.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19 22:30:00</th>\n",
       "      <td>391.000000</td>\n",
       "      <td>170.551667</td>\n",
       "      <td>308.111667</td>\n",
       "      <td>219.138333</td>\n",
       "      <td>248.690000</td>\n",
       "      <td>263.465000</td>\n",
       "      <td>394.298333</td>\n",
       "      <td>321.186667</td>\n",
       "      <td>179.930000</td>\n",
       "      <td>183.028333</td>\n",
       "      <td>252.631667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19 23:00:00</th>\n",
       "      <td>325.661667</td>\n",
       "      <td>179.190000</td>\n",
       "      <td>359.870000</td>\n",
       "      <td>462.121667</td>\n",
       "      <td>193.123333</td>\n",
       "      <td>248.146667</td>\n",
       "      <td>446.995000</td>\n",
       "      <td>249.420000</td>\n",
       "      <td>227.778333</td>\n",
       "      <td>136.183333</td>\n",
       "      <td>283.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19 23:30:00</th>\n",
       "      <td>292.276667</td>\n",
       "      <td>143.980000</td>\n",
       "      <td>281.753333</td>\n",
       "      <td>410.721667</td>\n",
       "      <td>234.463333</td>\n",
       "      <td>184.536667</td>\n",
       "      <td>328.713333</td>\n",
       "      <td>302.810000</td>\n",
       "      <td>136.246667</td>\n",
       "      <td>206.191667</td>\n",
       "      <td>234.481667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14016 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "entity_type                 n11         n13         n17        n355  \\\n",
       "Timestamp                                                             \n",
       "2018-01-01 00:00:00  252.763333  169.983333  268.900000  144.061667   \n",
       "2018-01-01 00:30:00  272.173333  101.300000  204.651667  233.173333   \n",
       "2018-01-01 01:00:00  189.163333   91.825000  196.053333  182.311667   \n",
       "2018-01-01 01:30:00  189.800000   43.513333  145.695000  106.415000   \n",
       "2018-01-01 02:00:00  126.500000   53.878333   90.496667   76.330000   \n",
       "...                         ...         ...         ...         ...   \n",
       "2018-10-19 21:30:00  567.195000  266.296667  430.823333  515.263333   \n",
       "2018-10-19 22:00:00  475.620000  211.653333  432.701667  401.605000   \n",
       "2018-10-19 22:30:00  391.000000  170.551667  308.111667  219.138333   \n",
       "2018-10-19 23:00:00  325.661667  179.190000  359.870000  462.121667   \n",
       "2018-10-19 23:30:00  292.276667  143.980000  281.753333  410.721667   \n",
       "\n",
       "entity_type                n360        n386        n388         n40  \\\n",
       "Timestamp                                                             \n",
       "2018-01-01 00:00:00  163.010000  178.736667  307.150000  210.528333   \n",
       "2018-01-01 00:30:00  117.076667  115.551667  252.593333  151.203333   \n",
       "2018-01-01 01:00:00   97.891667   79.065000  205.691667  126.426667   \n",
       "2018-01-01 01:30:00   44.513333  107.911667  157.490000   57.490000   \n",
       "2018-01-01 02:00:00   70.858333   92.508333  108.628333   91.510000   \n",
       "...                         ...         ...         ...         ...   \n",
       "2018-10-19 21:30:00  244.650000  288.431667  443.606667  315.965000   \n",
       "2018-10-19 22:00:00  242.830000  307.023333  471.475000  313.611667   \n",
       "2018-10-19 22:30:00  248.690000  263.465000  394.298333  321.186667   \n",
       "2018-10-19 23:00:00  193.123333  248.146667  446.995000  249.420000   \n",
       "2018-10-19 23:30:00  234.463333  184.536667  328.713333  302.810000   \n",
       "\n",
       "entity_type                 n42         n45          n8  \n",
       "Timestamp                                                \n",
       "2018-01-01 00:00:00  133.441667  217.703333  231.466667  \n",
       "2018-01-01 00:30:00  123.778333  136.255000  126.196667  \n",
       "2018-01-01 01:00:00   81.520000  116.596667  116.610000  \n",
       "2018-01-01 01:30:00   62.923333   91.736667  115.490000  \n",
       "2018-01-01 02:00:00   72.335000   84.108333   76.676667  \n",
       "...                         ...         ...         ...  \n",
       "2018-10-19 21:30:00  347.305000  186.545000  138.800000  \n",
       "2018-10-19 22:00:00  260.241667  177.061667  223.646667  \n",
       "2018-10-19 22:30:00  179.930000  183.028333  252.631667  \n",
       "2018-10-19 23:00:00  227.778333  136.183333  283.435000  \n",
       "2018-10-19 23:30:00  136.246667  206.191667  234.481667  \n",
       "\n",
       "[14016 rows x 11 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full_unscaled[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b21b29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_3d(data, window_size, stride):\n",
    "    \"\"\"\n",
    "    Converts a long time series [1, T, F] into [N, window_size, F]\n",
    "    \"\"\"\n",
    "    data = data.squeeze(0)  # [T, F]\n",
    "    total_steps, n_features = data.shape\n",
    "    windows = []\n",
    "\n",
    "    for i in range(0, total_steps - window_size + 1, stride):\n",
    "        window = data[i:i+window_size]\n",
    "        windows.append(window)\n",
    "\n",
    "    return np.stack(windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9caad",
   "metadata": {},
   "source": [
    "### Introduce MCAR Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3fa6cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing 5.0% missingness for cluster 0 with key 5\n",
      "Introducing 20.0% missingness for cluster 0 with key 20\n",
      "Introducing 60.0% missingness for cluster 0 with key 60\n",
      "Introducing 99.0% missingness for cluster 0 with key 99\n",
      "Introducing 5.0% missingness for cluster 1 with key 5\n",
      "Introducing 20.0% missingness for cluster 1 with key 20\n",
      "Introducing 60.0% missingness for cluster 1 with key 60\n",
      "Introducing 99.0% missingness for cluster 1 with key 99\n",
      "Introducing 5.0% missingness for cluster 2 with key 5\n",
      "Introducing 20.0% missingness for cluster 2 with key 20\n",
      "Introducing 60.0% missingness for cluster 2 with key 60\n",
      "Introducing 99.0% missingness for cluster 2 with key 99\n",
      "Introducing 5.0% missingness for cluster 3 with key 5\n",
      "Introducing 20.0% missingness for cluster 3 with key 20\n",
      "Introducing 60.0% missingness for cluster 3 with key 60\n",
      "Introducing 99.0% missingness for cluster 3 with key 99\n",
      "Introducing 5.0% missingness for cluster 4 with key 5\n",
      "Introducing 20.0% missingness for cluster 4 with key 20\n",
      "Introducing 60.0% missingness for cluster 4 with key 60\n",
      "Introducing 99.0% missingness for cluster 4 with key 99\n"
     ]
    }
   ],
   "source": [
    "from pygrinder import mar_logistic\n",
    "\n",
    "missing_rates = [0.05, 0.2, 0.6, 0.99]\n",
    "\n",
    "# Training and validation sets for each cluster\n",
    "X_train_incomplete = {}\n",
    "X_val_incomplete = {}\n",
    "train_masks = {}\n",
    "val_masks = {}\n",
    "X_train_seq = {}\n",
    "X_val_seq = {}\n",
    "train_masks_seq = {}\n",
    "val_masks_seq = {}\n",
    "\n",
    "# Full tensors for each cluster\n",
    "X_train_full_tensor = {}\n",
    "X_val_full_tensor = {}\n",
    "X_val_full_seq = {}\n",
    "X_train_full_seq = {}\n",
    "X_train_full_unscaled_seq_tensor = {}\n",
    "X_val_full_unscaled_seq_tensor = {}\n",
    "\n",
    "# Define sliding window parameters\n",
    "n_steps = 168 # 3.5 days each window\n",
    "stride = 48 # 1 day stride\n",
    "\n",
    "for cluster_id, flow_cluster in enumerate(clusters):\n",
    "    X_train_incomplete[cluster_id] = {}\n",
    "    X_val_incomplete[cluster_id] = {}\n",
    "    train_masks[cluster_id] = {}\n",
    "    val_masks[cluster_id] = {}\n",
    "    X_train_seq[cluster_id] = {}\n",
    "    X_val_seq[cluster_id] = {}\n",
    "    train_masks_seq[cluster_id] = {}\n",
    "    val_masks_seq[cluster_id] = {}\n",
    "\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        # Introduce missingness per cluster & rate\n",
    "        print(f\"Introducing {rate*100}% missingness for cluster {cluster_id} with key {key}\")\n",
    "        X_train_incomplete[cluster_id][key] = mar_logistic(X_train_full_scaled[cluster_id].values, obs_rate = 0.4, missing_rate=rate)\n",
    "        X_val_incomplete[cluster_id][key] = mar_logistic(X_val_full_scaled[cluster_id].values, obs_rate = 0.4, missing_rate=rate)\n",
    "\n",
    "        # Masks for missingness\n",
    "        train_masks[cluster_id][key] = np.isnan(X_train_incomplete[cluster_id][key])\n",
    "        val_masks[cluster_id][key] = np.isnan(X_val_incomplete[cluster_id][key])\n",
    "\n",
    "        # Expand dims for batch axis (needed for sliding window)\n",
    "        X_train_tensor = np.expand_dims(X_train_incomplete[cluster_id][key], axis=0)\n",
    "        X_val_tensor = np.expand_dims(X_val_incomplete[cluster_id][key], axis=0)\n",
    "        train_mask_tensor = np.expand_dims(train_masks[cluster_id][key], axis=0)\n",
    "        val_mask_tensor = np.expand_dims(val_masks[cluster_id][key], axis=0)\n",
    "\n",
    "        # Sliding window on data\n",
    "        X_train_seq[cluster_id][key] = sliding_window_3d(X_train_tensor, window_size=n_steps, stride=stride)\n",
    "        X_val_seq[cluster_id][key] = sliding_window_3d(X_val_tensor, window_size=n_steps, stride=stride)\n",
    "\n",
    "        # Sliding window on masks\n",
    "        train_masks_seq[cluster_id][key] = sliding_window_3d(train_mask_tensor, window_size=n_steps, stride=stride)\n",
    "        val_masks_seq[cluster_id][key] = sliding_window_3d(val_mask_tensor, window_size=n_steps, stride=stride)\n",
    "\n",
    "\n",
    "    # Expand full training tensors\n",
    "    X_train_full_tensor[cluster_id] = np.expand_dims(X_train_full_scaled[cluster_id].values, axis = 0)\n",
    "\n",
    "    # Expand full validation tensors\n",
    "    X_val_full_tensor[cluster_id] = np.expand_dims(X_val_full_scaled[cluster_id].values, axis = 0)\n",
    "\n",
    "    # Convert scaled data to tensor\n",
    "    X_val_full_seq[cluster_id] = sliding_window_3d(X_val_full_tensor[cluster_id], window_size=n_steps, stride=stride)\n",
    "    X_train_full_seq[cluster_id] = sliding_window_3d(X_train_full_tensor[cluster_id], window_size=n_steps, stride=stride)\n",
    "\n",
    "    # Convert unscaled data to tensor\n",
    "    X_train_full_unscaled_values = np.expand_dims(X_train_full_unscaled[cluster_id].values, axis=0)\n",
    "    X_train_full_unscaled_seq_tensor[cluster_id] = sliding_window_3d(X_train_full_unscaled_values, window_size=n_steps, stride=stride)\n",
    "\n",
    "    X_val_full_unscaled_values = np.expand_dims(X_val_full_unscaled[cluster_id].values, axis=0)\n",
    "    X_val_full_unscaled_seq_tensor[cluster_id] = sliding_window_3d(X_val_full_unscaled_values, window_size=n_steps, stride=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "033d88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare the final datasets with 'X' (incomplete) and 'X_ori' (full data)\n",
    "\n",
    "# 20 percent missing\n",
    "train_data, val_data = {}, {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    train_data[cluster_id] = {}\n",
    "    val_data[cluster_id] = {}\n",
    "    \n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        \n",
    "        # Prepare the train and validation data dictionaries for each missing rate\n",
    "        train_data[cluster_id][key] = {\"X\": X_train_seq[cluster_id][key]}\n",
    "        val_data[cluster_id][key] = {\"X\": X_val_seq[cluster_id][key], \"X_ori\": X_val_full_seq[cluster_id]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9babf5e8",
   "metadata": {},
   "source": [
    "## BRITS IMputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "732a2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypots.imputation import BRITS\n",
    "from pypots.nn.modules.loss import MAE, MSE\n",
    "from pypots.optim.adam import Adam\n",
    "import torch\n",
    "\n",
    "def intialize_BRITS(n_steps, num_features, rnn_hidden_size):\n",
    "\n",
    "    # Basic configuration\n",
    "    model = BRITS(\n",
    "        n_steps=n_steps,\n",
    "        n_features=num_features,\n",
    "        rnn_hidden_size=rnn_hidden_size,               # Reasonable hidden size\n",
    "        batch_size=32,                    # Standard for most datasets\n",
    "        epochs=25,                       # Higher epochs for better convergence\n",
    "        patience=5,                      # Early stopping if no improvement\n",
    "        training_loss=MAE,                # MAE often performs well for imputation\n",
    "        validation_metric=MSE,           # Use MSE for validation comparison\n",
    "        optimizer=Adam,                   # Adam optimizer (default)\n",
    "        num_workers=0,                    # Adjust if using DataLoader with multiprocessing\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # Use GPU if available\n",
    "        saving_path=\"./brits_model\",     # Directory to save model checkpoints\n",
    "        model_saving_strategy=\"best\",    # Save best model only\n",
    "        verbose=True                      # Print training progress\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61fd877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 23:51:54 [INFO]: Using the given device: cpu\n",
      "2025-06-24 23:51:54 [INFO]: Model files will be saved to ./brits_model\\20250624_T235154\n",
      "2025-06-24 23:51:54 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T235154\\tensorboard\n",
      "2025-06-24 23:51:54 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 23:51:54 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 23:51:54 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 18,576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 0...\n",
      "Training model for missing rate 0.05 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 23:52:03 [INFO]: Epoch 001 - training loss (MAE): 1.6298, validation MSE: 0.8784\n",
      "2025-06-24 23:52:09 [INFO]: Epoch 002 - training loss (MAE): 1.4395, validation MSE: 0.5967\n",
      "2025-06-24 23:52:15 [INFO]: Epoch 003 - training loss (MAE): 1.2843, validation MSE: 0.4057\n",
      "2025-06-24 23:52:21 [INFO]: Epoch 004 - training loss (MAE): 1.1236, validation MSE: 0.3083\n",
      "2025-06-24 23:52:27 [INFO]: Epoch 005 - training loss (MAE): 1.0380, validation MSE: 0.2751\n",
      "2025-06-24 23:52:33 [INFO]: Epoch 006 - training loss (MAE): 0.9815, validation MSE: 0.2604\n",
      "2025-06-24 23:52:39 [INFO]: Epoch 007 - training loss (MAE): 0.9051, validation MSE: 0.2492\n",
      "2025-06-24 23:52:45 [INFO]: Epoch 008 - training loss (MAE): 0.8724, validation MSE: 0.2438\n",
      "2025-06-24 23:52:50 [INFO]: Epoch 009 - training loss (MAE): 0.8345, validation MSE: 0.2412\n",
      "2025-06-24 23:52:56 [INFO]: Epoch 010 - training loss (MAE): 0.8003, validation MSE: 0.2378\n",
      "2025-06-24 23:53:02 [INFO]: Epoch 011 - training loss (MAE): 0.7900, validation MSE: 0.2356\n",
      "2025-06-24 23:53:07 [INFO]: Epoch 012 - training loss (MAE): 0.7694, validation MSE: 0.2337\n",
      "2025-06-24 23:53:13 [INFO]: Epoch 013 - training loss (MAE): 0.7720, validation MSE: 0.2326\n",
      "2025-06-24 23:53:19 [INFO]: Epoch 014 - training loss (MAE): 0.7513, validation MSE: 0.2318\n",
      "2025-06-24 23:53:25 [INFO]: Epoch 015 - training loss (MAE): 0.7420, validation MSE: 0.2296\n",
      "2025-06-24 23:53:31 [INFO]: Epoch 016 - training loss (MAE): 0.7397, validation MSE: 0.2277\n",
      "2025-06-24 23:53:36 [INFO]: Epoch 017 - training loss (MAE): 0.7238, validation MSE: 0.2269\n",
      "2025-06-24 23:53:41 [INFO]: Epoch 018 - training loss (MAE): 0.7243, validation MSE: 0.2256\n",
      "2025-06-24 23:53:46 [INFO]: Epoch 019 - training loss (MAE): 0.7099, validation MSE: 0.2231\n",
      "2025-06-24 23:53:52 [INFO]: Epoch 020 - training loss (MAE): 0.7018, validation MSE: 0.2221\n",
      "2025-06-24 23:53:59 [INFO]: Epoch 021 - training loss (MAE): 0.7017, validation MSE: 0.2206\n",
      "2025-06-24 23:54:06 [INFO]: Epoch 022 - training loss (MAE): 0.6905, validation MSE: 0.2186\n",
      "2025-06-24 23:54:12 [INFO]: Epoch 023 - training loss (MAE): 0.6948, validation MSE: 0.2172\n",
      "2025-06-24 23:54:18 [INFO]: Epoch 024 - training loss (MAE): 0.6871, validation MSE: 0.2166\n",
      "2025-06-24 23:54:25 [INFO]: Epoch 025 - training loss (MAE): 0.6772, validation MSE: 0.2155\n",
      "2025-06-24 23:54:25 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 23:54:25 [INFO]: Saved the model to ./brits_model\\20250624_T235154\\BRITS.pypots\n",
      "2025-06-24 23:54:25 [INFO]: Using the given device: cpu\n",
      "2025-06-24 23:54:25 [INFO]: Model files will be saved to ./brits_model\\20250624_T235425\n",
      "2025-06-24 23:54:25 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T235425\\tensorboard\n",
      "2025-06-24 23:54:25 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 23:54:25 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 23:54:25 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 18,576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 23:54:35 [INFO]: Epoch 001 - training loss (MAE): 1.7391, validation MSE: 0.7724\n",
      "2025-06-24 23:54:42 [INFO]: Epoch 002 - training loss (MAE): 1.5372, validation MSE: 0.5490\n",
      "2025-06-24 23:54:50 [INFO]: Epoch 003 - training loss (MAE): 1.3597, validation MSE: 0.3891\n",
      "2025-06-24 23:54:58 [INFO]: Epoch 004 - training loss (MAE): 1.2222, validation MSE: 0.2914\n",
      "2025-06-24 23:55:05 [INFO]: Epoch 005 - training loss (MAE): 1.1004, validation MSE: 0.2364\n",
      "2025-06-24 23:55:13 [INFO]: Epoch 006 - training loss (MAE): 1.0056, validation MSE: 0.2071\n",
      "2025-06-24 23:55:20 [INFO]: Epoch 007 - training loss (MAE): 0.9429, validation MSE: 0.1936\n",
      "2025-06-24 23:55:28 [INFO]: Epoch 008 - training loss (MAE): 0.8883, validation MSE: 0.1875\n",
      "2025-06-24 23:55:37 [INFO]: Epoch 009 - training loss (MAE): 0.8441, validation MSE: 0.1831\n",
      "2025-06-24 23:55:45 [INFO]: Epoch 010 - training loss (MAE): 0.8156, validation MSE: 0.1801\n",
      "2025-06-24 23:55:53 [INFO]: Epoch 011 - training loss (MAE): 0.7906, validation MSE: 0.1778\n",
      "2025-06-24 23:56:01 [INFO]: Epoch 012 - training loss (MAE): 0.7799, validation MSE: 0.1761\n",
      "2025-06-24 23:56:10 [INFO]: Epoch 013 - training loss (MAE): 0.7827, validation MSE: 0.1748\n",
      "2025-06-24 23:56:18 [INFO]: Epoch 014 - training loss (MAE): 0.7710, validation MSE: 0.1736\n",
      "2025-06-24 23:56:25 [INFO]: Epoch 015 - training loss (MAE): 0.7475, validation MSE: 0.1723\n",
      "2025-06-24 23:56:31 [INFO]: Epoch 016 - training loss (MAE): 0.7469, validation MSE: 0.1712\n",
      "2025-06-24 23:56:37 [INFO]: Epoch 017 - training loss (MAE): 0.7340, validation MSE: 0.1704\n",
      "2025-06-24 23:56:43 [INFO]: Epoch 018 - training loss (MAE): 0.7351, validation MSE: 0.1695\n",
      "2025-06-24 23:56:49 [INFO]: Epoch 019 - training loss (MAE): 0.7277, validation MSE: 0.1688\n",
      "2025-06-24 23:56:54 [INFO]: Epoch 020 - training loss (MAE): 0.7133, validation MSE: 0.1677\n",
      "2025-06-24 23:57:01 [INFO]: Epoch 021 - training loss (MAE): 0.7184, validation MSE: 0.1669\n",
      "2025-06-24 23:57:07 [INFO]: Epoch 022 - training loss (MAE): 0.7055, validation MSE: 0.1655\n",
      "2025-06-24 23:57:14 [INFO]: Epoch 023 - training loss (MAE): 0.7162, validation MSE: 0.1649\n",
      "2025-06-24 23:57:21 [INFO]: Epoch 024 - training loss (MAE): 0.7069, validation MSE: 0.1643\n",
      "2025-06-24 23:57:29 [INFO]: Epoch 025 - training loss (MAE): 0.7050, validation MSE: 0.1637\n",
      "2025-06-24 23:57:29 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-24 23:57:29 [INFO]: Saved the model to ./brits_model\\20250624_T235425\\BRITS.pypots\n",
      "2025-06-24 23:57:29 [INFO]: Using the given device: cpu\n",
      "2025-06-24 23:57:29 [INFO]: Model files will be saved to ./brits_model\\20250624_T235729\n",
      "2025-06-24 23:57:29 [INFO]: Tensorboard file will be saved to ./brits_model\\20250624_T235729\\tensorboard\n",
      "2025-06-24 23:57:29 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-24 23:57:29 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-24 23:57:29 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 18,576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 23:57:39 [INFO]: Epoch 001 - training loss (MAE): 1.6759, validation MSE: 0.8601\n",
      "2025-06-24 23:57:48 [INFO]: Epoch 002 - training loss (MAE): 1.5057, validation MSE: 0.6957\n",
      "2025-06-24 23:57:56 [INFO]: Epoch 003 - training loss (MAE): 1.3674, validation MSE: 0.5475\n",
      "2025-06-24 23:58:05 [INFO]: Epoch 004 - training loss (MAE): 1.2129, validation MSE: 0.4268\n",
      "2025-06-24 23:58:13 [INFO]: Epoch 005 - training loss (MAE): 1.0892, validation MSE: 0.3489\n",
      "2025-06-24 23:58:20 [INFO]: Epoch 006 - training loss (MAE): 1.0135, validation MSE: 0.3100\n",
      "2025-06-24 23:58:27 [INFO]: Epoch 007 - training loss (MAE): 0.9394, validation MSE: 0.2855\n",
      "2025-06-24 23:58:34 [INFO]: Epoch 008 - training loss (MAE): 0.9052, validation MSE: 0.2708\n",
      "2025-06-24 23:58:42 [INFO]: Epoch 009 - training loss (MAE): 0.8719, validation MSE: 0.2605\n",
      "2025-06-24 23:58:49 [INFO]: Epoch 010 - training loss (MAE): 0.8335, validation MSE: 0.2520\n",
      "2025-06-24 23:58:56 [INFO]: Epoch 011 - training loss (MAE): 0.8148, validation MSE: 0.2440\n",
      "2025-06-24 23:59:03 [INFO]: Epoch 012 - training loss (MAE): 0.7807, validation MSE: 0.2386\n",
      "2025-06-24 23:59:11 [INFO]: Epoch 013 - training loss (MAE): 0.7631, validation MSE: 0.2329\n",
      "2025-06-24 23:59:18 [INFO]: Epoch 014 - training loss (MAE): 0.7487, validation MSE: 0.2289\n",
      "2025-06-24 23:59:25 [INFO]: Epoch 015 - training loss (MAE): 0.7401, validation MSE: 0.2236\n",
      "2025-06-24 23:59:32 [INFO]: Epoch 016 - training loss (MAE): 0.7413, validation MSE: 0.2208\n",
      "2025-06-24 23:59:40 [INFO]: Epoch 017 - training loss (MAE): 0.7251, validation MSE: 0.2178\n",
      "2025-06-24 23:59:47 [INFO]: Epoch 018 - training loss (MAE): 0.7206, validation MSE: 0.2153\n",
      "2025-06-24 23:59:54 [INFO]: Epoch 019 - training loss (MAE): 0.7083, validation MSE: 0.2136\n",
      "2025-06-25 00:00:02 [INFO]: Epoch 020 - training loss (MAE): 0.7142, validation MSE: 0.2130\n",
      "2025-06-25 00:00:09 [INFO]: Epoch 021 - training loss (MAE): 0.6929, validation MSE: 0.2109\n",
      "2025-06-25 00:00:16 [INFO]: Epoch 022 - training loss (MAE): 0.7111, validation MSE: 0.2116\n",
      "2025-06-25 00:00:23 [INFO]: Epoch 023 - training loss (MAE): 0.6951, validation MSE: 0.2076\n",
      "2025-06-25 00:00:30 [INFO]: Epoch 024 - training loss (MAE): 0.6947, validation MSE: 0.2073\n",
      "2025-06-25 00:00:37 [INFO]: Epoch 025 - training loss (MAE): 0.6836, validation MSE: 0.2063\n",
      "2025-06-25 00:00:37 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:00:37 [INFO]: Saved the model to ./brits_model\\20250624_T235729\\BRITS.pypots\n",
      "2025-06-25 00:00:37 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:00:37 [INFO]: Model files will be saved to ./brits_model\\20250625_T000037\n",
      "2025-06-25 00:00:37 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T000037\\tensorboard\n",
      "2025-06-25 00:00:37 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:00:37 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:00:37 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 18,576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.99 in cluster 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:00:48 [INFO]: Epoch 001 - training loss (MAE): 1.7703, validation MSE: 0.8748\n",
      "2025-06-25 00:00:55 [INFO]: Epoch 002 - training loss (MAE): 1.6234, validation MSE: 0.8510\n",
      "2025-06-25 00:01:02 [INFO]: Epoch 003 - training loss (MAE): 1.4683, validation MSE: 0.8214\n",
      "2025-06-25 00:01:09 [INFO]: Epoch 004 - training loss (MAE): 1.3343, validation MSE: 0.7737\n",
      "2025-06-25 00:01:16 [INFO]: Epoch 005 - training loss (MAE): 1.1403, validation MSE: 0.7143\n",
      "2025-06-25 00:01:23 [INFO]: Epoch 006 - training loss (MAE): 1.0050, validation MSE: 0.6795\n",
      "2025-06-25 00:01:30 [INFO]: Epoch 007 - training loss (MAE): 0.9296, validation MSE: 0.6481\n",
      "2025-06-25 00:01:37 [INFO]: Epoch 008 - training loss (MAE): 0.8615, validation MSE: 0.6149\n",
      "2025-06-25 00:01:44 [INFO]: Epoch 009 - training loss (MAE): 0.8030, validation MSE: 0.5875\n",
      "2025-06-25 00:01:51 [INFO]: Epoch 010 - training loss (MAE): 0.7827, validation MSE: 0.5656\n",
      "2025-06-25 00:01:58 [INFO]: Epoch 011 - training loss (MAE): 0.7558, validation MSE: 0.5471\n",
      "2025-06-25 00:02:05 [INFO]: Epoch 012 - training loss (MAE): 0.7380, validation MSE: 0.5318\n",
      "2025-06-25 00:02:12 [INFO]: Epoch 013 - training loss (MAE): 0.7354, validation MSE: 0.5166\n",
      "2025-06-25 00:02:19 [INFO]: Epoch 014 - training loss (MAE): 0.7217, validation MSE: 0.5047\n",
      "2025-06-25 00:02:26 [INFO]: Epoch 015 - training loss (MAE): 0.7089, validation MSE: 0.4937\n",
      "2025-06-25 00:02:33 [INFO]: Epoch 016 - training loss (MAE): 0.6995, validation MSE: 0.4842\n",
      "2025-06-25 00:02:40 [INFO]: Epoch 017 - training loss (MAE): 0.6967, validation MSE: 0.4753\n",
      "2025-06-25 00:02:47 [INFO]: Epoch 018 - training loss (MAE): 0.6883, validation MSE: 0.4649\n",
      "2025-06-25 00:02:54 [INFO]: Epoch 019 - training loss (MAE): 0.6952, validation MSE: 0.4593\n",
      "2025-06-25 00:03:02 [INFO]: Epoch 020 - training loss (MAE): 0.6989, validation MSE: 0.4559\n",
      "2025-06-25 00:03:09 [INFO]: Epoch 021 - training loss (MAE): 0.6826, validation MSE: 0.4477\n",
      "2025-06-25 00:03:17 [INFO]: Epoch 022 - training loss (MAE): 0.6825, validation MSE: 0.4431\n",
      "2025-06-25 00:03:24 [INFO]: Epoch 023 - training loss (MAE): 0.6805, validation MSE: 0.4388\n",
      "2025-06-25 00:03:31 [INFO]: Epoch 024 - training loss (MAE): 0.6817, validation MSE: 0.4349\n",
      "2025-06-25 00:03:38 [INFO]: Epoch 025 - training loss (MAE): 0.6904, validation MSE: 0.4330\n",
      "2025-06-25 00:03:38 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:03:38 [INFO]: Saved the model to ./brits_model\\20250625_T000037\\BRITS.pypots\n",
      "2025-06-25 00:03:38 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:03:38 [INFO]: Model files will be saved to ./brits_model\\20250625_T000338\n",
      "2025-06-25 00:03:38 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T000338\\tensorboard\n",
      "2025-06-25 00:03:38 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:03:38 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:03:38 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 1...\n",
      "Training model for missing rate 0.05 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:03:48 [INFO]: Epoch 001 - training loss (MAE): 1.7098, validation MSE: 0.9730\n",
      "2025-06-25 00:03:55 [INFO]: Epoch 002 - training loss (MAE): 1.6055, validation MSE: 0.8262\n",
      "2025-06-25 00:04:02 [INFO]: Epoch 003 - training loss (MAE): 1.4931, validation MSE: 0.6891\n",
      "2025-06-25 00:04:08 [INFO]: Epoch 004 - training loss (MAE): 1.3874, validation MSE: 0.5628\n",
      "2025-06-25 00:04:14 [INFO]: Epoch 005 - training loss (MAE): 1.2751, validation MSE: 0.4530\n",
      "2025-06-25 00:04:21 [INFO]: Epoch 006 - training loss (MAE): 1.1793, validation MSE: 0.3578\n",
      "2025-06-25 00:04:28 [INFO]: Epoch 007 - training loss (MAE): 1.0660, validation MSE: 0.2812\n",
      "2025-06-25 00:04:34 [INFO]: Epoch 008 - training loss (MAE): 0.9958, validation MSE: 0.2240\n",
      "2025-06-25 00:04:41 [INFO]: Epoch 009 - training loss (MAE): 0.9301, validation MSE: 0.1901\n",
      "2025-06-25 00:04:47 [INFO]: Epoch 010 - training loss (MAE): 0.8707, validation MSE: 0.1726\n",
      "2025-06-25 00:04:53 [INFO]: Epoch 011 - training loss (MAE): 0.8315, validation MSE: 0.1641\n",
      "2025-06-25 00:04:59 [INFO]: Epoch 012 - training loss (MAE): 0.7996, validation MSE: 0.1609\n",
      "2025-06-25 00:05:06 [INFO]: Epoch 013 - training loss (MAE): 0.7802, validation MSE: 0.1595\n",
      "2025-06-25 00:05:12 [INFO]: Epoch 014 - training loss (MAE): 0.7546, validation MSE: 0.1588\n",
      "2025-06-25 00:05:19 [INFO]: Epoch 015 - training loss (MAE): 0.7371, validation MSE: 0.1583\n",
      "2025-06-25 00:05:25 [INFO]: Epoch 016 - training loss (MAE): 0.7317, validation MSE: 0.1578\n",
      "2025-06-25 00:05:31 [INFO]: Epoch 017 - training loss (MAE): 0.7239, validation MSE: 0.1573\n",
      "2025-06-25 00:05:38 [INFO]: Epoch 018 - training loss (MAE): 0.7065, validation MSE: 0.1568\n",
      "2025-06-25 00:05:45 [INFO]: Epoch 019 - training loss (MAE): 0.7164, validation MSE: 0.1565\n",
      "2025-06-25 00:05:51 [INFO]: Epoch 020 - training loss (MAE): 0.6968, validation MSE: 0.1562\n",
      "2025-06-25 00:05:57 [INFO]: Epoch 021 - training loss (MAE): 0.6975, validation MSE: 0.1558\n",
      "2025-06-25 00:06:04 [INFO]: Epoch 022 - training loss (MAE): 0.6958, validation MSE: 0.1553\n",
      "2025-06-25 00:06:10 [INFO]: Epoch 023 - training loss (MAE): 0.6940, validation MSE: 0.1549\n",
      "2025-06-25 00:06:16 [INFO]: Epoch 024 - training loss (MAE): 0.6865, validation MSE: 0.1546\n",
      "2025-06-25 00:06:22 [INFO]: Epoch 025 - training loss (MAE): 0.6789, validation MSE: 0.1541\n",
      "2025-06-25 00:06:22 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:06:22 [INFO]: Saved the model to ./brits_model\\20250625_T000338\\BRITS.pypots\n",
      "2025-06-25 00:06:22 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:06:22 [INFO]: Model files will be saved to ./brits_model\\20250625_T000622\n",
      "2025-06-25 00:06:22 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T000622\\tensorboard\n",
      "2025-06-25 00:06:22 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:06:22 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:06:22 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:06:33 [INFO]: Epoch 001 - training loss (MAE): 1.7858, validation MSE: 0.8074\n",
      "2025-06-25 00:06:39 [INFO]: Epoch 002 - training loss (MAE): 1.6532, validation MSE: 0.6809\n",
      "2025-06-25 00:06:46 [INFO]: Epoch 003 - training loss (MAE): 1.5714, validation MSE: 0.5551\n",
      "2025-06-25 00:06:52 [INFO]: Epoch 004 - training loss (MAE): 1.4309, validation MSE: 0.4389\n",
      "2025-06-25 00:06:59 [INFO]: Epoch 005 - training loss (MAE): 1.3043, validation MSE: 0.3481\n",
      "2025-06-25 00:07:05 [INFO]: Epoch 006 - training loss (MAE): 1.1827, validation MSE: 0.2822\n",
      "2025-06-25 00:07:12 [INFO]: Epoch 007 - training loss (MAE): 1.0790, validation MSE: 0.2398\n",
      "2025-06-25 00:07:18 [INFO]: Epoch 008 - training loss (MAE): 0.9915, validation MSE: 0.2160\n",
      "2025-06-25 00:07:24 [INFO]: Epoch 009 - training loss (MAE): 0.9322, validation MSE: 0.2014\n",
      "2025-06-25 00:07:31 [INFO]: Epoch 010 - training loss (MAE): 0.8725, validation MSE: 0.1924\n",
      "2025-06-25 00:07:37 [INFO]: Epoch 011 - training loss (MAE): 0.8460, validation MSE: 0.1869\n",
      "2025-06-25 00:07:44 [INFO]: Epoch 012 - training loss (MAE): 0.8062, validation MSE: 0.1837\n",
      "2025-06-25 00:07:50 [INFO]: Epoch 013 - training loss (MAE): 0.7754, validation MSE: 0.1814\n",
      "2025-06-25 00:07:57 [INFO]: Epoch 014 - training loss (MAE): 0.7615, validation MSE: 0.1795\n",
      "2025-06-25 00:08:03 [INFO]: Epoch 015 - training loss (MAE): 0.7389, validation MSE: 0.1783\n",
      "2025-06-25 00:08:10 [INFO]: Epoch 016 - training loss (MAE): 0.7364, validation MSE: 0.1770\n",
      "2025-06-25 00:08:16 [INFO]: Epoch 017 - training loss (MAE): 0.7269, validation MSE: 0.1766\n",
      "2025-06-25 00:08:23 [INFO]: Epoch 018 - training loss (MAE): 0.7163, validation MSE: 0.1759\n",
      "2025-06-25 00:08:29 [INFO]: Epoch 019 - training loss (MAE): 0.7090, validation MSE: 0.1744\n",
      "2025-06-25 00:08:36 [INFO]: Epoch 020 - training loss (MAE): 0.7028, validation MSE: 0.1737\n",
      "2025-06-25 00:08:42 [INFO]: Epoch 021 - training loss (MAE): 0.7065, validation MSE: 0.1732\n",
      "2025-06-25 00:08:49 [INFO]: Epoch 022 - training loss (MAE): 0.6994, validation MSE: 0.1726\n",
      "2025-06-25 00:08:55 [INFO]: Epoch 023 - training loss (MAE): 0.6875, validation MSE: 0.1716\n",
      "2025-06-25 00:09:01 [INFO]: Epoch 024 - training loss (MAE): 0.6892, validation MSE: 0.1711\n",
      "2025-06-25 00:09:08 [INFO]: Epoch 025 - training loss (MAE): 0.6896, validation MSE: 0.1710\n",
      "2025-06-25 00:09:08 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:09:08 [INFO]: Saved the model to ./brits_model\\20250625_T000622\\BRITS.pypots\n",
      "2025-06-25 00:09:08 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:09:08 [INFO]: Model files will be saved to ./brits_model\\20250625_T000908\n",
      "2025-06-25 00:09:08 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T000908\\tensorboard\n",
      "2025-06-25 00:09:08 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:09:08 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:09:08 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:09:18 [INFO]: Epoch 001 - training loss (MAE): 1.7325, validation MSE: 0.8575\n",
      "2025-06-25 00:09:25 [INFO]: Epoch 002 - training loss (MAE): 1.6889, validation MSE: 0.7769\n",
      "2025-06-25 00:09:32 [INFO]: Epoch 003 - training loss (MAE): 1.6099, validation MSE: 0.6888\n",
      "2025-06-25 00:09:38 [INFO]: Epoch 004 - training loss (MAE): 1.4893, validation MSE: 0.5873\n",
      "2025-06-25 00:09:45 [INFO]: Epoch 005 - training loss (MAE): 1.3820, validation MSE: 0.4831\n",
      "2025-06-25 00:09:52 [INFO]: Epoch 006 - training loss (MAE): 1.2677, validation MSE: 0.3947\n",
      "2025-06-25 00:09:58 [INFO]: Epoch 007 - training loss (MAE): 1.1610, validation MSE: 0.3250\n",
      "2025-06-25 00:10:05 [INFO]: Epoch 008 - training loss (MAE): 1.0734, validation MSE: 0.2744\n",
      "2025-06-25 00:10:11 [INFO]: Epoch 009 - training loss (MAE): 0.9973, validation MSE: 0.2411\n",
      "2025-06-25 00:10:18 [INFO]: Epoch 010 - training loss (MAE): 0.9147, validation MSE: 0.2194\n",
      "2025-06-25 00:10:25 [INFO]: Epoch 011 - training loss (MAE): 0.8563, validation MSE: 0.2053\n",
      "2025-06-25 00:10:31 [INFO]: Epoch 012 - training loss (MAE): 0.8076, validation MSE: 0.1957\n",
      "2025-06-25 00:10:38 [INFO]: Epoch 013 - training loss (MAE): 0.7873, validation MSE: 0.1892\n",
      "2025-06-25 00:10:45 [INFO]: Epoch 014 - training loss (MAE): 0.7641, validation MSE: 0.1850\n",
      "2025-06-25 00:10:52 [INFO]: Epoch 015 - training loss (MAE): 0.7369, validation MSE: 0.1824\n",
      "2025-06-25 00:10:59 [INFO]: Epoch 016 - training loss (MAE): 0.7300, validation MSE: 0.1795\n",
      "2025-06-25 00:11:05 [INFO]: Epoch 017 - training loss (MAE): 0.7213, validation MSE: 0.1779\n",
      "2025-06-25 00:11:12 [INFO]: Epoch 018 - training loss (MAE): 0.7121, validation MSE: 0.1767\n",
      "2025-06-25 00:11:19 [INFO]: Epoch 019 - training loss (MAE): 0.7072, validation MSE: 0.1758\n",
      "2025-06-25 00:11:25 [INFO]: Epoch 020 - training loss (MAE): 0.6959, validation MSE: 0.1748\n",
      "2025-06-25 00:11:32 [INFO]: Epoch 021 - training loss (MAE): 0.7018, validation MSE: 0.1734\n",
      "2025-06-25 00:11:39 [INFO]: Epoch 022 - training loss (MAE): 0.6949, validation MSE: 0.1726\n",
      "2025-06-25 00:11:45 [INFO]: Epoch 023 - training loss (MAE): 0.6986, validation MSE: 0.1710\n",
      "2025-06-25 00:11:52 [INFO]: Epoch 024 - training loss (MAE): 0.6867, validation MSE: 0.1698\n",
      "2025-06-25 00:11:58 [INFO]: Epoch 025 - training loss (MAE): 0.6948, validation MSE: 0.1691\n",
      "2025-06-25 00:11:58 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:11:58 [INFO]: Saved the model to ./brits_model\\20250625_T000908\\BRITS.pypots\n",
      "2025-06-25 00:11:58 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:11:58 [INFO]: Model files will be saved to ./brits_model\\20250625_T001158\n",
      "2025-06-25 00:11:58 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T001158\\tensorboard\n",
      "2025-06-25 00:11:58 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:11:58 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:11:58 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.99 in cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:12:08 [INFO]: Epoch 001 - training loss (MAE): 1.6688, validation MSE: 0.9164\n",
      "2025-06-25 00:12:15 [INFO]: Epoch 002 - training loss (MAE): 1.6453, validation MSE: 0.8949\n",
      "2025-06-25 00:12:22 [INFO]: Epoch 003 - training loss (MAE): 1.5689, validation MSE: 0.8716\n",
      "2025-06-25 00:12:28 [INFO]: Epoch 004 - training loss (MAE): 1.5097, validation MSE: 0.8481\n",
      "2025-06-25 00:12:35 [INFO]: Epoch 005 - training loss (MAE): 1.4389, validation MSE: 0.8226\n",
      "2025-06-25 00:12:42 [INFO]: Epoch 006 - training loss (MAE): 1.3435, validation MSE: 0.7909\n",
      "2025-06-25 00:12:48 [INFO]: Epoch 007 - training loss (MAE): 1.2416, validation MSE: 0.7553\n",
      "2025-06-25 00:12:55 [INFO]: Epoch 008 - training loss (MAE): 1.1383, validation MSE: 0.7261\n",
      "2025-06-25 00:13:01 [INFO]: Epoch 009 - training loss (MAE): 1.0310, validation MSE: 0.7024\n",
      "2025-06-25 00:13:08 [INFO]: Epoch 010 - training loss (MAE): 0.9560, validation MSE: 0.6802\n",
      "2025-06-25 00:13:14 [INFO]: Epoch 011 - training loss (MAE): 0.8882, validation MSE: 0.6583\n",
      "2025-06-25 00:13:20 [INFO]: Epoch 012 - training loss (MAE): 0.8496, validation MSE: 0.6376\n",
      "2025-06-25 00:13:27 [INFO]: Epoch 013 - training loss (MAE): 0.8019, validation MSE: 0.6104\n",
      "2025-06-25 00:13:33 [INFO]: Epoch 014 - training loss (MAE): 0.7667, validation MSE: 0.5786\n",
      "2025-06-25 00:13:40 [INFO]: Epoch 015 - training loss (MAE): 0.7550, validation MSE: 0.5533\n",
      "2025-06-25 00:13:47 [INFO]: Epoch 016 - training loss (MAE): 0.7688, validation MSE: 0.5299\n",
      "2025-06-25 00:13:53 [INFO]: Epoch 017 - training loss (MAE): 0.7535, validation MSE: 0.5071\n",
      "2025-06-25 00:14:00 [INFO]: Epoch 018 - training loss (MAE): 0.7314, validation MSE: 0.4903\n",
      "2025-06-25 00:14:06 [INFO]: Epoch 019 - training loss (MAE): 0.7425, validation MSE: 0.4750\n",
      "2025-06-25 00:14:13 [INFO]: Epoch 020 - training loss (MAE): 0.7267, validation MSE: 0.4606\n",
      "2025-06-25 00:14:19 [INFO]: Epoch 021 - training loss (MAE): 0.7219, validation MSE: 0.4477\n",
      "2025-06-25 00:14:26 [INFO]: Epoch 022 - training loss (MAE): 0.7294, validation MSE: 0.4370\n",
      "2025-06-25 00:14:32 [INFO]: Epoch 023 - training loss (MAE): 0.7282, validation MSE: 0.4280\n",
      "2025-06-25 00:14:38 [INFO]: Epoch 024 - training loss (MAE): 0.7284, validation MSE: 0.4185\n",
      "2025-06-25 00:14:45 [INFO]: Epoch 025 - training loss (MAE): 0.7198, validation MSE: 0.4082\n",
      "2025-06-25 00:14:45 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:14:45 [INFO]: Saved the model to ./brits_model\\20250625_T001158\\BRITS.pypots\n",
      "2025-06-25 00:14:45 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:14:45 [INFO]: Model files will be saved to ./brits_model\\20250625_T001445\n",
      "2025-06-25 00:14:45 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T001445\\tensorboard\n",
      "2025-06-25 00:14:45 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:14:45 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:14:45 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 2...\n",
      "Training model for missing rate 0.05 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:14:55 [INFO]: Epoch 001 - training loss (MAE): 1.7311, validation MSE: 1.0395\n",
      "2025-06-25 00:15:02 [INFO]: Epoch 002 - training loss (MAE): 1.5784, validation MSE: 0.8675\n",
      "2025-06-25 00:15:09 [INFO]: Epoch 003 - training loss (MAE): 1.4950, validation MSE: 0.6968\n",
      "2025-06-25 00:15:15 [INFO]: Epoch 004 - training loss (MAE): 1.3896, validation MSE: 0.5442\n",
      "2025-06-25 00:15:22 [INFO]: Epoch 005 - training loss (MAE): 1.2719, validation MSE: 0.4150\n",
      "2025-06-25 00:15:29 [INFO]: Epoch 006 - training loss (MAE): 1.1686, validation MSE: 0.3132\n",
      "2025-06-25 00:15:35 [INFO]: Epoch 007 - training loss (MAE): 1.0862, validation MSE: 0.2448\n",
      "2025-06-25 00:15:42 [INFO]: Epoch 008 - training loss (MAE): 1.0239, validation MSE: 0.1993\n",
      "2025-06-25 00:15:48 [INFO]: Epoch 009 - training loss (MAE): 0.9514, validation MSE: 0.1674\n",
      "2025-06-25 00:15:55 [INFO]: Epoch 010 - training loss (MAE): 0.8989, validation MSE: 0.1469\n",
      "2025-06-25 00:16:02 [INFO]: Epoch 011 - training loss (MAE): 0.8519, validation MSE: 0.1341\n",
      "2025-06-25 00:16:08 [INFO]: Epoch 012 - training loss (MAE): 0.8210, validation MSE: 0.1258\n",
      "2025-06-25 00:16:15 [INFO]: Epoch 013 - training loss (MAE): 0.7941, validation MSE: 0.1210\n",
      "2025-06-25 00:16:21 [INFO]: Epoch 014 - training loss (MAE): 0.7709, validation MSE: 0.1176\n",
      "2025-06-25 00:16:28 [INFO]: Epoch 015 - training loss (MAE): 0.7558, validation MSE: 0.1163\n",
      "2025-06-25 00:16:34 [INFO]: Epoch 016 - training loss (MAE): 0.7486, validation MSE: 0.1154\n",
      "2025-06-25 00:16:41 [INFO]: Epoch 017 - training loss (MAE): 0.7330, validation MSE: 0.1145\n",
      "2025-06-25 00:16:47 [INFO]: Epoch 018 - training loss (MAE): 0.7234, validation MSE: 0.1137\n",
      "2025-06-25 00:16:54 [INFO]: Epoch 019 - training loss (MAE): 0.7041, validation MSE: 0.1131\n",
      "2025-06-25 00:17:01 [INFO]: Epoch 020 - training loss (MAE): 0.7041, validation MSE: 0.1126\n",
      "2025-06-25 00:17:07 [INFO]: Epoch 021 - training loss (MAE): 0.6996, validation MSE: 0.1126\n",
      "2025-06-25 00:17:14 [INFO]: Epoch 022 - training loss (MAE): 0.6960, validation MSE: 0.1121\n",
      "2025-06-25 00:17:21 [INFO]: Epoch 023 - training loss (MAE): 0.6884, validation MSE: 0.1116\n",
      "2025-06-25 00:17:27 [INFO]: Epoch 024 - training loss (MAE): 0.6926, validation MSE: 0.1112\n",
      "2025-06-25 00:17:33 [INFO]: Epoch 025 - training loss (MAE): 0.6787, validation MSE: 0.1109\n",
      "2025-06-25 00:17:33 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:17:33 [INFO]: Saved the model to ./brits_model\\20250625_T001445\\BRITS.pypots\n",
      "2025-06-25 00:17:33 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:17:33 [INFO]: Model files will be saved to ./brits_model\\20250625_T001733\n",
      "2025-06-25 00:17:33 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T001733\\tensorboard\n",
      "2025-06-25 00:17:33 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:17:33 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:17:33 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:17:44 [INFO]: Epoch 001 - training loss (MAE): 1.9044, validation MSE: 1.4632\n",
      "2025-06-25 00:17:51 [INFO]: Epoch 002 - training loss (MAE): 1.7832, validation MSE: 1.2856\n",
      "2025-06-25 00:17:58 [INFO]: Epoch 003 - training loss (MAE): 1.6940, validation MSE: 1.1146\n",
      "2025-06-25 00:18:04 [INFO]: Epoch 004 - training loss (MAE): 1.6118, validation MSE: 0.9467\n",
      "2025-06-25 00:18:11 [INFO]: Epoch 005 - training loss (MAE): 1.5100, validation MSE: 0.7818\n",
      "2025-06-25 00:18:17 [INFO]: Epoch 006 - training loss (MAE): 1.3905, validation MSE: 0.6235\n",
      "2025-06-25 00:18:24 [INFO]: Epoch 007 - training loss (MAE): 1.2682, validation MSE: 0.4828\n",
      "2025-06-25 00:18:31 [INFO]: Epoch 008 - training loss (MAE): 1.1969, validation MSE: 0.3695\n",
      "2025-06-25 00:18:37 [INFO]: Epoch 009 - training loss (MAE): 1.1011, validation MSE: 0.2917\n",
      "2025-06-25 00:18:44 [INFO]: Epoch 010 - training loss (MAE): 1.0241, validation MSE: 0.2498\n",
      "2025-06-25 00:18:50 [INFO]: Epoch 011 - training loss (MAE): 0.9477, validation MSE: 0.2247\n",
      "2025-06-25 00:18:57 [INFO]: Epoch 012 - training loss (MAE): 0.8986, validation MSE: 0.2103\n",
      "2025-06-25 00:19:04 [INFO]: Epoch 013 - training loss (MAE): 0.8672, validation MSE: 0.1986\n",
      "2025-06-25 00:19:11 [INFO]: Epoch 014 - training loss (MAE): 0.8323, validation MSE: 0.1922\n",
      "2025-06-25 00:19:17 [INFO]: Epoch 015 - training loss (MAE): 0.8011, validation MSE: 0.1882\n",
      "2025-06-25 00:19:24 [INFO]: Epoch 016 - training loss (MAE): 0.7887, validation MSE: 0.1861\n",
      "2025-06-25 00:19:31 [INFO]: Epoch 017 - training loss (MAE): 0.7800, validation MSE: 0.1855\n",
      "2025-06-25 00:19:37 [INFO]: Epoch 018 - training loss (MAE): 0.7648, validation MSE: 0.1845\n",
      "2025-06-25 00:19:44 [INFO]: Epoch 019 - training loss (MAE): 0.7437, validation MSE: 0.1838\n",
      "2025-06-25 00:19:50 [INFO]: Epoch 020 - training loss (MAE): 0.7449, validation MSE: 0.1838\n",
      "2025-06-25 00:19:57 [INFO]: Epoch 021 - training loss (MAE): 0.7293, validation MSE: 0.1833\n",
      "2025-06-25 00:20:04 [INFO]: Epoch 022 - training loss (MAE): 0.7166, validation MSE: 0.1830\n",
      "2025-06-25 00:20:10 [INFO]: Epoch 023 - training loss (MAE): 0.7126, validation MSE: 0.1821\n",
      "2025-06-25 00:20:17 [INFO]: Epoch 024 - training loss (MAE): 0.7092, validation MSE: 0.1820\n",
      "2025-06-25 00:20:23 [INFO]: Epoch 025 - training loss (MAE): 0.7117, validation MSE: 0.1819\n",
      "2025-06-25 00:20:23 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:20:23 [INFO]: Saved the model to ./brits_model\\20250625_T001733\\BRITS.pypots\n",
      "2025-06-25 00:20:23 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:20:23 [INFO]: Model files will be saved to ./brits_model\\20250625_T002023\n",
      "2025-06-25 00:20:23 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T002023\\tensorboard\n",
      "2025-06-25 00:20:23 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:20:23 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:20:23 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:20:33 [INFO]: Epoch 001 - training loss (MAE): 1.8007, validation MSE: 1.0467\n",
      "2025-06-25 00:20:40 [INFO]: Epoch 002 - training loss (MAE): 1.6882, validation MSE: 0.9651\n",
      "2025-06-25 00:20:46 [INFO]: Epoch 003 - training loss (MAE): 1.6087, validation MSE: 0.8736\n",
      "2025-06-25 00:20:53 [INFO]: Epoch 004 - training loss (MAE): 1.5143, validation MSE: 0.7662\n",
      "2025-06-25 00:21:01 [INFO]: Epoch 005 - training loss (MAE): 1.4070, validation MSE: 0.6359\n",
      "2025-06-25 00:21:07 [INFO]: Epoch 006 - training loss (MAE): 1.2762, validation MSE: 0.5098\n",
      "2025-06-25 00:21:13 [INFO]: Epoch 007 - training loss (MAE): 1.1725, validation MSE: 0.4074\n",
      "2025-06-25 00:21:19 [INFO]: Epoch 008 - training loss (MAE): 1.0863, validation MSE: 0.3281\n",
      "2025-06-25 00:21:25 [INFO]: Epoch 009 - training loss (MAE): 1.0057, validation MSE: 0.2773\n",
      "2025-06-25 00:21:31 [INFO]: Epoch 010 - training loss (MAE): 0.9384, validation MSE: 0.2462\n",
      "2025-06-25 00:21:37 [INFO]: Epoch 011 - training loss (MAE): 0.8787, validation MSE: 0.2184\n",
      "2025-06-25 00:21:42 [INFO]: Epoch 012 - training loss (MAE): 0.8307, validation MSE: 0.1992\n",
      "2025-06-25 00:21:48 [INFO]: Epoch 013 - training loss (MAE): 0.7989, validation MSE: 0.1858\n",
      "2025-06-25 00:21:54 [INFO]: Epoch 014 - training loss (MAE): 0.7877, validation MSE: 0.1785\n",
      "2025-06-25 00:22:00 [INFO]: Epoch 015 - training loss (MAE): 0.7518, validation MSE: 0.1710\n",
      "2025-06-25 00:22:06 [INFO]: Epoch 016 - training loss (MAE): 0.7440, validation MSE: 0.1685\n",
      "2025-06-25 00:22:11 [INFO]: Epoch 017 - training loss (MAE): 0.7486, validation MSE: 0.1667\n",
      "2025-06-25 00:22:17 [INFO]: Epoch 018 - training loss (MAE): 0.7191, validation MSE: 0.1628\n",
      "2025-06-25 00:22:23 [INFO]: Epoch 019 - training loss (MAE): 0.7137, validation MSE: 0.1597\n",
      "2025-06-25 00:22:29 [INFO]: Epoch 020 - training loss (MAE): 0.7100, validation MSE: 0.1584\n",
      "2025-06-25 00:22:34 [INFO]: Epoch 021 - training loss (MAE): 0.7031, validation MSE: 0.1568\n",
      "2025-06-25 00:22:40 [INFO]: Epoch 022 - training loss (MAE): 0.7082, validation MSE: 0.1565\n",
      "2025-06-25 00:22:46 [INFO]: Epoch 023 - training loss (MAE): 0.7015, validation MSE: 0.1563\n",
      "2025-06-25 00:22:52 [INFO]: Epoch 024 - training loss (MAE): 0.6985, validation MSE: 0.1555\n",
      "2025-06-25 00:22:58 [INFO]: Epoch 025 - training loss (MAE): 0.6964, validation MSE: 0.1555\n",
      "2025-06-25 00:22:58 [INFO]: Finished training. The best model is from epoch#24.\n",
      "2025-06-25 00:22:58 [INFO]: Saved the model to ./brits_model\\20250625_T002023\\BRITS.pypots\n",
      "2025-06-25 00:22:58 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:22:58 [INFO]: Model files will be saved to ./brits_model\\20250625_T002258\n",
      "2025-06-25 00:22:58 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T002258\\tensorboard\n",
      "2025-06-25 00:22:58 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:22:58 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:22:58 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 6,416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.99 in cluster 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:23:08 [INFO]: Epoch 001 - training loss (MAE): 1.7936, validation MSE: 1.0715\n",
      "2025-06-25 00:23:14 [INFO]: Epoch 002 - training loss (MAE): 1.7299, validation MSE: 1.0553\n",
      "2025-06-25 00:23:21 [INFO]: Epoch 003 - training loss (MAE): 1.6646, validation MSE: 1.0410\n",
      "2025-06-25 00:23:29 [INFO]: Epoch 004 - training loss (MAE): 1.5460, validation MSE: 1.0240\n",
      "2025-06-25 00:23:39 [INFO]: Epoch 005 - training loss (MAE): 1.4859, validation MSE: 1.0024\n",
      "2025-06-25 00:23:49 [INFO]: Epoch 006 - training loss (MAE): 1.3529, validation MSE: 0.9716\n",
      "2025-06-25 00:23:58 [INFO]: Epoch 007 - training loss (MAE): 1.2511, validation MSE: 0.9237\n",
      "2025-06-25 00:24:08 [INFO]: Epoch 008 - training loss (MAE): 1.1500, validation MSE: 0.8522\n",
      "2025-06-25 00:24:18 [INFO]: Epoch 009 - training loss (MAE): 1.0431, validation MSE: 0.7775\n",
      "2025-06-25 00:24:28 [INFO]: Epoch 010 - training loss (MAE): 0.9475, validation MSE: 0.7229\n",
      "2025-06-25 00:24:37 [INFO]: Epoch 011 - training loss (MAE): 0.8703, validation MSE: 0.6866\n",
      "2025-06-25 00:24:48 [INFO]: Epoch 012 - training loss (MAE): 0.8310, validation MSE: 0.6578\n",
      "2025-06-25 00:24:58 [INFO]: Epoch 013 - training loss (MAE): 0.7843, validation MSE: 0.6405\n",
      "2025-06-25 00:25:08 [INFO]: Epoch 014 - training loss (MAE): 0.7762, validation MSE: 0.6328\n",
      "2025-06-25 00:25:17 [INFO]: Epoch 015 - training loss (MAE): 0.7581, validation MSE: 0.6279\n",
      "2025-06-25 00:25:27 [INFO]: Epoch 016 - training loss (MAE): 0.7547, validation MSE: 0.6244\n",
      "2025-06-25 00:25:36 [INFO]: Epoch 017 - training loss (MAE): 0.7557, validation MSE: 0.6192\n",
      "2025-06-25 00:25:46 [INFO]: Epoch 018 - training loss (MAE): 0.7427, validation MSE: 0.6148\n",
      "2025-06-25 00:25:56 [INFO]: Epoch 019 - training loss (MAE): 0.7457, validation MSE: 0.6090\n",
      "2025-06-25 00:26:05 [INFO]: Epoch 020 - training loss (MAE): 0.7317, validation MSE: 0.6025\n",
      "2025-06-25 00:26:15 [INFO]: Epoch 021 - training loss (MAE): 0.7389, validation MSE: 0.5971\n",
      "2025-06-25 00:26:25 [INFO]: Epoch 022 - training loss (MAE): 0.7288, validation MSE: 0.5913\n",
      "2025-06-25 00:26:34 [INFO]: Epoch 023 - training loss (MAE): 0.7157, validation MSE: 0.5839\n",
      "2025-06-25 00:26:44 [INFO]: Epoch 024 - training loss (MAE): 0.7202, validation MSE: 0.5798\n",
      "2025-06-25 00:26:54 [INFO]: Epoch 025 - training loss (MAE): 0.7131, validation MSE: 0.5671\n",
      "2025-06-25 00:26:54 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:26:54 [INFO]: Saved the model to ./brits_model\\20250625_T002258\\BRITS.pypots\n",
      "2025-06-25 00:26:54 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:26:54 [INFO]: Model files will be saved to ./brits_model\\20250625_T002654\n",
      "2025-06-25 00:26:54 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T002654\\tensorboard\n",
      "2025-06-25 00:26:54 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:26:54 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:26:54 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 21,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 3...\n",
      "Training model for missing rate 0.05 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:27:09 [INFO]: Epoch 001 - training loss (MAE): 1.6338, validation MSE: 0.8051\n",
      "2025-06-25 00:27:18 [INFO]: Epoch 002 - training loss (MAE): 1.4608, validation MSE: 0.5636\n",
      "2025-06-25 00:27:28 [INFO]: Epoch 003 - training loss (MAE): 1.3195, validation MSE: 0.3946\n",
      "2025-06-25 00:27:37 [INFO]: Epoch 004 - training loss (MAE): 1.1813, validation MSE: 0.3025\n",
      "2025-06-25 00:27:46 [INFO]: Epoch 005 - training loss (MAE): 1.0842, validation MSE: 0.2692\n",
      "2025-06-25 00:27:55 [INFO]: Epoch 006 - training loss (MAE): 1.0162, validation MSE: 0.2600\n",
      "2025-06-25 00:28:04 [INFO]: Epoch 007 - training loss (MAE): 0.9522, validation MSE: 0.2542\n",
      "2025-06-25 00:28:12 [INFO]: Epoch 008 - training loss (MAE): 0.9199, validation MSE: 0.2474\n",
      "2025-06-25 00:28:21 [INFO]: Epoch 009 - training loss (MAE): 0.8929, validation MSE: 0.2425\n",
      "2025-06-25 00:28:30 [INFO]: Epoch 010 - training loss (MAE): 0.8687, validation MSE: 0.2398\n",
      "2025-06-25 00:28:39 [INFO]: Epoch 011 - training loss (MAE): 0.8346, validation MSE: 0.2366\n",
      "2025-06-25 00:28:47 [INFO]: Epoch 012 - training loss (MAE): 0.8324, validation MSE: 0.2339\n",
      "2025-06-25 00:28:56 [INFO]: Epoch 013 - training loss (MAE): 0.8263, validation MSE: 0.2318\n",
      "2025-06-25 00:29:05 [INFO]: Epoch 014 - training loss (MAE): 0.8083, validation MSE: 0.2294\n",
      "2025-06-25 00:29:14 [INFO]: Epoch 015 - training loss (MAE): 0.8051, validation MSE: 0.2272\n",
      "2025-06-25 00:29:23 [INFO]: Epoch 016 - training loss (MAE): 0.7958, validation MSE: 0.2241\n",
      "2025-06-25 00:29:32 [INFO]: Epoch 017 - training loss (MAE): 0.7948, validation MSE: 0.2218\n",
      "2025-06-25 00:29:41 [INFO]: Epoch 018 - training loss (MAE): 0.7883, validation MSE: 0.2201\n",
      "2025-06-25 00:29:50 [INFO]: Epoch 019 - training loss (MAE): 0.7758, validation MSE: 0.2182\n",
      "2025-06-25 00:29:58 [INFO]: Epoch 020 - training loss (MAE): 0.7756, validation MSE: 0.2157\n",
      "2025-06-25 00:30:07 [INFO]: Epoch 021 - training loss (MAE): 0.7674, validation MSE: 0.2147\n",
      "2025-06-25 00:30:16 [INFO]: Epoch 022 - training loss (MAE): 0.7652, validation MSE: 0.2134\n",
      "2025-06-25 00:30:25 [INFO]: Epoch 023 - training loss (MAE): 0.7651, validation MSE: 0.2114\n",
      "2025-06-25 00:30:34 [INFO]: Epoch 024 - training loss (MAE): 0.7641, validation MSE: 0.2106\n",
      "2025-06-25 00:30:42 [INFO]: Epoch 025 - training loss (MAE): 0.7554, validation MSE: 0.2084\n",
      "2025-06-25 00:30:42 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:30:42 [INFO]: Saved the model to ./brits_model\\20250625_T002654\\BRITS.pypots\n",
      "2025-06-25 00:30:42 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:30:42 [INFO]: Model files will be saved to ./brits_model\\20250625_T003042\n",
      "2025-06-25 00:30:42 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T003042\\tensorboard\n",
      "2025-06-25 00:30:42 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:30:42 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:30:42 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 21,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:30:57 [INFO]: Epoch 001 - training loss (MAE): 1.6558, validation MSE: 0.8141\n",
      "2025-06-25 00:31:06 [INFO]: Epoch 002 - training loss (MAE): 1.5130, validation MSE: 0.6275\n",
      "2025-06-25 00:31:15 [INFO]: Epoch 003 - training loss (MAE): 1.3648, validation MSE: 0.4966\n",
      "2025-06-25 00:31:23 [INFO]: Epoch 004 - training loss (MAE): 1.2452, validation MSE: 0.3997\n",
      "2025-06-25 00:31:32 [INFO]: Epoch 005 - training loss (MAE): 1.1292, validation MSE: 0.3302\n",
      "2025-06-25 00:31:41 [INFO]: Epoch 006 - training loss (MAE): 1.0669, validation MSE: 0.2899\n",
      "2025-06-25 00:31:50 [INFO]: Epoch 007 - training loss (MAE): 1.0071, validation MSE: 0.2727\n",
      "2025-06-25 00:31:59 [INFO]: Epoch 008 - training loss (MAE): 0.9734, validation MSE: 0.2654\n",
      "2025-06-25 00:32:07 [INFO]: Epoch 009 - training loss (MAE): 0.9236, validation MSE: 0.2602\n",
      "2025-06-25 00:32:16 [INFO]: Epoch 010 - training loss (MAE): 0.9070, validation MSE: 0.2561\n",
      "2025-06-25 00:32:25 [INFO]: Epoch 011 - training loss (MAE): 0.8681, validation MSE: 0.2525\n",
      "2025-06-25 00:32:34 [INFO]: Epoch 012 - training loss (MAE): 0.8505, validation MSE: 0.2491\n",
      "2025-06-25 00:32:42 [INFO]: Epoch 013 - training loss (MAE): 0.8406, validation MSE: 0.2461\n",
      "2025-06-25 00:32:50 [INFO]: Epoch 014 - training loss (MAE): 0.8334, validation MSE: 0.2432\n",
      "2025-06-25 00:32:59 [INFO]: Epoch 015 - training loss (MAE): 0.8098, validation MSE: 0.2404\n",
      "2025-06-25 00:33:07 [INFO]: Epoch 016 - training loss (MAE): 0.8059, validation MSE: 0.2383\n",
      "2025-06-25 00:33:15 [INFO]: Epoch 017 - training loss (MAE): 0.7941, validation MSE: 0.2367\n",
      "2025-06-25 00:33:24 [INFO]: Epoch 018 - training loss (MAE): 0.8007, validation MSE: 0.2343\n",
      "2025-06-25 00:33:32 [INFO]: Epoch 019 - training loss (MAE): 0.7890, validation MSE: 0.2321\n",
      "2025-06-25 00:33:40 [INFO]: Epoch 020 - training loss (MAE): 0.7675, validation MSE: 0.2303\n",
      "2025-06-25 00:33:48 [INFO]: Epoch 021 - training loss (MAE): 0.7732, validation MSE: 0.2288\n",
      "2025-06-25 00:33:56 [INFO]: Epoch 022 - training loss (MAE): 0.7716, validation MSE: 0.2272\n",
      "2025-06-25 00:34:05 [INFO]: Epoch 023 - training loss (MAE): 0.7697, validation MSE: 0.2259\n",
      "2025-06-25 00:34:13 [INFO]: Epoch 024 - training loss (MAE): 0.7636, validation MSE: 0.2246\n",
      "2025-06-25 00:34:22 [INFO]: Epoch 025 - training loss (MAE): 0.7500, validation MSE: 0.2234\n",
      "2025-06-25 00:34:22 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:34:22 [INFO]: Saved the model to ./brits_model\\20250625_T003042\\BRITS.pypots\n",
      "2025-06-25 00:34:22 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:34:22 [INFO]: Model files will be saved to ./brits_model\\20250625_T003422\n",
      "2025-06-25 00:34:22 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T003422\\tensorboard\n",
      "2025-06-25 00:34:22 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:34:22 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:34:22 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 21,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:34:36 [INFO]: Epoch 001 - training loss (MAE): 1.7682, validation MSE: 0.8907\n",
      "2025-06-25 00:34:44 [INFO]: Epoch 002 - training loss (MAE): 1.5898, validation MSE: 0.7312\n",
      "2025-06-25 00:34:53 [INFO]: Epoch 003 - training loss (MAE): 1.4641, validation MSE: 0.5855\n",
      "2025-06-25 00:35:01 [INFO]: Epoch 004 - training loss (MAE): 1.3365, validation MSE: 0.4574\n",
      "2025-06-25 00:35:10 [INFO]: Epoch 005 - training loss (MAE): 1.2330, validation MSE: 0.3638\n",
      "2025-06-25 00:35:19 [INFO]: Epoch 006 - training loss (MAE): 1.1494, validation MSE: 0.3093\n",
      "2025-06-25 00:35:27 [INFO]: Epoch 007 - training loss (MAE): 1.0535, validation MSE: 0.2803\n",
      "2025-06-25 00:35:36 [INFO]: Epoch 008 - training loss (MAE): 1.0010, validation MSE: 0.2657\n",
      "2025-06-25 00:35:45 [INFO]: Epoch 009 - training loss (MAE): 0.9510, validation MSE: 0.2525\n",
      "2025-06-25 00:35:53 [INFO]: Epoch 010 - training loss (MAE): 0.9357, validation MSE: 0.2456\n",
      "2025-06-25 00:36:02 [INFO]: Epoch 011 - training loss (MAE): 0.9045, validation MSE: 0.2392\n",
      "2025-06-25 00:36:10 [INFO]: Epoch 012 - training loss (MAE): 0.8774, validation MSE: 0.2343\n",
      "2025-06-25 00:36:18 [INFO]: Epoch 013 - training loss (MAE): 0.8630, validation MSE: 0.2311\n",
      "2025-06-25 00:36:27 [INFO]: Epoch 014 - training loss (MAE): 0.8551, validation MSE: 0.2286\n",
      "2025-06-25 00:36:35 [INFO]: Epoch 015 - training loss (MAE): 0.8447, validation MSE: 0.2255\n",
      "2025-06-25 00:36:44 [INFO]: Epoch 016 - training loss (MAE): 0.8311, validation MSE: 0.2230\n",
      "2025-06-25 00:36:53 [INFO]: Epoch 017 - training loss (MAE): 0.8182, validation MSE: 0.2213\n",
      "2025-06-25 00:37:01 [INFO]: Epoch 018 - training loss (MAE): 0.8113, validation MSE: 0.2182\n",
      "2025-06-25 00:37:08 [INFO]: Epoch 019 - training loss (MAE): 0.8155, validation MSE: 0.2164\n",
      "2025-06-25 00:37:15 [INFO]: Epoch 020 - training loss (MAE): 0.8103, validation MSE: 0.2156\n",
      "2025-06-25 00:37:23 [INFO]: Epoch 021 - training loss (MAE): 0.8009, validation MSE: 0.2145\n",
      "2025-06-25 00:37:30 [INFO]: Epoch 022 - training loss (MAE): 0.7901, validation MSE: 0.2132\n",
      "2025-06-25 00:37:37 [INFO]: Epoch 023 - training loss (MAE): 0.7799, validation MSE: 0.2115\n",
      "2025-06-25 00:37:44 [INFO]: Epoch 024 - training loss (MAE): 0.7774, validation MSE: 0.2104\n",
      "2025-06-25 00:37:52 [INFO]: Epoch 025 - training loss (MAE): 0.7846, validation MSE: 0.2093\n",
      "2025-06-25 00:37:52 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:37:52 [INFO]: Saved the model to ./brits_model\\20250625_T003422\\BRITS.pypots\n",
      "2025-06-25 00:37:52 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:37:52 [INFO]: Model files will be saved to ./brits_model\\20250625_T003752\n",
      "2025-06-25 00:37:52 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T003752\\tensorboard\n",
      "2025-06-25 00:37:52 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:37:52 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:37:52 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 21,024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.99 in cluster 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:38:02 [INFO]: Epoch 001 - training loss (MAE): 1.7791, validation MSE: 0.9445\n",
      "2025-06-25 00:38:10 [INFO]: Epoch 002 - training loss (MAE): 1.6493, validation MSE: 0.9385\n",
      "2025-06-25 00:38:17 [INFO]: Epoch 003 - training loss (MAE): 1.5383, validation MSE: 0.9381\n",
      "2025-06-25 00:38:24 [INFO]: Epoch 004 - training loss (MAE): 1.3785, validation MSE: 0.9302\n",
      "2025-06-25 00:38:32 [INFO]: Epoch 005 - training loss (MAE): 1.2381, validation MSE: 0.8920\n",
      "2025-06-25 00:38:39 [INFO]: Epoch 006 - training loss (MAE): 1.0950, validation MSE: 0.8603\n",
      "2025-06-25 00:38:47 [INFO]: Epoch 007 - training loss (MAE): 0.9896, validation MSE: 0.8528\n",
      "2025-06-25 00:38:54 [INFO]: Epoch 008 - training loss (MAE): 0.9297, validation MSE: 0.8353\n",
      "2025-06-25 00:39:01 [INFO]: Epoch 009 - training loss (MAE): 0.8607, validation MSE: 0.8297\n",
      "2025-06-25 00:39:08 [INFO]: Epoch 010 - training loss (MAE): 0.8293, validation MSE: 0.8310\n",
      "2025-06-25 00:39:15 [INFO]: Epoch 011 - training loss (MAE): 0.8101, validation MSE: 0.8245\n",
      "2025-06-25 00:39:23 [INFO]: Epoch 012 - training loss (MAE): 0.7974, validation MSE: 0.8131\n",
      "2025-06-25 00:39:30 [INFO]: Epoch 013 - training loss (MAE): 0.7676, validation MSE: 0.8040\n",
      "2025-06-25 00:39:37 [INFO]: Epoch 014 - training loss (MAE): 0.7758, validation MSE: 0.7952\n",
      "2025-06-25 00:39:44 [INFO]: Epoch 015 - training loss (MAE): 0.7537, validation MSE: 0.7919\n",
      "2025-06-25 00:39:51 [INFO]: Epoch 016 - training loss (MAE): 0.7609, validation MSE: 0.7779\n",
      "2025-06-25 00:39:58 [INFO]: Epoch 017 - training loss (MAE): 0.7394, validation MSE: 0.7743\n",
      "2025-06-25 00:40:06 [INFO]: Epoch 018 - training loss (MAE): 0.7458, validation MSE: 0.7597\n",
      "2025-06-25 00:40:13 [INFO]: Epoch 019 - training loss (MAE): 0.7459, validation MSE: 0.7512\n",
      "2025-06-25 00:40:20 [INFO]: Epoch 020 - training loss (MAE): 0.7365, validation MSE: 0.7409\n",
      "2025-06-25 00:40:27 [INFO]: Epoch 021 - training loss (MAE): 0.7315, validation MSE: 0.7326\n",
      "2025-06-25 00:40:34 [INFO]: Epoch 022 - training loss (MAE): 0.7383, validation MSE: 0.7277\n",
      "2025-06-25 00:40:41 [INFO]: Epoch 023 - training loss (MAE): 0.7323, validation MSE: 0.7188\n",
      "2025-06-25 00:40:48 [INFO]: Epoch 024 - training loss (MAE): 0.7329, validation MSE: 0.7087\n",
      "2025-06-25 00:40:55 [INFO]: Epoch 025 - training loss (MAE): 0.7292, validation MSE: 0.7036\n",
      "2025-06-25 00:40:55 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:40:55 [INFO]: Saved the model to ./brits_model\\20250625_T003752\\BRITS.pypots\n",
      "2025-06-25 00:40:55 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:40:55 [INFO]: Model files will be saved to ./brits_model\\20250625_T004055\n",
      "2025-06-25 00:40:55 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T004055\\tensorboard\n",
      "2025-06-25 00:40:55 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:40:55 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:40:55 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 115,696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BRITS models for cluster 4...\n",
      "Training model for missing rate 0.05 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:41:08 [INFO]: Epoch 001 - training loss (MAE): 1.5219, validation MSE: 0.4468\n",
      "2025-06-25 00:41:16 [INFO]: Epoch 002 - training loss (MAE): 1.1905, validation MSE: 0.2735\n",
      "2025-06-25 00:41:25 [INFO]: Epoch 003 - training loss (MAE): 1.0237, validation MSE: 0.2291\n",
      "2025-06-25 00:41:34 [INFO]: Epoch 004 - training loss (MAE): 0.9349, validation MSE: 0.2172\n",
      "2025-06-25 00:41:43 [INFO]: Epoch 005 - training loss (MAE): 0.8663, validation MSE: 0.2047\n",
      "2025-06-25 00:41:52 [INFO]: Epoch 006 - training loss (MAE): 0.8229, validation MSE: 0.1965\n",
      "2025-06-25 00:42:00 [INFO]: Epoch 007 - training loss (MAE): 0.7819, validation MSE: 0.1917\n",
      "2025-06-25 00:42:09 [INFO]: Epoch 008 - training loss (MAE): 0.7542, validation MSE: 0.1874\n",
      "2025-06-25 00:42:18 [INFO]: Epoch 009 - training loss (MAE): 0.7389, validation MSE: 0.1833\n",
      "2025-06-25 00:42:27 [INFO]: Epoch 010 - training loss (MAE): 0.7233, validation MSE: 0.1796\n",
      "2025-06-25 00:42:35 [INFO]: Epoch 011 - training loss (MAE): 0.7198, validation MSE: 0.1764\n",
      "2025-06-25 00:42:44 [INFO]: Epoch 012 - training loss (MAE): 0.7076, validation MSE: 0.1734\n",
      "2025-06-25 00:42:53 [INFO]: Epoch 013 - training loss (MAE): 0.6956, validation MSE: 0.1703\n",
      "2025-06-25 00:43:01 [INFO]: Epoch 014 - training loss (MAE): 0.6806, validation MSE: 0.1673\n",
      "2025-06-25 00:43:10 [INFO]: Epoch 015 - training loss (MAE): 0.6931, validation MSE: 0.1646\n",
      "2025-06-25 00:43:19 [INFO]: Epoch 016 - training loss (MAE): 0.6804, validation MSE: 0.1622\n",
      "2025-06-25 00:43:27 [INFO]: Epoch 017 - training loss (MAE): 0.6715, validation MSE: 0.1595\n",
      "2025-06-25 00:43:37 [INFO]: Epoch 018 - training loss (MAE): 0.6666, validation MSE: 0.1570\n",
      "2025-06-25 00:43:46 [INFO]: Epoch 019 - training loss (MAE): 0.6512, validation MSE: 0.1547\n",
      "2025-06-25 00:43:55 [INFO]: Epoch 020 - training loss (MAE): 0.6558, validation MSE: 0.1524\n",
      "2025-06-25 00:44:04 [INFO]: Epoch 021 - training loss (MAE): 0.6454, validation MSE: 0.1495\n",
      "2025-06-25 00:44:13 [INFO]: Epoch 022 - training loss (MAE): 0.6431, validation MSE: 0.1474\n",
      "2025-06-25 00:44:22 [INFO]: Epoch 023 - training loss (MAE): 0.6316, validation MSE: 0.1448\n",
      "2025-06-25 00:44:31 [INFO]: Epoch 024 - training loss (MAE): 0.6246, validation MSE: 0.1427\n",
      "2025-06-25 00:44:40 [INFO]: Epoch 025 - training loss (MAE): 0.6191, validation MSE: 0.1399\n",
      "2025-06-25 00:44:40 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:44:40 [INFO]: Saved the model to ./brits_model\\20250625_T004055\\BRITS.pypots\n",
      "2025-06-25 00:44:40 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:44:40 [INFO]: Model files will be saved to ./brits_model\\20250625_T004440\n",
      "2025-06-25 00:44:40 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T004440\\tensorboard\n",
      "2025-06-25 00:44:40 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:44:40 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:44:40 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 115,696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.2 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:44:53 [INFO]: Epoch 001 - training loss (MAE): 1.5453, validation MSE: 0.4491\n",
      "2025-06-25 00:45:02 [INFO]: Epoch 002 - training loss (MAE): 1.2184, validation MSE: 0.2848\n",
      "2025-06-25 00:45:12 [INFO]: Epoch 003 - training loss (MAE): 1.0687, validation MSE: 0.2506\n",
      "2025-06-25 00:45:21 [INFO]: Epoch 004 - training loss (MAE): 0.9666, validation MSE: 0.2329\n",
      "2025-06-25 00:45:30 [INFO]: Epoch 005 - training loss (MAE): 0.8885, validation MSE: 0.2199\n",
      "2025-06-25 00:45:40 [INFO]: Epoch 006 - training loss (MAE): 0.8246, validation MSE: 0.2129\n",
      "2025-06-25 00:45:49 [INFO]: Epoch 007 - training loss (MAE): 0.7965, validation MSE: 0.2072\n",
      "2025-06-25 00:45:58 [INFO]: Epoch 008 - training loss (MAE): 0.7582, validation MSE: 0.2022\n",
      "2025-06-25 00:46:07 [INFO]: Epoch 009 - training loss (MAE): 0.7474, validation MSE: 0.1982\n",
      "2025-06-25 00:46:16 [INFO]: Epoch 010 - training loss (MAE): 0.7278, validation MSE: 0.1937\n",
      "2025-06-25 00:46:25 [INFO]: Epoch 011 - training loss (MAE): 0.7228, validation MSE: 0.1903\n",
      "2025-06-25 00:46:34 [INFO]: Epoch 012 - training loss (MAE): 0.7208, validation MSE: 0.1867\n",
      "2025-06-25 00:46:43 [INFO]: Epoch 013 - training loss (MAE): 0.6955, validation MSE: 0.1833\n",
      "2025-06-25 00:46:52 [INFO]: Epoch 014 - training loss (MAE): 0.6995, validation MSE: 0.1801\n",
      "2025-06-25 00:47:01 [INFO]: Epoch 015 - training loss (MAE): 0.6904, validation MSE: 0.1772\n",
      "2025-06-25 00:47:10 [INFO]: Epoch 016 - training loss (MAE): 0.6873, validation MSE: 0.1743\n",
      "2025-06-25 00:47:19 [INFO]: Epoch 017 - training loss (MAE): 0.6674, validation MSE: 0.1714\n",
      "2025-06-25 00:47:28 [INFO]: Epoch 018 - training loss (MAE): 0.6691, validation MSE: 0.1685\n",
      "2025-06-25 00:47:37 [INFO]: Epoch 019 - training loss (MAE): 0.6719, validation MSE: 0.1656\n",
      "2025-06-25 00:47:46 [INFO]: Epoch 020 - training loss (MAE): 0.6687, validation MSE: 0.1628\n",
      "2025-06-25 00:47:55 [INFO]: Epoch 021 - training loss (MAE): 0.6519, validation MSE: 0.1602\n",
      "2025-06-25 00:48:04 [INFO]: Epoch 022 - training loss (MAE): 0.6507, validation MSE: 0.1571\n",
      "2025-06-25 00:48:14 [INFO]: Epoch 023 - training loss (MAE): 0.6461, validation MSE: 0.1544\n",
      "2025-06-25 00:48:23 [INFO]: Epoch 024 - training loss (MAE): 0.6387, validation MSE: 0.1517\n",
      "2025-06-25 00:48:32 [INFO]: Epoch 025 - training loss (MAE): 0.6390, validation MSE: 0.1492\n",
      "2025-06-25 00:48:32 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:48:32 [INFO]: Saved the model to ./brits_model\\20250625_T004440\\BRITS.pypots\n",
      "2025-06-25 00:48:32 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:48:32 [INFO]: Model files will be saved to ./brits_model\\20250625_T004832\n",
      "2025-06-25 00:48:32 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T004832\\tensorboard\n",
      "2025-06-25 00:48:32 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:48:32 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:48:32 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 115,696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.6 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:48:45 [INFO]: Epoch 001 - training loss (MAE): 1.5472, validation MSE: 0.4804\n",
      "2025-06-25 00:48:53 [INFO]: Epoch 002 - training loss (MAE): 1.2343, validation MSE: 0.2988\n",
      "2025-06-25 00:49:02 [INFO]: Epoch 003 - training loss (MAE): 1.0617, validation MSE: 0.2638\n",
      "2025-06-25 00:49:11 [INFO]: Epoch 004 - training loss (MAE): 0.9526, validation MSE: 0.2441\n",
      "2025-06-25 00:49:20 [INFO]: Epoch 005 - training loss (MAE): 0.8707, validation MSE: 0.2369\n",
      "2025-06-25 00:49:29 [INFO]: Epoch 006 - training loss (MAE): 0.8314, validation MSE: 0.2304\n",
      "2025-06-25 00:49:38 [INFO]: Epoch 007 - training loss (MAE): 0.7899, validation MSE: 0.2257\n",
      "2025-06-25 00:49:47 [INFO]: Epoch 008 - training loss (MAE): 0.7640, validation MSE: 0.2225\n",
      "2025-06-25 00:49:56 [INFO]: Epoch 009 - training loss (MAE): 0.7511, validation MSE: 0.2189\n",
      "2025-06-25 00:50:05 [INFO]: Epoch 010 - training loss (MAE): 0.7509, validation MSE: 0.2156\n",
      "2025-06-25 00:50:14 [INFO]: Epoch 011 - training loss (MAE): 0.7345, validation MSE: 0.2125\n",
      "2025-06-25 00:50:23 [INFO]: Epoch 012 - training loss (MAE): 0.7228, validation MSE: 0.2083\n",
      "2025-06-25 00:50:32 [INFO]: Epoch 013 - training loss (MAE): 0.7190, validation MSE: 0.2052\n",
      "2025-06-25 00:50:40 [INFO]: Epoch 014 - training loss (MAE): 0.7072, validation MSE: 0.2019\n",
      "2025-06-25 00:50:49 [INFO]: Epoch 015 - training loss (MAE): 0.6960, validation MSE: 0.1985\n",
      "2025-06-25 00:50:58 [INFO]: Epoch 016 - training loss (MAE): 0.6961, validation MSE: 0.1966\n",
      "2025-06-25 00:51:07 [INFO]: Epoch 017 - training loss (MAE): 0.6785, validation MSE: 0.1933\n",
      "2025-06-25 00:51:16 [INFO]: Epoch 018 - training loss (MAE): 0.6866, validation MSE: 0.1902\n",
      "2025-06-25 00:51:24 [INFO]: Epoch 019 - training loss (MAE): 0.6768, validation MSE: 0.1874\n",
      "2025-06-25 00:51:33 [INFO]: Epoch 020 - training loss (MAE): 0.6714, validation MSE: 0.1847\n",
      "2025-06-25 00:51:42 [INFO]: Epoch 021 - training loss (MAE): 0.6580, validation MSE: 0.1826\n",
      "2025-06-25 00:51:50 [INFO]: Epoch 022 - training loss (MAE): 0.6569, validation MSE: 0.1788\n",
      "2025-06-25 00:51:59 [INFO]: Epoch 023 - training loss (MAE): 0.6592, validation MSE: 0.1768\n",
      "2025-06-25 00:52:08 [INFO]: Epoch 024 - training loss (MAE): 0.6541, validation MSE: 0.1752\n",
      "2025-06-25 00:52:17 [INFO]: Epoch 025 - training loss (MAE): 0.6495, validation MSE: 0.1716\n",
      "2025-06-25 00:52:17 [INFO]: Finished training. The best model is from epoch#25.\n",
      "2025-06-25 00:52:17 [INFO]: Saved the model to ./brits_model\\20250625_T004832\\BRITS.pypots\n",
      "2025-06-25 00:52:17 [INFO]: Using the given device: cpu\n",
      "2025-06-25 00:52:17 [INFO]: Model files will be saved to ./brits_model\\20250625_T005217\n",
      "2025-06-25 00:52:17 [INFO]: Tensorboard file will be saved to ./brits_model\\20250625_T005217\\tensorboard\n",
      "2025-06-25 00:52:17 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-06-25 00:52:17 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-06-25 00:52:17 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 115,696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for missing rate 0.99 in cluster 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 00:52:30 [INFO]: Epoch 001 - training loss (MAE): 1.6037, validation MSE: 0.8662\n",
      "2025-06-25 00:52:39 [INFO]: Epoch 002 - training loss (MAE): 1.3092, validation MSE: 0.7681\n",
      "2025-06-25 00:52:48 [INFO]: Epoch 003 - training loss (MAE): 1.0987, validation MSE: 0.6795\n",
      "2025-06-25 00:52:57 [INFO]: Epoch 004 - training loss (MAE): 0.9715, validation MSE: 0.6168\n",
      "2025-06-25 00:53:06 [INFO]: Epoch 005 - training loss (MAE): 0.8891, validation MSE: 0.5521\n",
      "2025-06-25 00:53:16 [INFO]: Epoch 006 - training loss (MAE): 0.8397, validation MSE: 0.5094\n",
      "2025-06-25 00:53:25 [INFO]: Epoch 007 - training loss (MAE): 0.8075, validation MSE: 0.4679\n",
      "2025-06-25 00:53:34 [INFO]: Epoch 008 - training loss (MAE): 0.7929, validation MSE: 0.4355\n",
      "2025-06-25 00:53:43 [INFO]: Epoch 009 - training loss (MAE): 0.7706, validation MSE: 0.4110\n",
      "2025-06-25 00:53:52 [INFO]: Epoch 010 - training loss (MAE): 0.7611, validation MSE: 0.3874\n",
      "2025-06-25 00:54:01 [INFO]: Epoch 011 - training loss (MAE): 0.7425, validation MSE: 0.3734\n",
      "2025-06-25 00:54:10 [INFO]: Epoch 012 - training loss (MAE): 0.7349, validation MSE: 0.3648\n",
      "2025-06-25 00:54:19 [INFO]: Epoch 013 - training loss (MAE): 0.7292, validation MSE: 0.3555\n",
      "2025-06-25 00:54:28 [INFO]: Epoch 014 - training loss (MAE): 0.7355, validation MSE: 0.3480\n",
      "2025-06-25 00:54:37 [INFO]: Epoch 015 - training loss (MAE): 0.7291, validation MSE: 0.3430\n",
      "2025-06-25 00:54:45 [INFO]: Epoch 016 - training loss (MAE): 0.7284, validation MSE: 0.3408\n",
      "2025-06-25 00:54:54 [INFO]: Epoch 017 - training loss (MAE): 0.7180, validation MSE: 0.3359\n",
      "2025-06-25 00:55:03 [INFO]: Epoch 018 - training loss (MAE): 0.7117, validation MSE: 0.3325\n",
      "2025-06-25 00:55:12 [INFO]: Epoch 019 - training loss (MAE): 0.7174, validation MSE: 0.3254\n",
      "2025-06-25 00:55:21 [INFO]: Epoch 020 - training loss (MAE): 0.7041, validation MSE: 0.3283\n",
      "2025-06-25 00:55:31 [INFO]: Epoch 021 - training loss (MAE): 0.6907, validation MSE: 0.3323\n",
      "2025-06-25 00:55:40 [INFO]: Epoch 022 - training loss (MAE): 0.7011, validation MSE: 0.3291\n",
      "2025-06-25 00:55:49 [INFO]: Epoch 023 - training loss (MAE): 0.6967, validation MSE: 0.3306\n",
      "2025-06-25 00:55:58 [INFO]: Epoch 024 - training loss (MAE): 0.6838, validation MSE: 0.3374\n",
      "2025-06-25 00:55:58 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-06-25 00:55:58 [INFO]: Finished training. The best model is from epoch#19.\n",
      "2025-06-25 00:55:58 [INFO]: Saved the model to ./brits_model\\20250625_T005217\\BRITS.pypots\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "rnn_hidden = 0\n",
    "# Initialize and fit BRITS models for each missing rate\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    print(f\"Training BRITS models for cluster {cluster_id}...\")\n",
    "    models[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        print(f\"Training model for missing rate {rate} in cluster {cluster_id}...\")\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        _, n_steps, n_features = train_data[cluster_id][key][\"X\"].shape\n",
    "        \n",
    "        # Reduce complexity of model for less features\n",
    "        if cluster_id != len(clusters) - 1:\n",
    "            rnn_hidden = 16\n",
    "        else:\n",
    "            rnn_hidden = 32\n",
    "        \n",
    "        models[cluster_id][key] = intialize_BRITS(n_steps, n_features, rnn_hidden)\n",
    "        models[cluster_id][key].fit(train_data[cluster_id][key], val_set=val_data[cluster_id][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0acfdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluation, since BRITS does not have passed ground truth without missing values.\n",
    "\n",
    "imputed = {}\n",
    "\n",
    "# Impute missing values using the trained models\n",
    "for cluster_id in range(len(clusters)):\n",
    "    imputed[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        imputed[cluster_id][key] = models[cluster_id][key].impute(val_data[cluster_id][key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0cbf79",
   "metadata": {},
   "source": [
    "### Unscale data before evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6037148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "imputed_unscaled = {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    imputed_unscaled[cluster_id] = {}\n",
    "    \n",
    "    scaler = joblib.load(f\"demand_scaler_{cluster_id}.pkl\")\n",
    "    print(f\"{type(scaler)}\")\n",
    "\n",
    "# Unscale the imputed values for each cluster and missing rate\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        n_samples, n_steps, n_features = imputed[cluster_id][key].shape\n",
    "        tensor_2d = imputed[cluster_id][key].reshape(-1, n_features)  # Flatten time dimension\n",
    "        tensor_2d_unscaled = scaler.inverse_transform(tensor_2d)\n",
    "        imputed_unscaled[cluster_id][key] = tensor_2d_unscaled.reshape(n_samples, n_steps, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9735c0fe",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26ac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Cluster 0 Rate 5%: 0.682\n",
      "R² Cluster 0 Rate 20%: 0.742\n",
      "R² Cluster 0 Rate 60%: 0.760\n",
      "R² Cluster 0 Rate 99%: 0.518\n",
      "R² Cluster 1 Rate 5%: 0.681\n",
      "R² Cluster 1 Rate 20%: 0.701\n",
      "R² Cluster 1 Rate 60%: 0.774\n",
      "R² Cluster 1 Rate 99%: 0.539\n",
      "R² Cluster 2 Rate 5%: 0.759\n",
      "R² Cluster 2 Rate 20%: 0.671\n",
      "R² Cluster 2 Rate 60%: 0.816\n",
      "R² Cluster 2 Rate 99%: 0.376\n",
      "R² Cluster 3 Rate 5%: 0.684\n",
      "R² Cluster 3 Rate 20%: 0.676\n",
      "R² Cluster 3 Rate 60%: 0.761\n",
      "R² Cluster 3 Rate 99%: 0.238\n",
      "R² Cluster 4 Rate 5%: 0.776\n",
      "R² Cluster 4 Rate 20%: 0.769\n",
      "R² Cluster 4 Rate 60%: 0.775\n",
      "R² Cluster 4 Rate 99%: 0.635\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_scores = {}\n",
    "\n",
    "for cluster_id in range(len(clusters)):\n",
    "    r2_scores[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "\n",
    "        imputed = imputed_unscaled[cluster_id][key]\n",
    "        original = X_val_full_unscaled_seq_tensor[cluster_id]\n",
    "        mask = val_masks_seq[cluster_id][key]\n",
    "\n",
    "        # Initialize list for per-feature R²\n",
    "        feature_r2 = []\n",
    "\n",
    "        for f in range(original.shape[2]):  # loop over features\n",
    "            f_mask = mask[:, :, f]\n",
    "            if not np.any(f_mask):\n",
    "                continue  # skip if no missing values for this feature\n",
    "\n",
    "            y_true = original[:, :, f][f_mask]\n",
    "            y_pred = imputed[:, :, f][f_mask]\n",
    "\n",
    "            if len(y_true) < 2:\n",
    "                continue  # not enough points to compute R²\n",
    "\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            feature_r2.append(r2)\n",
    "\n",
    "        if feature_r2:\n",
    "            r2_scores[cluster_id][key] = np.mean(feature_r2)\n",
    "        else:\n",
    "            r2_scores[cluster_id][key] = np.nan \n",
    "\n",
    "        print(f\"R² Cluster {cluster_id} Rate {rate*100:.0f}%: {r2_scores[cluster_id][key]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8638c47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE Cluster 0 Rate 5.0%: 23.43%\n",
      "SMAPE Cluster 0 Rate 20.0%: 16.74%\n",
      "SMAPE Cluster 0 Rate 60.0%: 28.49%\n",
      "SMAPE Cluster 0 Rate 99.0%: 36.76%\n",
      "SMAPE Cluster 1 Rate 5.0%: 15.71%\n",
      "SMAPE Cluster 1 Rate 20.0%: 16.59%\n",
      "SMAPE Cluster 1 Rate 60.0%: 17.03%\n",
      "SMAPE Cluster 1 Rate 99.0%: 34.10%\n",
      "SMAPE Cluster 2 Rate 5.0%: 16.36%\n",
      "SMAPE Cluster 2 Rate 20.0%: 17.56%\n",
      "SMAPE Cluster 2 Rate 60.0%: 18.76%\n",
      "SMAPE Cluster 2 Rate 99.0%: 42.89%\n",
      "SMAPE Cluster 3 Rate 5.0%: 18.07%\n",
      "SMAPE Cluster 3 Rate 20.0%: 20.49%\n",
      "SMAPE Cluster 3 Rate 60.0%: 17.25%\n",
      "SMAPE Cluster 3 Rate 99.0%: 42.21%\n",
      "SMAPE Cluster 4 Rate 5.0%: 16.44%\n",
      "SMAPE Cluster 4 Rate 20.0%: 18.74%\n",
      "SMAPE Cluster 4 Rate 60.0%: 18.60%\n",
      "SMAPE Cluster 4 Rate 99.0%: 29.12%\n"
     ]
    }
   ],
   "source": [
    "smape = {}\n",
    "for cluster_id in range(len(clusters)):\n",
    "    smape[cluster_id] = {}\n",
    "    for rate in missing_rates:\n",
    "        key = int(rate * 100)\n",
    "        imputed = imputed_unscaled[cluster_id][key]  # shape (n_samples, n_steps, n_features)\n",
    "        original = X_val_full_unscaled_seq_tensor[cluster_id]  # same shape\n",
    "        mask = val_masks_seq[cluster_id][key]  # same shape (bool mask)\n",
    "\n",
    "        n_samples, n_steps, n_features = original.shape\n",
    "\n",
    "        feature_smapes = []\n",
    "        for f in range(n_features):\n",
    "            # Select the mask and data for feature f\n",
    "            f_mask = mask[:, :, f]\n",
    "            if not np.any(f_mask):\n",
    "                continue  # skip if no missing values for this feature\n",
    "\n",
    "            numerator = np.abs(imputed[:, :, f][f_mask] - original[:, :, f][f_mask])\n",
    "            denominator = np.abs(imputed[:, :, f][f_mask]) + np.abs(original[:, :, f][f_mask]) + 1e-8\n",
    "            smape_f = 100 * np.mean(2 * numerator / denominator)\n",
    "            feature_smapes.append(smape_f)\n",
    "\n",
    "        smape[cluster_id][key] = np.mean(feature_smapes) if feature_smapes else np.nan\n",
    "        print(f\"SMAPE Cluster {cluster_id} Rate {rate*100}%: {smape[cluster_id][key]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7a8813",
   "metadata": {},
   "source": [
    "### Average errors per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a28efcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_per_cluster = {i: X_val_full_unscaled_seq_tensor[i].shape[-1] for i in range(len(clusters))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47fe8430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 29, 1: 11, 2: 10, 3: 32, 4: 82}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff3943e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average NRMSE for rate 5.0%: 0.69%\n",
      "NRMSE for full at rate 5.0%: 0.78%\n",
      "Weighted Average NRMSE for rate 20.0%: 0.70%\n",
      "NRMSE for full at rate 20.0%: 0.77%\n",
      "Weighted Average NRMSE for rate 60.0%: 0.77%\n",
      "NRMSE for full at rate 60.0%: 0.78%\n",
      "Weighted Average NRMSE for rate 99.0%: 0.39%\n",
      "NRMSE for full at rate 99.0%: 0.63%\n"
     ]
    }
   ],
   "source": [
    "n_clusters = len(clusters) - 1  # number of actual clusters\n",
    "flow_all_id = len(clusters) - 1  # index of the full dataset\n",
    "\n",
    "avg_r2_cluster = {}\n",
    "r2_all = {}\n",
    "\n",
    "for rate in missing_rates:\n",
    "    key = int(rate * 100)\n",
    "\n",
    "    # Gather NRMSE and weights (number of features per cluster)\n",
    "    r2_values = np.array([r2_scores[cluster_id][key] for cluster_id in range(n_clusters)])\n",
    "    feature_counts = np.array([features_per_cluster[cluster_id] for cluster_id in range(n_clusters)])\n",
    "\n",
    "    # Compute weighted average\n",
    "    weighted_avg = np.average(r2_values, weights=feature_counts)\n",
    "    \n",
    "    avg_r2_cluster[key] = weighted_avg\n",
    "    r2_all[key] = r2_scores[flow_all_id][key]  # for full feature set\n",
    "\n",
    "    print(f\"Weighted Average NRMSE for rate {rate*100}%: {avg_r2_cluster[key]:.2f}%\")\n",
    "    print(f\"NRMSE for full at rate {rate*100}%: {r2_all[key]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73e2293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average SMAPE for rate 5.0%: 19.44%\n",
      "SMAPE for full at rate 5.0%: 16.44%\n",
      "Weighted Average SMAPE for rate 20.0%: 18.28%\n",
      "SMAPE for full at rate 20.0%: 18.74%\n",
      "Weighted Average SMAPE for rate 60.0%: 21.38%\n",
      "SMAPE for full at rate 60.0%: 18.60%\n",
      "Weighted Average SMAPE for rate 99.0%: 39.28%\n",
      "SMAPE for full at rate 99.0%: 29.12%\n"
     ]
    }
   ],
   "source": [
    "avg_smape_cluster = {}\n",
    "smape_all = {}\n",
    "\n",
    "for rate in missing_rates:\n",
    "    key = int(rate * 100)\n",
    "    \n",
    "    # Gather SMAPE and weights (number of features per cluster)\n",
    "    smape_values = np.array([smape[cluster_id][key] for cluster_id in range(n_clusters)])\n",
    "    feature_counts = np.array([features_per_cluster[cluster_id] for cluster_id in range(n_clusters)])\n",
    "    \n",
    "    # Compute weighted average\n",
    "    weighted_avg = np.average(smape_values, weights=feature_counts)\n",
    "    \n",
    "    avg_smape_cluster[key] = weighted_avg\n",
    "    smape_all[key] = smape[flow_all_id][key]  # for full feature set\n",
    "    \n",
    "    print(f\"Weighted Average SMAPE for rate {rate*100}%: {avg_smape_cluster[key]:.2f}%\")\n",
    "    print(f\"SMAPE for full at rate {rate*100}%: {smape_all[key]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a46fd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{5: 23.431198603290937, 20: 16.736880958388205, 60: 28.48650393473094, 99: 36.7553764066602}, {5: 15.713516102730923, 20: 16.585547552672843, 60: 17.032335403910775, 99: 34.10418207517046}, {5: 16.355135500077193, 20: 17.55620859073525, 60: 18.757917370926627, 99: 42.89355028513864}, {5: 18.074603333750005, 20: 20.49193632921142, 60: 17.246693574146345, 99: 42.20873031060727}, {5: 16.444951345839446, 20: 18.73675455619697, 60: 18.601833612970953, 99: 29.1153140033935}])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14dfd112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_missing_vs_observed(data, mask, feature_name=\"flow\"):\n",
    "    \"\"\"\n",
    "    data: 1D array of original values\n",
    "    mask: 1D boolean array, True if missing\n",
    "    feature_name: for labeling\n",
    "    \"\"\"\n",
    "    data_missing = data[mask]\n",
    "    data_observed = data[~mask]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(data_observed, color='blue', label='Observed', kde=True, stat=\"density\", bins=30)\n",
    "    sns.histplot(data_missing, color='red', label='Missing', kde=True, stat=\"density\", bins=30)\n",
    "    plt.title(f\"Distribution of {feature_name} - Observed vs Missing\")\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_missing_vs_observed(X_val_full_unscaled_seq_tensor[0].flatten(), val_masks_seq[0][99].flatten(), feature_name=\"Flow at 20% missingness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7a9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Missingness levels\n",
    "missing_levels = ['5%', '40%', '60%', '90%']\n",
    "\n",
    "# Bar chart setup\n",
    "x = np.arange(len(missing_levels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# --- MAE plot ---\n",
    "ax[0].bar(x - width/2, r2_all.values(), width, label='Without Semantics', color='tab:blue')\n",
    "ax[0].bar(x + width/2, avg_r2_cluster.values(), width, label='With Semantics', color='tab:orange')\n",
    "ax[0].set_ylabel('MAE')\n",
    "ax[0].set_title('MAE by Missingness Level')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# --- SMAPE plot ---\n",
    "ax[1].bar(x - width/2, smape_all.values(), width, label='Without Semantics', color='tab:blue')\n",
    "ax[1].bar(x + width/2, avg_smape_cluster.values(), width, label='With Semantics', color='tab:orange')\n",
    "ax[1].set_ylabel('SMAPE (%)')\n",
    "ax[1].set_title('SMAPE by Missingness Level')\n",
    "ax[1].set_xticks(x)\n",
    "ax[1].set_xticklabels(missing_levels)\n",
    "ax[1].legend()\n",
    "ax[1].grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
